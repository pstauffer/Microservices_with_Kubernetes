{
    "docs": [
        {
            "location": "/",
            "text": "Welcome to my docs\n\n\ndeployed via travis ci",
            "title": "Home"
        },
        {
            "location": "/#welcome-to-my-docs",
            "text": "",
            "title": "Welcome to my docs"
        },
        {
            "location": "/#deployed-via-travis-ci",
            "text": "",
            "title": "deployed via travis ci"
        },
        {
            "location": "/README/",
            "text": "Microservices with Kubernetes\n\n\n\n\nSetup\n\n\nFirst REST service\n\n\nDocker registry\n\n\nJenkins\n\n\nBuild and push\n\n\nSystemtest\n\n\nUI test\n\n\nLasttest\n\n\nManual test\n\n\nCanary release\n\n\nFull production release\n\n\nOwn Git repository\n\n\nMonitoring\n\n\nDocumentation of a REST service\n\n\nAngular2 frontend\n\n\nSSO with Keycloak\n\n\nUse Cassandra for persistence",
            "title": "README"
        },
        {
            "location": "/README/#microservices-with-kubernetes",
            "text": "Setup  First REST service  Docker registry  Jenkins  Build and push  Systemtest  UI test  Lasttest  Manual test  Canary release  Full production release  Own Git repository  Monitoring  Documentation of a REST service  Angular2 frontend  SSO with Keycloak  Use Cassandra for persistence",
            "title": "Microservices with Kubernetes"
        },
        {
            "location": "/01_Setup/Host_setup/",
            "text": "Setup your local host machine\n\n\nBasic setup\n\n\nI'm using a Ubuntu 16.04 Desktop installation. After the installation I execute the following\n\nscript\n:\n\n\nsudo apt-add-repository ppa:ansible/ansible -y\nsudo apt-get update\nsudo apt-get upgrade -y\nsudo apt-get install software-properties-common -y\nsudo apt-get install ansible -y\nsudo apt-get install git -y\nansible --version\n\n\n\n\nInstallation of Docker, IntelliJ and Payara\n\n\nFor this installation I have created an Ansible script that can be checked out \nhere\n.\n\nStart the installation of the tools:\n\n\nansible-playbook playbooks/basicSetUp.yml\n\n\n\n\nTest if Docker can be used without root rights:\n\n\ndocker ps\n\n\n\n\nIf this is not the case you have to execute the following command:\n\n\nnewgrp docker\n\n\n\n\nIntelliJ live templates\n\n\nI'm using a lot of live templates that I've created for IntelliJ. This templates are \navailable on \nGitHub\n.\n\nTo include them in IntelliJ we have to check out the repository in the IntelliJ \nconfiguration folder.\n\n\ncd ~/.IntelliJIdea2016.3/config/\ngit clone https://github.com/robertBrem/IntelliJ_Live_Templates\nmv IntelliJ_Live_Templates/ templates\n\n\n\n\nNow I can use my live templates everywhere.",
            "title": "Host setup"
        },
        {
            "location": "/01_Setup/Host_setup/#setup-your-local-host-machine",
            "text": "",
            "title": "Setup your local host machine"
        },
        {
            "location": "/01_Setup/Host_setup/#basic-setup",
            "text": "I'm using a Ubuntu 16.04 Desktop installation. After the installation I execute the following script :  sudo apt-add-repository ppa:ansible/ansible -y\nsudo apt-get update\nsudo apt-get upgrade -y\nsudo apt-get install software-properties-common -y\nsudo apt-get install ansible -y\nsudo apt-get install git -y\nansible --version",
            "title": "Basic setup"
        },
        {
            "location": "/01_Setup/Host_setup/#installation-of-docker-intellij-and-payara",
            "text": "For this installation I have created an Ansible script that can be checked out  here . \nStart the installation of the tools:  ansible-playbook playbooks/basicSetUp.yml  Test if Docker can be used without root rights:  docker ps  If this is not the case you have to execute the following command:  newgrp docker",
            "title": "Installation of Docker, IntelliJ and Payara"
        },
        {
            "location": "/01_Setup/Host_setup/#intellij-live-templates",
            "text": "I'm using a lot of live templates that I've created for IntelliJ. This templates are \navailable on  GitHub . \nTo include them in IntelliJ we have to check out the repository in the IntelliJ \nconfiguration folder.  cd ~/.IntelliJIdea2016.3/config/\ngit clone https://github.com/robertBrem/IntelliJ_Live_Templates\nmv IntelliJ_Live_Templates/ templates  Now I can use my live templates everywhere.",
            "title": "IntelliJ live templates"
        },
        {
            "location": "/01_Setup/Kubernetes_setup/",
            "text": "Setup a Kubernetes cluster\n\n\nSetup the servers for the cluster\n\n\nI am using 5 small servers from \ncontabo\n.\n\nFor the setup with \nkubeadm\n \nthe OS has to be Ubuntu 16.04 or CentOS 7.x. In my case I am going with \nCent OS 7.3 (64 bit)\n.  \n\n\n  \n\n\n\n\nThe setup is working in the \nAWS Cloud\n with \n\nUbuntu 16.04 LTS - Xenial (HVM)\n \nand \nCentOS 7 (x86_64) - with Updates HVM\n \nas well.\n\n\n\n\nThat the Kubernetes setup can access the servers we have to install our ssh keys to the servers.\nIf you don't have a ssh key you can create one with the following command:\n\n\nssh-keygen -t rsa -b 4096\n\n\n\n\nNow we have to install our public key on every server:\n\n\nssh-copy-id root@5.189.153.209\n\n\n\n\nWe can test the setup if we try to ssh into the server:\n\n\nssh root@5.189.153.209\n\n\n\n\nIf the connection is working our initial setup of the server is done.\n\n\nSetup the cluster with Ansible\n\n\nThe setup with \nkubeadm\n is really simple, but still includes some manual steps that can be automated.\nTherefore a good friend of mine wrote a Ansible playbook that can be checked out from \nhere\n\n\n\n\nIn the following parts I'm using tools like Git and Ansible. \nHere\n I'm \ndescribing how to install the basic tools.\n\n\n\n\ngit clone https://github.com/pstauffer/kubernetes-setup\n\n\n\n\nCreate an inventory file with the following content:\n\n\n[master]\n5.189.173.45\n\n[minions]\n5.189.172.130\n5.189.172.129\n5.189.154.24\n5.189.153.209\n\n[cluster:children]\nmaster\nminions\n\n[cluster:vars]\n# kubernetes part\nkubemaster_token = abcdef.abcdefabcdefabcd\n\n# ansible part\nansible_ssh_private_key_file = /home/battleapp/.ssh/id_rsa\nansible_user = root\n\n# python part\ninstall_python_centos = true\ninstall_python_ubuntu = false\n\n\n\n\nStart the setup playbook with this inventory:\n\n\nansible-playbook -i inventories/sample playbooks/setup.yml\n\n\n\n\nInstall \nkubectl\n like described \non this site\n on your host machine. \nTest the installation:\n\n\nkubectl -h\n\n\n\n\nDownload the \nadmin.conf\n from your master:\n\n\nscp root@5.189.173.45:/etc/kubernetes/admin.conf .\n\n\n\n\nCreate an alias for your cluster.\n\nCreate the file \n.alias\n in your home directory with the following content:\n\n\nalias kc='kubectl --kubeconfig /home/[HOST USER]/Desktop/admin.conf'\n\n\n\n\nExtend the \n.bashrc\n of the home directory:\n\n\n. ~/.alias\n\n\n\n\nExecute \nalias\n in the current bash:\n\n\n. .alias\n\n\n\n\nTest the cluster:\n\n\nkc get no\nNAME                    STATUS         AGE\nvmi71989.contabo.host   Ready          21m\nvmi71992.contabo.host   Ready          22m\nvmi74388.contabo.host   Ready          22m\nvmi74389.contabo.host   Ready          22m\nvmi74448.contabo.host   Ready,master   24m",
            "title": "Kubernetes setup"
        },
        {
            "location": "/01_Setup/Kubernetes_setup/#setup-a-kubernetes-cluster",
            "text": "",
            "title": "Setup a Kubernetes cluster"
        },
        {
            "location": "/01_Setup/Kubernetes_setup/#setup-the-servers-for-the-cluster",
            "text": "I am using 5 small servers from  contabo . \nFor the setup with  kubeadm  \nthe OS has to be Ubuntu 16.04 or CentOS 7.x. In my case I am going with  Cent OS 7.3 (64 bit) .         The setup is working in the  AWS Cloud  with  Ubuntu 16.04 LTS - Xenial (HVM)  \nand  CentOS 7 (x86_64) - with Updates HVM  \nas well.   That the Kubernetes setup can access the servers we have to install our ssh keys to the servers.\nIf you don't have a ssh key you can create one with the following command:  ssh-keygen -t rsa -b 4096  Now we have to install our public key on every server:  ssh-copy-id root@5.189.153.209  We can test the setup if we try to ssh into the server:  ssh root@5.189.153.209  If the connection is working our initial setup of the server is done.",
            "title": "Setup the servers for the cluster"
        },
        {
            "location": "/01_Setup/Kubernetes_setup/#setup-the-cluster-with-ansible",
            "text": "The setup with  kubeadm  is really simple, but still includes some manual steps that can be automated.\nTherefore a good friend of mine wrote a Ansible playbook that can be checked out from  here   In the following parts I'm using tools like Git and Ansible.  Here  I'm \ndescribing how to install the basic tools.   git clone https://github.com/pstauffer/kubernetes-setup  Create an inventory file with the following content:  [master]\n5.189.173.45\n\n[minions]\n5.189.172.130\n5.189.172.129\n5.189.154.24\n5.189.153.209\n\n[cluster:children]\nmaster\nminions\n\n[cluster:vars]\n# kubernetes part\nkubemaster_token = abcdef.abcdefabcdefabcd\n\n# ansible part\nansible_ssh_private_key_file = /home/battleapp/.ssh/id_rsa\nansible_user = root\n\n# python part\ninstall_python_centos = true\ninstall_python_ubuntu = false  Start the setup playbook with this inventory:  ansible-playbook -i inventories/sample playbooks/setup.yml  Install  kubectl  like described  on this site  on your host machine. \nTest the installation:  kubectl -h  Download the  admin.conf  from your master:  scp root@5.189.173.45:/etc/kubernetes/admin.conf .  Create an alias for your cluster. \nCreate the file  .alias  in your home directory with the following content:  alias kc='kubectl --kubeconfig /home/[HOST USER]/Desktop/admin.conf'  Extend the  .bashrc  of the home directory:  . ~/.alias  Execute  alias  in the current bash:  . .alias  Test the cluster:  kc get no\nNAME                    STATUS         AGE\nvmi71989.contabo.host   Ready          21m\nvmi71992.contabo.host   Ready          22m\nvmi74388.contabo.host   Ready          22m\nvmi74389.contabo.host   Ready          22m\nvmi74448.contabo.host   Ready,master   24m",
            "title": "Setup the cluster with Ansible"
        },
        {
            "location": "/01_Setup/README/",
            "text": "Setup\n\n\n\n\nHost setup\n\n\nKubernetes setup",
            "title": "README"
        },
        {
            "location": "/01_Setup/README/#setup",
            "text": "Host setup  Kubernetes setup",
            "title": "Setup"
        },
        {
            "location": "/02_First_rest_service/Deploy_in_Kubernetes/",
            "text": "Deploy the Docker image of the service in Kubernetes\n\n\nTo deploy the service in Kubernetes we need a \ndeployment\n and a \nservice\n \nas well as infrastructure with a Docker registry. How to setup a Docker registry is\ndescribed \nhere\n.\n\n\nBuild and push the service to the registry\n\n\nIf we have a Docker registry we can push our image to the registry. In the root folder\nof our service we build the Docker image with the registry information.\n\n\ndocker build -t disruptor.ninja:30500/robertbrem/battleapp:1.0.0 .\n\n\n\n\nNow we can push the image to the repository:\n\n\ndocker login disruptor.ninja:30500 --username=rob --password=1234\ndocker push disruptor.ninja:30500/robertbrem/battleapp:1.0.0\n\n\n\n\nDeploy the service in Kubernetes\n\n\nTo use the registry we need to create a Kubernetes secret:\n\n\nkc create secret docker-registry registrykey --docker-username=rob --docker-password=1234 --docker-email=brem_robert@hotmail.com --docker-server=disruptor.ninja:30500\n\n\n\n\nThe \ndeployment\n looks like this:\n\n\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: battleapp\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: battleapp\n    spec:\n      containers:\n      - resources:\n        name: battleapp\n        image: disruptor.ninja:30500/robertbrem/battleapp:1.0.0\n        ports:\n        - name: port\n          containerPort: 8080\n      imagePullSecrets:\n      - name: registrykey\n\n\n\n\nThen we can create this deployment:\n\n\nkc create -f deployment.yml\n\n\n\n\nTo see the REST service we have to expose it to the internet with a Kubernetes service:\n\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: battleapp\n  labels:\n    name: battleapp\nspec:\n  ports:\n  - port: 8081\n    targetPort: 8080\n    nodePort: 30080\n  selector:\n    name: battleapp\n  type: NodePort\n\n\n\n\nThe service is now running on the following url:  \n\n\nhttp://disruptor.ninja:30080/battleapp/resources/users\n\n\n\n\nThe output should be something like that:\n\n\n[{\"name\":\"dan\"},{\"name\":\"robert\"},{\"name\":\"kevin\"}]",
            "title": "Deploy in Kubernetes"
        },
        {
            "location": "/02_First_rest_service/Deploy_in_Kubernetes/#deploy-the-docker-image-of-the-service-in-kubernetes",
            "text": "To deploy the service in Kubernetes we need a  deployment  and a  service  \nas well as infrastructure with a Docker registry. How to setup a Docker registry is\ndescribed  here .",
            "title": "Deploy the Docker image of the service in Kubernetes"
        },
        {
            "location": "/02_First_rest_service/Deploy_in_Kubernetes/#build-and-push-the-service-to-the-registry",
            "text": "If we have a Docker registry we can push our image to the registry. In the root folder\nof our service we build the Docker image with the registry information.  docker build -t disruptor.ninja:30500/robertbrem/battleapp:1.0.0 .  Now we can push the image to the repository:  docker login disruptor.ninja:30500 --username=rob --password=1234\ndocker push disruptor.ninja:30500/robertbrem/battleapp:1.0.0",
            "title": "Build and push the service to the registry"
        },
        {
            "location": "/02_First_rest_service/Deploy_in_Kubernetes/#deploy-the-service-in-kubernetes",
            "text": "To use the registry we need to create a Kubernetes secret:  kc create secret docker-registry registrykey --docker-username=rob --docker-password=1234 --docker-email=brem_robert@hotmail.com --docker-server=disruptor.ninja:30500  The  deployment  looks like this:  apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: battleapp\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: battleapp\n    spec:\n      containers:\n      - resources:\n        name: battleapp\n        image: disruptor.ninja:30500/robertbrem/battleapp:1.0.0\n        ports:\n        - name: port\n          containerPort: 8080\n      imagePullSecrets:\n      - name: registrykey  Then we can create this deployment:  kc create -f deployment.yml  To see the REST service we have to expose it to the internet with a Kubernetes service:  apiVersion: v1\nkind: Service\nmetadata:\n  name: battleapp\n  labels:\n    name: battleapp\nspec:\n  ports:\n  - port: 8081\n    targetPort: 8080\n    nodePort: 30080\n  selector:\n    name: battleapp\n  type: NodePort  The service is now running on the following url:    http://disruptor.ninja:30080/battleapp/resources/users  The output should be something like that:  [{\"name\":\"dan\"},{\"name\":\"robert\"},{\"name\":\"kevin\"}]",
            "title": "Deploy the service in Kubernetes"
        },
        {
            "location": "/02_First_rest_service/Dockerization/",
            "text": "Dockerization of the service\n\n\nKubernetes uses containers for the orchestration. Therefore we have to pack our service in \na container. I'm using Docker as container technology.\n\n\nAt first we have to create a \nDockerfile\n in the root folder of the project with the following\ncontent:\n\n\nFROM airhacks/wildfly\n\nMAINTAINER Robert Brem <brem_robert@hotmail.com>\n\nADD target/battleapp.war ${DEPLOYMENT_DIR}\n\n\n\n\nTo test it just build the application:\n\n\nmvn clean install\n\n\n\n\nThen build the Docker image:\n\n\ndocker build -t battleapp .\n\n\n\n\nAfter the build you can start a container for this image:\n\n\ndocker run -p 8081:8080 --name battleapp -d battleapp\n\n\n\n\nThe service is now running on the port 8081:  \n\n\nhttp://localhost:8081/battleapp/resources/users\n\n\n\n\nThe output should be something like that:\n\n\n[{\"name\":\"dan\"},{\"name\":\"robert\"},{\"name\":\"kevin\"}]",
            "title": "Dockerization"
        },
        {
            "location": "/02_First_rest_service/Dockerization/#dockerization-of-the-service",
            "text": "Kubernetes uses containers for the orchestration. Therefore we have to pack our service in \na container. I'm using Docker as container technology.  At first we have to create a  Dockerfile  in the root folder of the project with the following\ncontent:  FROM airhacks/wildfly\n\nMAINTAINER Robert Brem <brem_robert@hotmail.com>\n\nADD target/battleapp.war ${DEPLOYMENT_DIR}  To test it just build the application:  mvn clean install  Then build the Docker image:  docker build -t battleapp .  After the build you can start a container for this image:  docker run -p 8081:8080 --name battleapp -d battleapp  The service is now running on the port 8081:    http://localhost:8081/battleapp/resources/users  The output should be something like that:  [{\"name\":\"dan\"},{\"name\":\"robert\"},{\"name\":\"kevin\"}]",
            "title": "Dockerization of the service"
        },
        {
            "location": "/02_First_rest_service/JavaEE_service/",
            "text": "Creating our first JavaEE microservice\n\n\nOur first microservice is a REST service written in Java. I'm using JavaEE and Wildfly\nas application server. JavaEE is the perfect combination with Docker.\n\nWildfly can be downloaded from \nhere\n.\n\nAs IDE I'm using IntelliJ.\n\n\n\n\nIntelliJ and Maven is already installed during the \nhost setup\n.\n\n\n\n\nSetup a new maven project\n\n\nI'm using a minimalistic maven setup:  \n\n\ncom.airhacks:javaee7-essentials-archetype:1.3\n\n\n\n\nTo create a project in IntelliJ with this Archetype you have to open IntelliJ and choose \n\nFile -> New -> Project...\n\nAnd make the following settings:\n\n\n\n\nIf you creating a project with this Archetype for the first time you have to use \nAdd Archetype...\n\nand insert the information from the Archetype.\n\n\nNow click \nNext\n and insert the project settings:\n\n\n\n\nClick \nNext\n \nNext\n \nFinish\n\n\nNow you can implement the REST service. I've made a simple service that can be cloned from\n\n\nhere\n.\n\n\nUsing Lombok\n\n\nI use Lombok in my example service. To use Lombok you have to add the dependency to the \n\npom.xml\n as well as to install the Lombok plugin in IntelliJ. You can install the plugin\nover \nFile -> Settings...\n \nPlugins\n \nBrowse repositories...\n and search for \nLombok\n.\n\n\n\n\nClick \nInstall\n \nRestart\n.\n\n\nAdd this to you \npom.xml\n:\n\n\n<dependency>\n    <groupId>org.projectlombok</groupId>\n    <artifactId>lombok</artifactId>\n    <version>1.16.12</version>\n</dependency>\n\n\n\n\nThis is also available as IntelliJ live template.\n\n\nNow you can use Lombok for constructors, getters, setters, toString and so on. This\nis useful especially for data classes:\n\n\n@AllArgsConstructor\n@Data\npublic class User {\n    private String name;\n}\n\n\n\n\nUsing porcupine for thread pools\n\n\nTo have a fully async REST service we've to use thread pools as bulkheads and to handle\nbackpressure.\n\n\nTherefore we use porcupine.\n\n\n<dependency>\n    <groupId>com.airhacks</groupId>\n    <artifactId>porcupine</artifactId>\n    <version>0.0.4</version>\n</dependency>\n\n\n\n\nHere is the implementation of our \njax-rs\n service.\n\n\n@Path(\"users\")\n@Produces(MediaType.APPLICATION_JSON)\npublic class UserResource {\n\n    @Dedicated\n    @Inject\n    ExecutorService usersPool;\n\n    @Inject\n    UserService userService;\n\n    @GET\n    public void getUsers(@Suspended AsyncResponse response) {\n        CompletableFuture\n                .supplyAsync(userService::getUsersAsGenericEntity, usersPool)\n                .thenAccept(response::resume);\n    }\n\n}\n\n\n\n\nIt is also possible to configure the thread pool in code:\n\n\n@Specializes\npublic class CustomExecutorConfigurator extends ExecutorConfigurator {\n\n    @Override\n    public ExecutorConfiguration defaultConfigurator() {\n        return super.defaultConfigurator();\n    }\n\n    @Override\n    public ExecutorConfiguration forPipeline(String name) {\n        if (\"heavy\".equals(name)) {\n            return new ExecutorConfiguration.Builder().\n                    corePoolSize(4).\n                    maxPoolSize(8).\n                    queueCapacity(16).\n                    keepAliveTime(1).\n                    callerRunsPolicy().\n                    build();\n        }\n        return super.forPipeline(name);\n    }\n\n}\n\n\n\n\nExport entities as JSON\n\n\nSet\ns and \nList\ns can't be automatically exported as JSON arrays there fore we need\nthe \nGenericEntity\n like in our control. \n\n\n@Stateless\npublic class UserService {\n\n    public GenericEntity<Set<User>> getUsersAsGenericEntity() {\n        return new GenericEntity<Set<User>>(getUsers()) {\n        };\n    }\n\n    public Set<User> getUsers() {\n        HashSet<User> users = new HashSet<>();\n        users.add(new User(\"Rob\"));\n        users.add(new User(\"Dan\"));\n        users.add(new User(\"Kevin\"));\n        users.add(new User(\"Corine\"));\n        return users;\n    }\n\n}\n\n\n\n\nWildfly in IntelliJ\n\n\nYou can setup Wildfly in IntelliJ over the \nEdit Configuration...\n menu.\n\n\n\n\nClick on the \n+\n\n\n\n\nIn the \nServer\n tab make the following settings:\n\n\n\n\nChange to the \nDeployment\n tab and add the artifact:\n\n\n\n\nTest the service\n\n\nTo test the service you simply have to push the play button:\n\n\n\n\nAnd call the following url: \nhttp://localhost:8080/battleapp/resources/users\n.\nThe output should be something like that:\n\n\n[{\"name\":\"dan\"},{\"name\":\"robert\"},{\"name\":\"kevin\"}]",
            "title": "JavaEE service"
        },
        {
            "location": "/02_First_rest_service/JavaEE_service/#creating-our-first-javaee-microservice",
            "text": "Our first microservice is a REST service written in Java. I'm using JavaEE and Wildfly\nas application server. JavaEE is the perfect combination with Docker. \nWildfly can be downloaded from  here . \nAs IDE I'm using IntelliJ.   IntelliJ and Maven is already installed during the  host setup .",
            "title": "Creating our first JavaEE microservice"
        },
        {
            "location": "/02_First_rest_service/JavaEE_service/#setup-a-new-maven-project",
            "text": "I'm using a minimalistic maven setup:    com.airhacks:javaee7-essentials-archetype:1.3  To create a project in IntelliJ with this Archetype you have to open IntelliJ and choose  File -> New -> Project... \nAnd make the following settings:   If you creating a project with this Archetype for the first time you have to use  Add Archetype... \nand insert the information from the Archetype.  Now click  Next  and insert the project settings:   Click  Next   Next   Finish  Now you can implement the REST service. I've made a simple service that can be cloned from  here .",
            "title": "Setup a new maven project"
        },
        {
            "location": "/02_First_rest_service/JavaEE_service/#using-lombok",
            "text": "I use Lombok in my example service. To use Lombok you have to add the dependency to the  pom.xml  as well as to install the Lombok plugin in IntelliJ. You can install the plugin\nover  File -> Settings...   Plugins   Browse repositories...  and search for  Lombok .   Click  Install   Restart .  Add this to you  pom.xml :  <dependency>\n    <groupId>org.projectlombok</groupId>\n    <artifactId>lombok</artifactId>\n    <version>1.16.12</version>\n</dependency>  This is also available as IntelliJ live template.  Now you can use Lombok for constructors, getters, setters, toString and so on. This\nis useful especially for data classes:  @AllArgsConstructor\n@Data\npublic class User {\n    private String name;\n}",
            "title": "Using Lombok"
        },
        {
            "location": "/02_First_rest_service/JavaEE_service/#using-porcupine-for-thread-pools",
            "text": "To have a fully async REST service we've to use thread pools as bulkheads and to handle\nbackpressure.  Therefore we use porcupine.  <dependency>\n    <groupId>com.airhacks</groupId>\n    <artifactId>porcupine</artifactId>\n    <version>0.0.4</version>\n</dependency>  Here is the implementation of our  jax-rs  service.  @Path(\"users\")\n@Produces(MediaType.APPLICATION_JSON)\npublic class UserResource {\n\n    @Dedicated\n    @Inject\n    ExecutorService usersPool;\n\n    @Inject\n    UserService userService;\n\n    @GET\n    public void getUsers(@Suspended AsyncResponse response) {\n        CompletableFuture\n                .supplyAsync(userService::getUsersAsGenericEntity, usersPool)\n                .thenAccept(response::resume);\n    }\n\n}  It is also possible to configure the thread pool in code:  @Specializes\npublic class CustomExecutorConfigurator extends ExecutorConfigurator {\n\n    @Override\n    public ExecutorConfiguration defaultConfigurator() {\n        return super.defaultConfigurator();\n    }\n\n    @Override\n    public ExecutorConfiguration forPipeline(String name) {\n        if (\"heavy\".equals(name)) {\n            return new ExecutorConfiguration.Builder().\n                    corePoolSize(4).\n                    maxPoolSize(8).\n                    queueCapacity(16).\n                    keepAliveTime(1).\n                    callerRunsPolicy().\n                    build();\n        }\n        return super.forPipeline(name);\n    }\n\n}",
            "title": "Using porcupine for thread pools"
        },
        {
            "location": "/02_First_rest_service/JavaEE_service/#export-entities-as-json",
            "text": "Set s and  List s can't be automatically exported as JSON arrays there fore we need\nthe  GenericEntity  like in our control.   @Stateless\npublic class UserService {\n\n    public GenericEntity<Set<User>> getUsersAsGenericEntity() {\n        return new GenericEntity<Set<User>>(getUsers()) {\n        };\n    }\n\n    public Set<User> getUsers() {\n        HashSet<User> users = new HashSet<>();\n        users.add(new User(\"Rob\"));\n        users.add(new User(\"Dan\"));\n        users.add(new User(\"Kevin\"));\n        users.add(new User(\"Corine\"));\n        return users;\n    }\n\n}",
            "title": "Export entities as JSON"
        },
        {
            "location": "/02_First_rest_service/JavaEE_service/#wildfly-in-intellij",
            "text": "You can setup Wildfly in IntelliJ over the  Edit Configuration...  menu.   Click on the  +   In the  Server  tab make the following settings:   Change to the  Deployment  tab and add the artifact:",
            "title": "Wildfly in IntelliJ"
        },
        {
            "location": "/02_First_rest_service/JavaEE_service/#test-the-service",
            "text": "To test the service you simply have to push the play button:   And call the following url:  http://localhost:8080/battleapp/resources/users .\nThe output should be something like that:  [{\"name\":\"dan\"},{\"name\":\"robert\"},{\"name\":\"kevin\"}]",
            "title": "Test the service"
        },
        {
            "location": "/02_First_rest_service/README/",
            "text": "Creation of our first microservice\n\n\n\n\nJavaEE service\n\n\nDockerization\n\n\nDeploy in Kubernetes",
            "title": "README"
        },
        {
            "location": "/02_First_rest_service/README/#creation-of-our-first-microservice",
            "text": "JavaEE service  Dockerization  Deploy in Kubernetes",
            "title": "Creation of our first microservice"
        },
        {
            "location": "/03_Docker_registry/README/",
            "text": "Setup a docker registry\n\n\nCreate folders for the persistence\n\n\nThe Docker registry has persistent data therefore we've to mount this data somewhere.\nThe easiest way to do that is over a node selector. A more advanced solution would be\nto use GlusterFS, Flocker, NFS or something similar.\n\n\nIf we use node selectors for our persistence then we've to log in to the server\nthat ip is used in the DNS registry. In my case that's the master.\n\n\nssh root@5.189.173.45\n\n\n\n\nOn the server we've to create the folder structure that gets mounted to the host.\nIn our case we have three folders one for the Docker images, one for our ssl certificates\nand the last for the authorization information.  \n\n\nmkdir -p registry/{images,certs,auth}\nsudo docker run --entrypoint htpasswd registry:2 -Bbn rob 1234 > registry/auth/htpasswd\n\n\n\n\nThe last command creates a user with a password for the Docker registry.\n\n\nCreate SSL certificates\n\n\nWe are going to create SSL certificates with LetsEncrypt. Therefore we have to install\nLetsEncrypt on the server:\n\n\nsudo yum update -y\nsudo yum install epel-release -y\nsudo yum install letsencrypt -y\n\n\n\n\nNow we can create the certificates:\n\n\nsudo letsencrypt certonly -d disruptor.ninja\n\n\n\n\nThe certificates are created under the following folder:\n\n\n/etc/letsencrypt/live/disruptor.ninja\n\n\n\n\nThe certificates have to be visible for the Docker registry therefore we copy them to\nthe \ncerts\n folder we have created:\n\n\nsudo cp /etc/letsencrypt/live/disruptor.ninja/fullchain.pem registry/certs/\nsudo cp /etc/letsencrypt/live/disruptor.ninja/privkey.pem registry/certs/\n\n\n\n\nKubernetes deployment\n\n\nTo tell Kubernetes to schedule the Docker registry pod on the master node we've to \nlabel the node:\n\n\nkc label nodes vmi74448.contabo.host name=vmi74448\n\n\n\n\nNext we create a \ndeployment.yml\n file \nlike this one\n.\n\n\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: registry\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: registry\n    spec:\n      containers:\n      - resources:\n        name: registry\n        image: registry:2\n        ports:\n        - name: registry-port\n          containerPort: 5000\n        volumeMounts:\n        - mountPath: /var/lib/registry\n          name: images\n        - mountPath: /certs\n          name: certs\n        - mountPath: /auth\n          name: auth\n        env:\n        - name: REGISTRY_AUTH\n          value: \"htpasswd\"\n        - name: REGISTRY_AUTH_HTPASSWD_REALM\n          value: \"Registry Realm\"\n        - name: REGISTRY_AUTH_HTPASSWD_PATH\n          value: /auth/htpasswd\n        - name: REGISTRY_HTTP_TLS_CERTIFICATE\n          value: /certs/fullchain.pem\n        - name: REGISTRY_HTTP_TLS_KEY\n          value: /certs/privkey.pem\n      volumes:\n      - name: images\n        hostPath:\n          path: /root/registry/images\n      - name: certs\n        hostPath:\n          path: /root/registry/certs\n      - name: auth\n        hostPath:\n          path: /root/registry/auth\n      nodeSelector:\n        name: vmi74448\n\n\n\n\nThis file has to be deployed:\n\n\nkc create -f deployment.yml\n\n\n\n\nTo test if the deployment is working you can display all pods:\n\n\nkc get po\n\n\n\n\nNAME                      READY     STATUS    RESTARTS   AGE\nregistry-95525520-9rdvc   1/1       Running   0          1m\n\n\n\n\nKubernetes service\n\n\nTo make the registry visible outside the cluster we have to create a Kubernetes service.\nThe \nservice.yml\n file can be created similar to \nthis file\n.\n\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: registry\n  labels:\n    name: registry\nspec:\n  ports:\n  - port: 5001\n    targetPort: 5000\n    nodePort: 30500\n  selector:\n    name: registry\n  type: NodePort\n\n\n\n\nTo test the registry we can call the following url:\n\n\nhttps://disruptor.ninja:30500/v2/_catalog",
            "title": "README"
        },
        {
            "location": "/03_Docker_registry/README/#setup-a-docker-registry",
            "text": "",
            "title": "Setup a docker registry"
        },
        {
            "location": "/03_Docker_registry/README/#create-folders-for-the-persistence",
            "text": "The Docker registry has persistent data therefore we've to mount this data somewhere.\nThe easiest way to do that is over a node selector. A more advanced solution would be\nto use GlusterFS, Flocker, NFS or something similar.  If we use node selectors for our persistence then we've to log in to the server\nthat ip is used in the DNS registry. In my case that's the master.  ssh root@5.189.173.45  On the server we've to create the folder structure that gets mounted to the host.\nIn our case we have three folders one for the Docker images, one for our ssl certificates\nand the last for the authorization information.    mkdir -p registry/{images,certs,auth}\nsudo docker run --entrypoint htpasswd registry:2 -Bbn rob 1234 > registry/auth/htpasswd  The last command creates a user with a password for the Docker registry.",
            "title": "Create folders for the persistence"
        },
        {
            "location": "/03_Docker_registry/README/#create-ssl-certificates",
            "text": "We are going to create SSL certificates with LetsEncrypt. Therefore we have to install\nLetsEncrypt on the server:  sudo yum update -y\nsudo yum install epel-release -y\nsudo yum install letsencrypt -y  Now we can create the certificates:  sudo letsencrypt certonly -d disruptor.ninja  The certificates are created under the following folder:  /etc/letsencrypt/live/disruptor.ninja  The certificates have to be visible for the Docker registry therefore we copy them to\nthe  certs  folder we have created:  sudo cp /etc/letsencrypt/live/disruptor.ninja/fullchain.pem registry/certs/\nsudo cp /etc/letsencrypt/live/disruptor.ninja/privkey.pem registry/certs/",
            "title": "Create SSL certificates"
        },
        {
            "location": "/03_Docker_registry/README/#kubernetes-deployment",
            "text": "To tell Kubernetes to schedule the Docker registry pod on the master node we've to \nlabel the node:  kc label nodes vmi74448.contabo.host name=vmi74448  Next we create a  deployment.yml  file  like this one .  apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: registry\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: registry\n    spec:\n      containers:\n      - resources:\n        name: registry\n        image: registry:2\n        ports:\n        - name: registry-port\n          containerPort: 5000\n        volumeMounts:\n        - mountPath: /var/lib/registry\n          name: images\n        - mountPath: /certs\n          name: certs\n        - mountPath: /auth\n          name: auth\n        env:\n        - name: REGISTRY_AUTH\n          value: \"htpasswd\"\n        - name: REGISTRY_AUTH_HTPASSWD_REALM\n          value: \"Registry Realm\"\n        - name: REGISTRY_AUTH_HTPASSWD_PATH\n          value: /auth/htpasswd\n        - name: REGISTRY_HTTP_TLS_CERTIFICATE\n          value: /certs/fullchain.pem\n        - name: REGISTRY_HTTP_TLS_KEY\n          value: /certs/privkey.pem\n      volumes:\n      - name: images\n        hostPath:\n          path: /root/registry/images\n      - name: certs\n        hostPath:\n          path: /root/registry/certs\n      - name: auth\n        hostPath:\n          path: /root/registry/auth\n      nodeSelector:\n        name: vmi74448  This file has to be deployed:  kc create -f deployment.yml  To test if the deployment is working you can display all pods:  kc get po  NAME                      READY     STATUS    RESTARTS   AGE\nregistry-95525520-9rdvc   1/1       Running   0          1m",
            "title": "Kubernetes deployment"
        },
        {
            "location": "/03_Docker_registry/README/#kubernetes-service",
            "text": "To make the registry visible outside the cluster we have to create a Kubernetes service.\nThe  service.yml  file can be created similar to  this file .  apiVersion: v1\nkind: Service\nmetadata:\n  name: registry\n  labels:\n    name: registry\nspec:\n  ports:\n  - port: 5001\n    targetPort: 5000\n    nodePort: 30500\n  selector:\n    name: registry\n  type: NodePort  To test the registry we can call the following url:  https://disruptor.ninja:30500/v2/_catalog",
            "title": "Kubernetes service"
        },
        {
            "location": "/04_Jenkins/README/",
            "text": "Setup Jenkins in Kubernetes\n\n\nTo deploy often we must have CI/CD. In this case we are using Jenkins.\n\n\nStart Jenkins without mounting \njenkins_home\n\n\nJenkins has persistent data therefore we have to mount this data somewhere.\nThe easiest way to do that is over a node selector. A more advanced solution would be\nto use GlusterFS, Flocker, NFS or something similar.\n\n\nIf we use node selectors for our persistence then we have to label a node.\nIn this case this is \n5.189.153.209\n.\n\n\nkc label nodes vmi71989.contabo.host name=vmi71989\n\n\n\n\nNow we create the Jenkins deployment without mounting the \njenkins_home\n. I'm\nusing \nthis file\n\nas a reference.\n\n\nLater we want to be able the push Docker images in the Docker registry therefore Jenkins\nneed to know a username and password. For this we can create another secret:\n\n\nkc create secret generic registrykeygeneric --from-literal=username=rob --from-literal=password=1234\n\n\n\n\nFor our first deployment I'm going to comment the \njenkins_home\n volume mount.\n\n\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: jenkins\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: jenkins\n    spec:\n      containers:\n      - resources:\n        name: jenkins\n        image: robertbrem/jenkins:1.0.5\n        ports:\n        - name: ui\n          containerPort: 8080\n        - name: hooks\n          containerPort: 50000\n        volumeMounts:\n        - mountPath: /var/run/docker.sock\n          name: docker-socket\n#        - mountPath: /var/jenkins_home\n#          name: jenkins-home\n        env:\n        - name: REGISTRY_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: registrykeygeneric\n              key: username\n        - name: REGISTRY_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: registrykeygeneric\n              key: password\n      volumes:\n      - name: docker-socket\n        hostPath:\n          path: /var/run/docker.sock\n#      - name: jenkins-home\n#        hostPath:\n#          path: /root/jenkins_home/\n      nodeSelector:\n        name: vmi71989\n\n\n\n\nStart the deployment:\n\n\nkc create -f deployment.yml\n\n\n\n\nCreate the persistence for \njenkins_home\n\n\nWhile jenkins is running connect on the server where the \nnodeSelector\n is pointing to.\n\n\nssh root@5.189.153.209\n\n\n\n\nNow we have to find the container where Jenkins is running:\n\n\nsudo docker ps  | grep jenkins\n\n\n\n\na80da2e388e1        robertbrem/jenkins:1.0.2                           \"/bin/bash -c ./run.s\"   2 minutes ago       Up 2 minutes                            k8s_jenkins.f24a85d5_jenkins-1074834219-nqlfc_default_ec99c5d7-c941-11e6-a836-0050563cad2a_5e2790be\n157591884d20        gcr.io/google_containers/pause-amd64:3.0           \"/pause\"                 5 minutes ago       Up 5 minutes                            k8s_POD.d8dbe16c_jenkins-1074834219-nqlfc_default_ec99c5d7-c941-11e6-a836-0050563cad2a_569a356a\n\n\n\n\nIn our case this is \na80da2e388e1\n. Now we copy the content of \njenkins_home\n on the server.\n\n\nsudo docker cp a80da2e388e1:/var/jenkins_home .\n\n\n\n\nThat the container can use this mount we have to change the rights of the folder.\n\n\nsudo chown -R 1000:1000 jenkins_home/\n\n\n\n\nStart Jenkins with the \njenkins_home\n mount\n\n\nNow we can stop the current Jenkins deployment:\n\n\nkc delete deployment jenkins\n\n\n\n\nThen we uncomment the previously commented lines of the deployment and redeploy it.\n\n\nkc create -f deployment.yml\n\n\n\n\nMake Jenkins visible\n\n\nThat Jenkins is visible outside the cluster we have to create a service:\n\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: jenkins\n  labels:\n    name: jenkins\nspec:\n  ports:\n  - port: 8082\n    targetPort: 8080\n    nodePort: 30180\n  selector:\n    name: jenkins\n  type: NodePort\n\n\n\n\nTo start using Jenkins we need the administrator password that is logged in the container.\nWe can access the log of a container over \nkubectl\n.\n\n\nkc get po -l name=jenkins\n\n\n\n\nNAME                       READY     STATUS    RESTARTS   AGE\njenkins-1074834219-7jws0   1/1       Running   0          3m\n\n\n\n\nNow we can display the log:\n\n\nkc logs jenkins-1074834219-7jws0\n\n\n\n\nHere we can find the administrator password that we need when we start Jenkins on:\n\n\nhttp://disruptor.ninja:30180",
            "title": "README"
        },
        {
            "location": "/04_Jenkins/README/#setup-jenkins-in-kubernetes",
            "text": "To deploy often we must have CI/CD. In this case we are using Jenkins.",
            "title": "Setup Jenkins in Kubernetes"
        },
        {
            "location": "/04_Jenkins/README/#start-jenkins-without-mounting-jenkins_home",
            "text": "Jenkins has persistent data therefore we have to mount this data somewhere.\nThe easiest way to do that is over a node selector. A more advanced solution would be\nto use GlusterFS, Flocker, NFS or something similar.  If we use node selectors for our persistence then we have to label a node.\nIn this case this is  5.189.153.209 .  kc label nodes vmi71989.contabo.host name=vmi71989  Now we create the Jenkins deployment without mounting the  jenkins_home . I'm\nusing  this file \nas a reference.  Later we want to be able the push Docker images in the Docker registry therefore Jenkins\nneed to know a username and password. For this we can create another secret:  kc create secret generic registrykeygeneric --from-literal=username=rob --from-literal=password=1234  For our first deployment I'm going to comment the  jenkins_home  volume mount.  apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: jenkins\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: jenkins\n    spec:\n      containers:\n      - resources:\n        name: jenkins\n        image: robertbrem/jenkins:1.0.5\n        ports:\n        - name: ui\n          containerPort: 8080\n        - name: hooks\n          containerPort: 50000\n        volumeMounts:\n        - mountPath: /var/run/docker.sock\n          name: docker-socket\n#        - mountPath: /var/jenkins_home\n#          name: jenkins-home\n        env:\n        - name: REGISTRY_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: registrykeygeneric\n              key: username\n        - name: REGISTRY_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: registrykeygeneric\n              key: password\n      volumes:\n      - name: docker-socket\n        hostPath:\n          path: /var/run/docker.sock\n#      - name: jenkins-home\n#        hostPath:\n#          path: /root/jenkins_home/\n      nodeSelector:\n        name: vmi71989  Start the deployment:  kc create -f deployment.yml",
            "title": "Start Jenkins without mounting jenkins_home"
        },
        {
            "location": "/04_Jenkins/README/#create-the-persistence-for-jenkins_home",
            "text": "While jenkins is running connect on the server where the  nodeSelector  is pointing to.  ssh root@5.189.153.209  Now we have to find the container where Jenkins is running:  sudo docker ps  | grep jenkins  a80da2e388e1        robertbrem/jenkins:1.0.2                           \"/bin/bash -c ./run.s\"   2 minutes ago       Up 2 minutes                            k8s_jenkins.f24a85d5_jenkins-1074834219-nqlfc_default_ec99c5d7-c941-11e6-a836-0050563cad2a_5e2790be\n157591884d20        gcr.io/google_containers/pause-amd64:3.0           \"/pause\"                 5 minutes ago       Up 5 minutes                            k8s_POD.d8dbe16c_jenkins-1074834219-nqlfc_default_ec99c5d7-c941-11e6-a836-0050563cad2a_569a356a  In our case this is  a80da2e388e1 . Now we copy the content of  jenkins_home  on the server.  sudo docker cp a80da2e388e1:/var/jenkins_home .  That the container can use this mount we have to change the rights of the folder.  sudo chown -R 1000:1000 jenkins_home/",
            "title": "Create the persistence for jenkins_home"
        },
        {
            "location": "/04_Jenkins/README/#start-jenkins-with-the-jenkins_home-mount",
            "text": "Now we can stop the current Jenkins deployment:  kc delete deployment jenkins  Then we uncomment the previously commented lines of the deployment and redeploy it.  kc create -f deployment.yml",
            "title": "Start Jenkins with the jenkins_home mount"
        },
        {
            "location": "/04_Jenkins/README/#make-jenkins-visible",
            "text": "That Jenkins is visible outside the cluster we have to create a service:  apiVersion: v1\nkind: Service\nmetadata:\n  name: jenkins\n  labels:\n    name: jenkins\nspec:\n  ports:\n  - port: 8082\n    targetPort: 8080\n    nodePort: 30180\n  selector:\n    name: jenkins\n  type: NodePort  To start using Jenkins we need the administrator password that is logged in the container.\nWe can access the log of a container over  kubectl .  kc get po -l name=jenkins  NAME                       READY     STATUS    RESTARTS   AGE\njenkins-1074834219-7jws0   1/1       Running   0          3m  Now we can display the log:  kc logs jenkins-1074834219-7jws0  Here we can find the administrator password that we need when we start Jenkins on:  http://disruptor.ninja:30180",
            "title": "Make Jenkins visible"
        },
        {
            "location": "/05_Build_and_push_ci_step/README/",
            "text": "Build and push CI step\n\n\nThe first step of the CI/CD pipeline is the creation of the service as a Docker image.  \n\n\nCreate a \nJenkinsfile\n\n\nTo create a new pipeline we've to create a \nJenkinsfile\n similar to \nthis one\n.\n\n\nwithEnv([\"VERSION=1.0.${currentBuild.number}\", \"REGISTRY_EMAIL=brem_robert@hotmail.com\"]) {\n  stage \"checkout, build, test and publish\"\n  node {\n    git url: \"https://github.com/robertBrem/battleapp\"\n    def mvnHome = tool 'M3'\n    sh \"${mvnHome}/bin/mvn clean install\"\n    sh \"./build.js\"\n  }\n}\n\n\n\n\nInstall Maven in Jenkins\n\n\nBefore we can execute this pipeline we have to install Maven in Jenkins.\n\n\nManage Jenkins\n \nGlobal Tool Configuration\n \nAdd Maven\n\nThere we set the name to \nM3\n\n\n  \n\n\nCreate the build script\n\n\nThe script to build and push the Docker image is written in JavaScript and gets executed\nwith Nashorn.\n\n\n#!/usr/bin/jjs -fv\n\nvar version = $ENV.VERSION;\nvar username = $ENV.REGISTRY_USERNAME;\nvar password = $ENV.REGISTRY_PASSWORD;\nvar email = $ENV.REGISTRY_EMAIL;\n\nvar registry = \"disruptor.ninja:30500\";\nvar image = \"robertbrem/battleapp\";\nvar completeImageName = registry + \"/\" + image + \":\" + version;\n\nvar dockerBuild = \"docker build -t \" + completeImageName + \" .\";\nexecute(dockerBuild);\n\nvar dockerLogin = \"docker login --username=\" + username + \" --password=\" + password + \" --email=\" + email + \" \" + registry;\nexecute(dockerLogin);\n\nvar push = \"docker push \" + completeImageName;\nexecute(push);\n\nfunction execute(command) {\n    $EXEC(command);\n    print($OUT);\n    print($ERR);\n}\n\n\n\n\nThis script is available as live script.\n\n\nThat the script can be executed it has to be executable:\n\n\nchmod 750 build.js\n\n\n\n\nCreate the pipeline in Jenkins\n\n\nNow create the Jenkins pipeline with the created \nJenkinsfile\n.\n\nClick in Jenkins on \nNew item\n with the name \nbattleapp\n and of type \nPipeline\n.\n\n\n  \n\n\nChoose \nTrigger builds remotely (e.g., from scripts)\n and set a token.\n\n\n  \n\n\nChoose \nPipeline script from SCM\n with the following settings:\n\n\n  \n\n\nThen \nSave\n and \nBuild Now\n.",
            "title": "README"
        },
        {
            "location": "/05_Build_and_push_ci_step/README/#build-and-push-ci-step",
            "text": "The first step of the CI/CD pipeline is the creation of the service as a Docker image.",
            "title": "Build and push CI step"
        },
        {
            "location": "/05_Build_and_push_ci_step/README/#create-a-jenkinsfile",
            "text": "To create a new pipeline we've to create a  Jenkinsfile  similar to  this one .  withEnv([\"VERSION=1.0.${currentBuild.number}\", \"REGISTRY_EMAIL=brem_robert@hotmail.com\"]) {\n  stage \"checkout, build, test and publish\"\n  node {\n    git url: \"https://github.com/robertBrem/battleapp\"\n    def mvnHome = tool 'M3'\n    sh \"${mvnHome}/bin/mvn clean install\"\n    sh \"./build.js\"\n  }\n}",
            "title": "Create a Jenkinsfile"
        },
        {
            "location": "/05_Build_and_push_ci_step/README/#install-maven-in-jenkins",
            "text": "Before we can execute this pipeline we have to install Maven in Jenkins.  Manage Jenkins   Global Tool Configuration   Add Maven \nThere we set the name to  M3",
            "title": "Install Maven in Jenkins"
        },
        {
            "location": "/05_Build_and_push_ci_step/README/#create-the-build-script",
            "text": "The script to build and push the Docker image is written in JavaScript and gets executed\nwith Nashorn.  #!/usr/bin/jjs -fv\n\nvar version = $ENV.VERSION;\nvar username = $ENV.REGISTRY_USERNAME;\nvar password = $ENV.REGISTRY_PASSWORD;\nvar email = $ENV.REGISTRY_EMAIL;\n\nvar registry = \"disruptor.ninja:30500\";\nvar image = \"robertbrem/battleapp\";\nvar completeImageName = registry + \"/\" + image + \":\" + version;\n\nvar dockerBuild = \"docker build -t \" + completeImageName + \" .\";\nexecute(dockerBuild);\n\nvar dockerLogin = \"docker login --username=\" + username + \" --password=\" + password + \" --email=\" + email + \" \" + registry;\nexecute(dockerLogin);\n\nvar push = \"docker push \" + completeImageName;\nexecute(push);\n\nfunction execute(command) {\n    $EXEC(command);\n    print($OUT);\n    print($ERR);\n}  This script is available as live script.  That the script can be executed it has to be executable:  chmod 750 build.js",
            "title": "Create the build script"
        },
        {
            "location": "/05_Build_and_push_ci_step/README/#create-the-pipeline-in-jenkins",
            "text": "Now create the Jenkins pipeline with the created  Jenkinsfile . \nClick in Jenkins on  New item  with the name  battleapp  and of type  Pipeline .      Choose  Trigger builds remotely (e.g., from scripts)  and set a token.      Choose  Pipeline script from SCM  with the following settings:      Then  Save  and  Build Now .",
            "title": "Create the pipeline in Jenkins"
        },
        {
            "location": "/06_Systemtest_ci_step/README/",
            "text": "System test CI step\n\n\n\n\nSetup test environment\n\n\nCreate a system test\n\n\nStart the Jenkins pipeline on every push",
            "title": "README"
        },
        {
            "location": "/06_Systemtest_ci_step/README/#system-test-ci-step",
            "text": "Setup test environment  Create a system test  Start the Jenkins pipeline on every push",
            "title": "System test CI step"
        },
        {
            "location": "/06_Systemtest_ci_step/Setup_test_env/",
            "text": "Setup the test environment\n\n\nAfter the build, unit tests and the Docker push we want to test the system from the outside.\nTherefore we need a test environment with the service.\n\n\nCreate JavaScript\n\n\nLike the Docker push we start the test environment with JavaScript.\n\n\n#!/usr/bin/jjs -fv\n\nvar FileWriter = Java.type(\"java.io.FileWriter\");\n\nvar version = $ENV.VERSION;\nvar kubectl = $ENV.KUBECTL;\n\nvar name = \"battleapp-test\";\nvar image = \"disruptor.ninja:30500/robertbrem/battleapp:\" + version;\nvar replicas = 1;\nvar port = 8080;\nvar clusterPort = 8088;\nvar nodePort = 31080;\nvar deploymentFileName = \"deployment.yml\";\nvar serviceFileName = \"service.yml\";\nvar registrysecret = \"registrykey\";\nvar url = \"http://disruptor.ninja:31080/battleapp/resources/users\";\nvar timeout = 2;\n\nvar deleteDeployment = kubectl + \" delete deployment \" + name;\nexecute(deleteDeployment);\n\nvar dfw = new FileWriter(deploymentFileName);\ndfw.write(\"apiVersion: extensions/v1beta1\\n\");\ndfw.write(\"kind: Deployment\\n\");\ndfw.write(\"metadata:\\n\");\ndfw.write(\"  name: \" + name + \"\\n\");\ndfw.write(\"spec:\\n\");\ndfw.write(\"  replicas: \" + replicas + \"\\n\");\ndfw.write(\"  template:\\n\");\ndfw.write(\"    metadata:\\n\");\ndfw.write(\"      labels:\\n\");\ndfw.write(\"        name: \" + name + \"\\n\");\ndfw.write(\"    spec:\\n\");\ndfw.write(\"      containers:\\n\");\ndfw.write(\"      - resources:\\n\");\ndfw.write(\"        name: \" + name + \"\\n\");\ndfw.write(\"        image: \" + image + \"\\n\");\ndfw.write(\"        ports:\\n\");\ndfw.write(\"        - name: port\\n\");\ndfw.write(\"          containerPort: \" + port + \"\\n\");\ndfw.write(\"      imagePullSecrets:\\n\");\ndfw.write(\"      - name: \" + registrysecret + \"\\n\");\ndfw.close();\n\nvar deploy = kubectl + \" create -f \" + deploymentFileName;\nexecute(deploy);\n\nvar deleteService = kubectl + \" delete service \" + name;\nexecute(deleteService);\n\nvar sfw = new FileWriter(serviceFileName);\nsfw.write(\"apiVersion: v1\\n\");\nsfw.write(\"kind: Service\\n\");\nsfw.write(\"metadata:\\n\");\nsfw.write(\"  name: \" + name + \"\\n\");\nsfw.write(\"  labels:\\n\");\nsfw.write(\"    name: \" + name + \"\\n\");\nsfw.write(\"spec:\\n\");\nsfw.write(\"  ports:\\n\");\nsfw.write(\"  - port: \" + clusterPort + \"\\n\");\nsfw.write(\"    targetPort: \" + port + \"\\n\");\nsfw.write(\"    nodePort: \" + nodePort + \"\\n\");\nsfw.write(\"  selector:\\n\");\nsfw.write(\"    name: \" + name + \"\\n\");\nsfw.write(\"  type: NodePort\\n\");\nsfw.close();\n\nvar deployService = kubectl + \" create -f \" + serviceFileName;\nexecute(deployService);\n\nvar testUrl = \"curl --write-out %{http_code} --silent --output /dev/null \" + url + \" --max-time \" + timeout;\nexecute(testUrl);\nwhile ($OUT != \"200\") {\n    $EXEC(\"sleep 1\");\n    execute(testUrl);\n}\n\nfunction execute(command) {\n    $EXEC(command);\n    print($OUT);\n    print($ERR);\n}\n\n\n\n\nThis script is available as live template.  \n\n\nThat the script can be executed it has to be executable:\n\n\nchmod 750 start.js\n\n\n\n\nAdd start test environment as CI step\n\n\nThis script has to be added to the Jenkins pipeline:\n\n\n  stage \"start test environment\"\n  node {\n    git url: \"https://github.com/robertBrem/BattleApp-StartTestEnv\"\n    sh \"./start.js\"\n  }\n\n\n\n\nThen \nBuild Now\n.",
            "title": "Setup test env"
        },
        {
            "location": "/06_Systemtest_ci_step/Setup_test_env/#setup-the-test-environment",
            "text": "After the build, unit tests and the Docker push we want to test the system from the outside.\nTherefore we need a test environment with the service.",
            "title": "Setup the test environment"
        },
        {
            "location": "/06_Systemtest_ci_step/Setup_test_env/#create-javascript",
            "text": "Like the Docker push we start the test environment with JavaScript.  #!/usr/bin/jjs -fv\n\nvar FileWriter = Java.type(\"java.io.FileWriter\");\n\nvar version = $ENV.VERSION;\nvar kubectl = $ENV.KUBECTL;\n\nvar name = \"battleapp-test\";\nvar image = \"disruptor.ninja:30500/robertbrem/battleapp:\" + version;\nvar replicas = 1;\nvar port = 8080;\nvar clusterPort = 8088;\nvar nodePort = 31080;\nvar deploymentFileName = \"deployment.yml\";\nvar serviceFileName = \"service.yml\";\nvar registrysecret = \"registrykey\";\nvar url = \"http://disruptor.ninja:31080/battleapp/resources/users\";\nvar timeout = 2;\n\nvar deleteDeployment = kubectl + \" delete deployment \" + name;\nexecute(deleteDeployment);\n\nvar dfw = new FileWriter(deploymentFileName);\ndfw.write(\"apiVersion: extensions/v1beta1\\n\");\ndfw.write(\"kind: Deployment\\n\");\ndfw.write(\"metadata:\\n\");\ndfw.write(\"  name: \" + name + \"\\n\");\ndfw.write(\"spec:\\n\");\ndfw.write(\"  replicas: \" + replicas + \"\\n\");\ndfw.write(\"  template:\\n\");\ndfw.write(\"    metadata:\\n\");\ndfw.write(\"      labels:\\n\");\ndfw.write(\"        name: \" + name + \"\\n\");\ndfw.write(\"    spec:\\n\");\ndfw.write(\"      containers:\\n\");\ndfw.write(\"      - resources:\\n\");\ndfw.write(\"        name: \" + name + \"\\n\");\ndfw.write(\"        image: \" + image + \"\\n\");\ndfw.write(\"        ports:\\n\");\ndfw.write(\"        - name: port\\n\");\ndfw.write(\"          containerPort: \" + port + \"\\n\");\ndfw.write(\"      imagePullSecrets:\\n\");\ndfw.write(\"      - name: \" + registrysecret + \"\\n\");\ndfw.close();\n\nvar deploy = kubectl + \" create -f \" + deploymentFileName;\nexecute(deploy);\n\nvar deleteService = kubectl + \" delete service \" + name;\nexecute(deleteService);\n\nvar sfw = new FileWriter(serviceFileName);\nsfw.write(\"apiVersion: v1\\n\");\nsfw.write(\"kind: Service\\n\");\nsfw.write(\"metadata:\\n\");\nsfw.write(\"  name: \" + name + \"\\n\");\nsfw.write(\"  labels:\\n\");\nsfw.write(\"    name: \" + name + \"\\n\");\nsfw.write(\"spec:\\n\");\nsfw.write(\"  ports:\\n\");\nsfw.write(\"  - port: \" + clusterPort + \"\\n\");\nsfw.write(\"    targetPort: \" + port + \"\\n\");\nsfw.write(\"    nodePort: \" + nodePort + \"\\n\");\nsfw.write(\"  selector:\\n\");\nsfw.write(\"    name: \" + name + \"\\n\");\nsfw.write(\"  type: NodePort\\n\");\nsfw.close();\n\nvar deployService = kubectl + \" create -f \" + serviceFileName;\nexecute(deployService);\n\nvar testUrl = \"curl --write-out %{http_code} --silent --output /dev/null \" + url + \" --max-time \" + timeout;\nexecute(testUrl);\nwhile ($OUT != \"200\") {\n    $EXEC(\"sleep 1\");\n    execute(testUrl);\n}\n\nfunction execute(command) {\n    $EXEC(command);\n    print($OUT);\n    print($ERR);\n}  This script is available as live template.    That the script can be executed it has to be executable:  chmod 750 start.js",
            "title": "Create JavaScript"
        },
        {
            "location": "/06_Systemtest_ci_step/Setup_test_env/#add-start-test-environment-as-ci-step",
            "text": "This script has to be added to the Jenkins pipeline:    stage \"start test environment\"\n  node {\n    git url: \"https://github.com/robertBrem/BattleApp-StartTestEnv\"\n    sh \"./start.js\"\n  }  Then  Build Now .",
            "title": "Add start test environment as CI step"
        },
        {
            "location": "/06_Systemtest_ci_step/Start_pipeline_on_every_push/",
            "text": "Start the Jenkins pipeline on every push\n\n\nDuring the creation of the Jenkins pipeline we've created a token that we can start the\npipeline automatically. Now we're going to use this hook.\n\n\nDeactivate CSRF\n\n\nIf \nCSRF\n is activated we've \nto create a crumb that have to be transmitted with the token as well. In this example \nI'm simply deactivating CSRF in Jenkins.\n\n\nIn Jenkins select \nManage Jenkins\n \nConfigure Global Security\n and deselect\n\nPrevent Cross Site Request Forgery exploits\n and \nSave\n.\n\n\n\n\nCreate hook in GitHub\n\n\n\n\nIf we are using an own Git repository like GoGs this is working exactly the same!\n\n\n\n\nTo create a webhook in GitHub we first need the Jenkins API token. You can find the \nJenkins token in Jenkins under \nPeople\n \nrob\n (username) \nConfigure\n\n\nShow API Token\n\n\n\n\nOn the project in GitHub go to \nSettings\n \nWebhooks\n \nAdd Webhook\n and enter the \npayload url like this:\n\n\nhttp://rob:[JENKINS:TOKEN]@disruptor.ninja:30180/job/battleapp/build?token=test\n\n\n\n\n\n\nFinally click on \nAdd webhook\n.\n\n\nNow every push on this GitHub repository starts the Jenkins pipeline.",
            "title": "Start pipeline on every push"
        },
        {
            "location": "/06_Systemtest_ci_step/Start_pipeline_on_every_push/#start-the-jenkins-pipeline-on-every-push",
            "text": "During the creation of the Jenkins pipeline we've created a token that we can start the\npipeline automatically. Now we're going to use this hook.",
            "title": "Start the Jenkins pipeline on every push"
        },
        {
            "location": "/06_Systemtest_ci_step/Start_pipeline_on_every_push/#deactivate-csrf",
            "text": "If  CSRF  is activated we've \nto create a crumb that have to be transmitted with the token as well. In this example \nI'm simply deactivating CSRF in Jenkins.  In Jenkins select  Manage Jenkins   Configure Global Security  and deselect Prevent Cross Site Request Forgery exploits  and  Save .",
            "title": "Deactivate CSRF"
        },
        {
            "location": "/06_Systemtest_ci_step/Start_pipeline_on_every_push/#create-hook-in-github",
            "text": "If we are using an own Git repository like GoGs this is working exactly the same!   To create a webhook in GitHub we first need the Jenkins API token. You can find the \nJenkins token in Jenkins under  People   rob  (username)  Configure  Show API Token   On the project in GitHub go to  Settings   Webhooks   Add Webhook  and enter the \npayload url like this:  http://rob:[JENKINS:TOKEN]@disruptor.ninja:30180/job/battleapp/build?token=test   Finally click on  Add webhook .  Now every push on this GitHub repository starts the Jenkins pipeline.",
            "title": "Create hook in GitHub"
        },
        {
            "location": "/06_Systemtest_ci_step/Systemtest/",
            "text": "Add a system test\n\n\nCreate a system test similar to \nthis one\n.  \n\n\nTherefore we need the following dependencies:\n\n\n<dependency>\n    <groupId>junit</groupId>\n    <artifactId>junit</artifactId>\n    <version>4.12</version>\n    <scope>test</scope>\n</dependency>\n<dependency>\n    <groupId>com.airhacks.rulz</groupId>\n    <artifactId>jaxrsclient</artifactId>\n    <version>0.0.1</version>\n    <scope>test</scope>\n</dependency>\n<dependency>\n    <groupId>org.glassfish.jersey.core</groupId>\n    <artifactId>jersey-client</artifactId>\n    <version>2.12</version>\n    <scope>test</scope>\n</dependency>\n\n\n\n\nAnd the following test class:\n\n\npublic class BattleAppIT {\n\n    @Rule\n    public JAXRSClientProvider provider = buildWithURI(\"http://\" + System.getenv(\"HOST\") + \":\" + System.getenv(\"PORT\") + \"/battleapp/resources/users\");\n\n    @Test\n    public void shouldReturn200() throws IOException {\n        Response response = provider\n                .target()\n                .request()\n                .get();\n        assertThat(response.getStatus(), is(200));\n    }\n\n}\n\n\n\n\nThe test can locally be executed with the following command:\n\n\nHOST=localhost PORT=8080 mvn clean install failsafe:integration-test failsafe:verify\n\n\n\n\nInclude the test in the Jenkins pipeline:\n\n\n  stage \"system test\"\n  node {\n    git url: \"https://github.com/robertBrem/BattleApp-ST\"\n    def mvnHome = tool 'M3'\n    sh \"PORT=31080 ${mvnHome}/bin/mvn clean install failsafe:integration-test failsafe:verify\"\n    step([$class: 'JUnitResultArchiver', testResults: '**/target/failsafe-reports/TEST-*.xml'])\n  }\n\n\n\n\nThen \nBuild Now\n.",
            "title": "Systemtest"
        },
        {
            "location": "/06_Systemtest_ci_step/Systemtest/#add-a-system-test",
            "text": "Create a system test similar to  this one .    Therefore we need the following dependencies:  <dependency>\n    <groupId>junit</groupId>\n    <artifactId>junit</artifactId>\n    <version>4.12</version>\n    <scope>test</scope>\n</dependency>\n<dependency>\n    <groupId>com.airhacks.rulz</groupId>\n    <artifactId>jaxrsclient</artifactId>\n    <version>0.0.1</version>\n    <scope>test</scope>\n</dependency>\n<dependency>\n    <groupId>org.glassfish.jersey.core</groupId>\n    <artifactId>jersey-client</artifactId>\n    <version>2.12</version>\n    <scope>test</scope>\n</dependency>  And the following test class:  public class BattleAppIT {\n\n    @Rule\n    public JAXRSClientProvider provider = buildWithURI(\"http://\" + System.getenv(\"HOST\") + \":\" + System.getenv(\"PORT\") + \"/battleapp/resources/users\");\n\n    @Test\n    public void shouldReturn200() throws IOException {\n        Response response = provider\n                .target()\n                .request()\n                .get();\n        assertThat(response.getStatus(), is(200));\n    }\n\n}  The test can locally be executed with the following command:  HOST=localhost PORT=8080 mvn clean install failsafe:integration-test failsafe:verify  Include the test in the Jenkins pipeline:    stage \"system test\"\n  node {\n    git url: \"https://github.com/robertBrem/BattleApp-ST\"\n    def mvnHome = tool 'M3'\n    sh \"PORT=31080 ${mvnHome}/bin/mvn clean install failsafe:integration-test failsafe:verify\"\n    step([$class: 'JUnitResultArchiver', testResults: '**/target/failsafe-reports/TEST-*.xml'])\n  }  Then  Build Now .",
            "title": "Add a system test"
        },
        {
            "location": "/07_UI_test/README/",
            "text": "UI Test\n\n\nCreate a UI test similar to \nthis one\n.\n\n\nTherefore we need the following dependencies:\n\n\n<dependency>\n    <groupId>org.jboss.arquillian.junit</groupId>\n    <artifactId>arquillian-junit-container</artifactId>\n    <scope>test</scope>\n</dependency>\n<dependency>\n    <groupId>org.jboss.arquillian.graphene</groupId>\n    <artifactId>arquillian-graphene</artifactId>\n    <type>pom</type>\n    <version>2.1.0.Alpha3</version>\n    <scope>test</scope>\n</dependency>\n<dependency>\n    <groupId>junit</groupId>\n    <artifactId>junit</artifactId>\n    <version>4.12</version>\n    <scope>test</scope>\n</dependency>\n\n\n\n\nAnd the following test classes:\n\n\n@Location(\"http://disruptor.ninja:31080/battleapp/resources/users\")\npublic class BattleAppPage {\n}\n\n\n\n\n@RunAsClient\n@RunWith(Arquillian.class)\npublic class BattleAppIT {\n\n    @Drone\n    WebDriver browser;\n\n    @Test\n    public void shouldContainRobert(@InitialPage BattleAppPage page) {\n        String expectedToContain = \"Rob\";\n        String content = browser.getPageSource();\n        assertThat(content, containsString(expectedToContain));\n    }\n\n}\n\n\n\n\nIntelliJ thinks every Arquillian class needs a \n@Deployment\n method. That's\nnot true. Therefore we've to disable this setting.\n\n\nFile -> Settings...\n \nEditor -> Inspections\n \n\n\n\n\nWhen you try to run the test IntelliJ expects an Arquillian configuration.\nWe create an empty \nManual container configuration\n.\n\n\n\n\nAnd select this configuration for our test.\n\n\n\n\nInclude the test in the Jenkins pipeline:\n\n\n  stage \"ui test\"\n  node {\n    git url: \"https://github.com/robertBrem/BattleApp-UIT\"\n    def mvnHome = tool 'M3'\n    sh \"${mvnHome}/bin/mvn clean install failsafe:integration-test failsafe:verify\"\n    step([$class: 'JUnitResultArchiver', testResults: '**/target/failsafe-reports/TEST-*.xml'])\n  }\n\n\n\n\nThen \nBuild Now\n.",
            "title": "README"
        },
        {
            "location": "/07_UI_test/README/#ui-test",
            "text": "Create a UI test similar to  this one .  Therefore we need the following dependencies:  <dependency>\n    <groupId>org.jboss.arquillian.junit</groupId>\n    <artifactId>arquillian-junit-container</artifactId>\n    <scope>test</scope>\n</dependency>\n<dependency>\n    <groupId>org.jboss.arquillian.graphene</groupId>\n    <artifactId>arquillian-graphene</artifactId>\n    <type>pom</type>\n    <version>2.1.0.Alpha3</version>\n    <scope>test</scope>\n</dependency>\n<dependency>\n    <groupId>junit</groupId>\n    <artifactId>junit</artifactId>\n    <version>4.12</version>\n    <scope>test</scope>\n</dependency>  And the following test classes:  @Location(\"http://disruptor.ninja:31080/battleapp/resources/users\")\npublic class BattleAppPage {\n}  @RunAsClient\n@RunWith(Arquillian.class)\npublic class BattleAppIT {\n\n    @Drone\n    WebDriver browser;\n\n    @Test\n    public void shouldContainRobert(@InitialPage BattleAppPage page) {\n        String expectedToContain = \"Rob\";\n        String content = browser.getPageSource();\n        assertThat(content, containsString(expectedToContain));\n    }\n\n}  IntelliJ thinks every Arquillian class needs a  @Deployment  method. That's\nnot true. Therefore we've to disable this setting.  File -> Settings...   Editor -> Inspections     When you try to run the test IntelliJ expects an Arquillian configuration.\nWe create an empty  Manual container configuration .   And select this configuration for our test.   Include the test in the Jenkins pipeline:    stage \"ui test\"\n  node {\n    git url: \"https://github.com/robertBrem/BattleApp-UIT\"\n    def mvnHome = tool 'M3'\n    sh \"${mvnHome}/bin/mvn clean install failsafe:integration-test failsafe:verify\"\n    step([$class: 'JUnitResultArchiver', testResults: '**/target/failsafe-reports/TEST-*.xml'])\n  }  Then  Build Now .",
            "title": "UI Test"
        },
        {
            "location": "/08_Lasttest/README/",
            "text": "Lasttest\n\n\nWe're going to use JMeter for our last tests.\n\n\nInstall JMeter\n\n\nInstall JMeter on your local machine.\n\n\nsudo apt-get install jmeter -y\n\n\n\n\nCreate a JMeter test in JMeter\n\n\nStart JMeter.\n\n\njmeter\n\n\n\n\nRight click on \nTest Plan\n \nAdd -> Threads (Users) -> Thread Group\n.\n\n\n\n\nMake the following settings:\n\n\nNumber of Threads (users):\n \n5\n\n\nRamp-Up Period (in seconds):\n \n1\n\n\nLoop Count:\n \n100\n  \n\n\n\n\nRight click on \nThread Group\n \nAdd -> Sampler -> HTTP Request\n.\n\n\n\n\nMake the following settings:\n\n\nServer Name or IP:\n \ndisruptor.ninja\n\n\nPort Number:\n \n31080\n\n\nPath:\n \n/battleapp/resources/users\n  \n\n\n\n\nRight click on \nThread Group\n \nAdd -> Listener -> Summary Report\n\n\n\n\nClick on \n.\n\nSave the run in \ntest.jmx\n.\n\n\n\n\nCreate last test project\n\n\nCreate a last test similar to \nthis one\n.\n\n\nMove the \ntest.jmx\n file in this folder \n/src/test/jmeter/test.jmx\n.  \n\n\nParametrize the \ntest.jmx\n file. The syntax is:\n\n\n${__property(host)}\n\n\n\n\nAdd the following Maven settings:\n\n\n<build>\n    <finalName>battleapp.lt</finalName>\n    <plugins>\n        <plugin>\n            <groupId>com.lazerycode.jmeter</groupId>\n            <artifactId>jmeter-maven-plugin</artifactId>\n            <version>2.0.3</version>\n            <configuration>\n                <propertiesUser>\n                    <host>${performancetest.webservice.host}</host>\n                    <port>${performancetest.webservice.port}</port>\n                    <iterations>${performancetest.webservice.iterations}</iterations>\n                    <threads>${performancetest.webservice.threads}</threads>\n                    <url>${performancetest.webservice.url}</url>\n                </propertiesUser>\n            </configuration>\n            <executions>\n                <execution>\n                    <id>jmeter-tests</id>\n                    <goals>\n                        <goal>jmeter</goal>\n                    </goals>\n                </execution>\n            </executions>\n        </plugin>\n        <plugin>\n            <groupId>com.lazerycode.jmeter</groupId>\n            <artifactId>jmeter-analysis-maven-plugin</artifactId>\n            <version>1.0.6</version>\n            <executions>\n                <execution>\n                    <goals>\n                        <goal>analyze</goal>\n                    </goals>\n                    <phase>post-integration-test</phase>\n                </execution>\n            </executions>\n            <configuration>\n                <source>${project.build.directory}/jmeter/results/*</source>\n                <targetDirectory>${project.build.directory}/reports</targetDirectory>\n            </configuration>\n        </plugin>\n    </plugins>\n</build>\n<properties>\n    <maven.compiler.source>1.8</maven.compiler.source>\n    <maven.compiler.target>1.8</maven.compiler.target>\n    <failOnMissingWebXml>false</failOnMissingWebXml>\n    <performancetest.webservice.host>ninja.disruptor</performancetest.webservice.host>\n    <performancetest.webservice.port>31080</performancetest.webservice.port>\n    <performancetest.webservice.iterations>31080</performancetest.webservice.iterations>\n    <performancetest.webservice.threads>31080</performancetest.webservice.threads>\n    <performancetest.webservice.url>/battleapp/resources/health</performancetest.webservice.url>\n</properties>\n\n\n\n\nStart Maven with the parameters set:\n\n\nmvn clean verify -Dperformancetest.webservice.host=localhost -Dperformancetest.webservice.port=8080 -Dperformancetest.webservice.threads=2 -Dperformancetest.webservice.iterations=50 -Dperformancetest.webservice.url=/battleapp/resources/users\n\n\n\n\nCreate the Jenkins pipeline step\n\n\nInclude the test in the Jenkins pipeline:\n\n\n  stage \"last test\"\n  node {\n    git url: \"https://github.com/robertBrem/BattleApp-LT\"\n    def mvnHome = tool 'M3'\n    sh \"${mvnHome}/bin/mvn clean verify -Dperformancetest.webservice.host=disruptor.ninja -Dperformancetest.webservice.port=31080 -Dperformancetest.webservice.threads=5 -Dperformancetest.webservice.iterations=500 -Dperformancetest.webservice.url=/battleapp/resources/users\"\n    archiveArtifacts artifacts: 'target/reports/*.*', fingerprint: true\n  }\n\n\n\n\nThen \nBuild Now\n.",
            "title": "README"
        },
        {
            "location": "/08_Lasttest/README/#lasttest",
            "text": "We're going to use JMeter for our last tests.",
            "title": "Lasttest"
        },
        {
            "location": "/08_Lasttest/README/#install-jmeter",
            "text": "Install JMeter on your local machine.  sudo apt-get install jmeter -y",
            "title": "Install JMeter"
        },
        {
            "location": "/08_Lasttest/README/#create-a-jmeter-test-in-jmeter",
            "text": "Start JMeter.  jmeter  Right click on  Test Plan   Add -> Threads (Users) -> Thread Group .   Make the following settings:  Number of Threads (users):   5  Ramp-Up Period (in seconds):   1  Loop Count:   100      Right click on  Thread Group   Add -> Sampler -> HTTP Request .   Make the following settings:  Server Name or IP:   disruptor.ninja  Port Number:   31080  Path:   /battleapp/resources/users      Right click on  Thread Group   Add -> Listener -> Summary Report   Click on  . \nSave the run in  test.jmx .",
            "title": "Create a JMeter test in JMeter"
        },
        {
            "location": "/08_Lasttest/README/#create-last-test-project",
            "text": "Create a last test similar to  this one .  Move the  test.jmx  file in this folder  /src/test/jmeter/test.jmx .    Parametrize the  test.jmx  file. The syntax is:  ${__property(host)}  Add the following Maven settings:  <build>\n    <finalName>battleapp.lt</finalName>\n    <plugins>\n        <plugin>\n            <groupId>com.lazerycode.jmeter</groupId>\n            <artifactId>jmeter-maven-plugin</artifactId>\n            <version>2.0.3</version>\n            <configuration>\n                <propertiesUser>\n                    <host>${performancetest.webservice.host}</host>\n                    <port>${performancetest.webservice.port}</port>\n                    <iterations>${performancetest.webservice.iterations}</iterations>\n                    <threads>${performancetest.webservice.threads}</threads>\n                    <url>${performancetest.webservice.url}</url>\n                </propertiesUser>\n            </configuration>\n            <executions>\n                <execution>\n                    <id>jmeter-tests</id>\n                    <goals>\n                        <goal>jmeter</goal>\n                    </goals>\n                </execution>\n            </executions>\n        </plugin>\n        <plugin>\n            <groupId>com.lazerycode.jmeter</groupId>\n            <artifactId>jmeter-analysis-maven-plugin</artifactId>\n            <version>1.0.6</version>\n            <executions>\n                <execution>\n                    <goals>\n                        <goal>analyze</goal>\n                    </goals>\n                    <phase>post-integration-test</phase>\n                </execution>\n            </executions>\n            <configuration>\n                <source>${project.build.directory}/jmeter/results/*</source>\n                <targetDirectory>${project.build.directory}/reports</targetDirectory>\n            </configuration>\n        </plugin>\n    </plugins>\n</build>\n<properties>\n    <maven.compiler.source>1.8</maven.compiler.source>\n    <maven.compiler.target>1.8</maven.compiler.target>\n    <failOnMissingWebXml>false</failOnMissingWebXml>\n    <performancetest.webservice.host>ninja.disruptor</performancetest.webservice.host>\n    <performancetest.webservice.port>31080</performancetest.webservice.port>\n    <performancetest.webservice.iterations>31080</performancetest.webservice.iterations>\n    <performancetest.webservice.threads>31080</performancetest.webservice.threads>\n    <performancetest.webservice.url>/battleapp/resources/health</performancetest.webservice.url>\n</properties>  Start Maven with the parameters set:  mvn clean verify -Dperformancetest.webservice.host=localhost -Dperformancetest.webservice.port=8080 -Dperformancetest.webservice.threads=2 -Dperformancetest.webservice.iterations=50 -Dperformancetest.webservice.url=/battleapp/resources/users",
            "title": "Create last test project"
        },
        {
            "location": "/08_Lasttest/README/#create-the-jenkins-pipeline-step",
            "text": "Include the test in the Jenkins pipeline:    stage \"last test\"\n  node {\n    git url: \"https://github.com/robertBrem/BattleApp-LT\"\n    def mvnHome = tool 'M3'\n    sh \"${mvnHome}/bin/mvn clean verify -Dperformancetest.webservice.host=disruptor.ninja -Dperformancetest.webservice.port=31080 -Dperformancetest.webservice.threads=5 -Dperformancetest.webservice.iterations=500 -Dperformancetest.webservice.url=/battleapp/resources/users\"\n    archiveArtifacts artifacts: 'target/reports/*.*', fingerprint: true\n  }  Then  Build Now .",
            "title": "Create the Jenkins pipeline step"
        },
        {
            "location": "/09_Manual_test/README/",
            "text": "Create manual test\n\n\nBefore a version is going into production the version is normally tested manually.\nWe can create a manual testing step in our Jenkins pipeline as well:\n\n\n  stage \"manual testing\"\n  input \"everything ok?\"\n\n\n\n\nThen \nBuild Now\n.",
            "title": "README"
        },
        {
            "location": "/09_Manual_test/README/#create-manual-test",
            "text": "Before a version is going into production the version is normally tested manually.\nWe can create a manual testing step in our Jenkins pipeline as well:    stage \"manual testing\"\n  input \"everything ok?\"  Then  Build Now .",
            "title": "Create manual test"
        },
        {
            "location": "/10_Canary_release/README/",
            "text": "Create a canary release\n\n\nTo test the new version in production for example with A/B testing we need the possibility\nto make a canary release.\n\n\nCreate JavaScript\n\n\nLike the start of the test environment we start the canary with JavaScript.\n\n\n#!/usr/bin/jjs -fv\n\nvar FileWriter = Java.type(\"java.io.FileWriter\");\n\nvar version = $ENV.VERSION;\nvar kubectl = $ENV.KUBECTL;\n\nvar name = \"battleapp\";\nvar nameWithVersion = name + \"-\" + version;\nvar image = \"disruptor.ninja:30500/robertbrem/battleapp:\" + version;\nvar replicas = 1;\nvar port = 8080;\nvar clusterPort = 8880;\nvar nodePort = 30080;\nvar deploymentFileName = \"deployment.yml\";\nvar serviceFileName = \"service.yml\";\nvar registrysecret = \"registrykey\";\nvar url = \"http://disruptor.ninja:\" + nodePort + \"/battleapp/resources/users\";\nvar timeout = 2;\n\nvar dfw = new FileWriter(deploymentFileName);\ndfw.write(\"apiVersion: extensions/v1beta1\\n\");\ndfw.write(\"kind: Deployment\\n\");\ndfw.write(\"metadata:\\n\");\ndfw.write(\"  name: \" + nameWithVersion + \"\\n\");\ndfw.write(\"spec:\\n\");\ndfw.write(\"  replicas: \" + replicas + \"\\n\");\ndfw.write(\"  template:\\n\");\ndfw.write(\"    metadata:\\n\");\ndfw.write(\"      labels:\\n\");\ndfw.write(\"        name: \" + name + \"\\n\");\ndfw.write(\"        version: \" + version + \"\\n\");\ndfw.write(\"    spec:\\n\");\ndfw.write(\"      containers:\\n\");\ndfw.write(\"      - resources:\\n\");\ndfw.write(\"        name: \" + name + \"\\n\");\ndfw.write(\"        image: \" + image + \"\\n\");\ndfw.write(\"        ports:\\n\");\ndfw.write(\"        - name: port\\n\");\ndfw.write(\"          containerPort: \" + port + \"\\n\");\ndfw.write(\"      imagePullSecrets:\\n\");\ndfw.write(\"      - name: \" + registrysecret + \"\\n\");\ndfw.close();\n\nvar deploy = kubectl + \" create -f \" + deploymentFileName;\nexecute(deploy);\n\nvar sfw = new FileWriter(serviceFileName);\nsfw.write(\"apiVersion: v1\\n\");\nsfw.write(\"kind: Service\\n\");\nsfw.write(\"metadata:\\n\");\nsfw.write(\"  name: \" + name + \"\\n\");\nsfw.write(\"  labels:\\n\");\nsfw.write(\"    name: \" + name + \"\\n\");\nsfw.write(\"spec:\\n\");\nsfw.write(\"  ports:\\n\");\nsfw.write(\"  - port: \" + clusterPort + \"\\n\");\nsfw.write(\"    targetPort: \" + port + \"\\n\");\nsfw.write(\"    nodePort: \" + nodePort + \"\\n\");\nsfw.write(\"  selector:\\n\");\nsfw.write(\"    name: \" + name + \"\\n\");\nsfw.write(\"  type: NodePort\\n\");\nsfw.close();\n\nvar deployService = kubectl + \" create -f \" + serviceFileName;\nexecute(deployService);\n\nvar testUrl = \"curl --write-out %{http_code} --silent --output /dev/null \" + url + \" --max-time \" + timeout;\nexecute(testUrl);\nwhile ($OUT != \"200\") {\n    $EXEC(\"sleep 1\");\n    execute(testUrl);\n}\n\nfunction execute(command) {\n    $EXEC(command);\n    print($OUT);\n    print($ERR);\n}\n\n\n\n\nThat the script can be executed it has to be executable:\n\n\nchmod 750 start.js\n\n\n\n\nAdd the canary release as CI step\n\n\nThis script has to be added to the Jenkins pipeline:\n\n\n  stage \"start canary\"\n  input \"deploy the canary?\"\n  node {\n    git url: \"https://github.com/robertBrem/BattleApp-Canary\"\n    sh \"./start.js\"\n  }\n\n\n\n\nThen \nBuild Now\n.\n\n\nTest the canary release\n\n\nAfter the first canary release we can check our cluster. It should look something like\nthis:\n\n\nkc get deployment\n\n\n\n\nNAME               DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE\nbattleapp-1.0.17   1         1         1            1           10m\nbattleapp-test     1         1         1            1           12m\njenkins            1         1         1            1           15h\nregistry           1         1         1            1           20h\n\n\n\n\nkc get pod\n\n\n\n\nNAME                                READY     STATUS    RESTARTS   AGE\nbattleapp-1.0.17-3230326404-2xvxb   1/1       Running   0          9m\nbattleapp-test-1930419673-78jpf     1/1       Running   0          13m\njenkins-3074977187-rcg1v            1/1       Running   0          15h\nregistry-95525520-9rdvc             1/1       Running   0          20h\n\n\n\n\nAn impressive way to test a canary release is to change the REST service and push the\nchange.\n\n\nThen you can open a terminal and execute this script to see the change:\n\n\nwhile true; do curl http://disruptor.ninja:30080/battleapp/resources/users; echo \"\"; sleep 1; done\n\n\n\n\nAfter the canary release of the changed service the output look something like this:\n\n\n[{\"name\":\"Robert\"},{\"name\":\"Kevin\"},{\"name\":\"Dan\"}]\n[{\"name\":\"dan\"},{\"name\":\"robert\"},{\"name\":\"kevin\"}]\n[{\"name\":\"Robert\"},{\"name\":\"Kevin\"},{\"name\":\"Dan\"}]\n[{\"name\":\"dan\"},{\"name\":\"robert\"},{\"name\":\"kevin\"}]\n[{\"name\":\"dan\"},{\"name\":\"robert\"},{\"name\":\"kevin\"}]\n[{\"name\":\"dan\"},{\"name\":\"robert\"},{\"name\":\"kevin\"}]\n[{\"name\":\"Robert\"},{\"name\":\"Kevin\"},{\"name\":\"Dan\"}]\n[{\"name\":\"Robert\"},{\"name\":\"Kevin\"},{\"name\":\"Dan\"}]\n[{\"name\":\"Robert\"},{\"name\":\"Kevin\"},{\"name\":\"Dan\"}]\n\n\n\n\nThe cluster is now looking something like this:\n\n\nkc get pod\n\n\n\n\nNAME                                READY     STATUS    RESTARTS   AGE\nbattleapp-1.0.17-3230326404-2xvxb   1/1       Running   0          19m\nbattleapp-1.0.18-3418480262-5n1d7   1/1       Running   0          2m\nbattleapp-test-2013584858-kq2bg     1/1       Running   0          4m\njenkins-3074977187-rcg1v            1/1       Running   0          15h\nregistry-95525520-9rdvc             1/1       Running   0          20h\n\n\n\n\nCreate a readiness probe\n\n\nIt can happen that the Kubernetes service is routing requests to the new service\neven if this service is not ready yet and we get \n404\n for a short period. To\nsuppress this behavior we can create a \nreadiness probe\n for our canary deployment:\n\n\nvar dfw = new FileWriter(deploymentFileName);\ndfw.write(\"apiVersion: extensions/v1beta1\\n\");\ndfw.write(\"kind: Deployment\\n\");\ndfw.write(\"metadata:\\n\");\ndfw.write(\"  name: \" + nameWithVersion + \"\\n\");\ndfw.write(\"spec:\\n\");\ndfw.write(\"  replicas: \" + replicas + \"\\n\");\ndfw.write(\"  template:\\n\");\ndfw.write(\"    metadata:\\n\");\ndfw.write(\"      labels:\\n\");\ndfw.write(\"        name: \" + name + \"\\n\");\ndfw.write(\"        version: \" + version + \"\\n\");\ndfw.write(\"    spec:\\n\");\ndfw.write(\"      containers:\\n\");\ndfw.write(\"      - resources:\\n\");\ndfw.write(\"        name: \" + name + \"\\n\");\ndfw.write(\"        image: \" + image + \"\\n\");\ndfw.write(\"        ports:\\n\");\ndfw.write(\"        - name: port\\n\");\ndfw.write(\"          containerPort: \" + port + \"\\n\");\ndfw.write(\"        readinessProbe:\\n\");\ndfw.write(\"          httpGet:\\n\");\ndfw.write(\"            path: \" + relativeUrl + \"\\n\");\ndfw.write(\"            port: \" + port + \"\\n\");\ndfw.write(\"          initialDelaySeconds: \" + initialDelay + \"\\n\");\ndfw.write(\"          timeoutSeconds: \" + readinessProbeTimeout + \"\\n\");\ndfw.write(\"      imagePullSecrets:\\n\");\ndfw.write(\"      - name: \" + registrysecret + \"\\n\");\ndfw.close();\n\n\n\n\nNow there shouldn't be any \n404\n errors.",
            "title": "README"
        },
        {
            "location": "/10_Canary_release/README/#create-a-canary-release",
            "text": "To test the new version in production for example with A/B testing we need the possibility\nto make a canary release.",
            "title": "Create a canary release"
        },
        {
            "location": "/10_Canary_release/README/#create-javascript",
            "text": "Like the start of the test environment we start the canary with JavaScript.  #!/usr/bin/jjs -fv\n\nvar FileWriter = Java.type(\"java.io.FileWriter\");\n\nvar version = $ENV.VERSION;\nvar kubectl = $ENV.KUBECTL;\n\nvar name = \"battleapp\";\nvar nameWithVersion = name + \"-\" + version;\nvar image = \"disruptor.ninja:30500/robertbrem/battleapp:\" + version;\nvar replicas = 1;\nvar port = 8080;\nvar clusterPort = 8880;\nvar nodePort = 30080;\nvar deploymentFileName = \"deployment.yml\";\nvar serviceFileName = \"service.yml\";\nvar registrysecret = \"registrykey\";\nvar url = \"http://disruptor.ninja:\" + nodePort + \"/battleapp/resources/users\";\nvar timeout = 2;\n\nvar dfw = new FileWriter(deploymentFileName);\ndfw.write(\"apiVersion: extensions/v1beta1\\n\");\ndfw.write(\"kind: Deployment\\n\");\ndfw.write(\"metadata:\\n\");\ndfw.write(\"  name: \" + nameWithVersion + \"\\n\");\ndfw.write(\"spec:\\n\");\ndfw.write(\"  replicas: \" + replicas + \"\\n\");\ndfw.write(\"  template:\\n\");\ndfw.write(\"    metadata:\\n\");\ndfw.write(\"      labels:\\n\");\ndfw.write(\"        name: \" + name + \"\\n\");\ndfw.write(\"        version: \" + version + \"\\n\");\ndfw.write(\"    spec:\\n\");\ndfw.write(\"      containers:\\n\");\ndfw.write(\"      - resources:\\n\");\ndfw.write(\"        name: \" + name + \"\\n\");\ndfw.write(\"        image: \" + image + \"\\n\");\ndfw.write(\"        ports:\\n\");\ndfw.write(\"        - name: port\\n\");\ndfw.write(\"          containerPort: \" + port + \"\\n\");\ndfw.write(\"      imagePullSecrets:\\n\");\ndfw.write(\"      - name: \" + registrysecret + \"\\n\");\ndfw.close();\n\nvar deploy = kubectl + \" create -f \" + deploymentFileName;\nexecute(deploy);\n\nvar sfw = new FileWriter(serviceFileName);\nsfw.write(\"apiVersion: v1\\n\");\nsfw.write(\"kind: Service\\n\");\nsfw.write(\"metadata:\\n\");\nsfw.write(\"  name: \" + name + \"\\n\");\nsfw.write(\"  labels:\\n\");\nsfw.write(\"    name: \" + name + \"\\n\");\nsfw.write(\"spec:\\n\");\nsfw.write(\"  ports:\\n\");\nsfw.write(\"  - port: \" + clusterPort + \"\\n\");\nsfw.write(\"    targetPort: \" + port + \"\\n\");\nsfw.write(\"    nodePort: \" + nodePort + \"\\n\");\nsfw.write(\"  selector:\\n\");\nsfw.write(\"    name: \" + name + \"\\n\");\nsfw.write(\"  type: NodePort\\n\");\nsfw.close();\n\nvar deployService = kubectl + \" create -f \" + serviceFileName;\nexecute(deployService);\n\nvar testUrl = \"curl --write-out %{http_code} --silent --output /dev/null \" + url + \" --max-time \" + timeout;\nexecute(testUrl);\nwhile ($OUT != \"200\") {\n    $EXEC(\"sleep 1\");\n    execute(testUrl);\n}\n\nfunction execute(command) {\n    $EXEC(command);\n    print($OUT);\n    print($ERR);\n}  That the script can be executed it has to be executable:  chmod 750 start.js",
            "title": "Create JavaScript"
        },
        {
            "location": "/10_Canary_release/README/#add-the-canary-release-as-ci-step",
            "text": "This script has to be added to the Jenkins pipeline:    stage \"start canary\"\n  input \"deploy the canary?\"\n  node {\n    git url: \"https://github.com/robertBrem/BattleApp-Canary\"\n    sh \"./start.js\"\n  }  Then  Build Now .",
            "title": "Add the canary release as CI step"
        },
        {
            "location": "/10_Canary_release/README/#test-the-canary-release",
            "text": "After the first canary release we can check our cluster. It should look something like\nthis:  kc get deployment  NAME               DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE\nbattleapp-1.0.17   1         1         1            1           10m\nbattleapp-test     1         1         1            1           12m\njenkins            1         1         1            1           15h\nregistry           1         1         1            1           20h  kc get pod  NAME                                READY     STATUS    RESTARTS   AGE\nbattleapp-1.0.17-3230326404-2xvxb   1/1       Running   0          9m\nbattleapp-test-1930419673-78jpf     1/1       Running   0          13m\njenkins-3074977187-rcg1v            1/1       Running   0          15h\nregistry-95525520-9rdvc             1/1       Running   0          20h  An impressive way to test a canary release is to change the REST service and push the\nchange.  Then you can open a terminal and execute this script to see the change:  while true; do curl http://disruptor.ninja:30080/battleapp/resources/users; echo \"\"; sleep 1; done  After the canary release of the changed service the output look something like this:  [{\"name\":\"Robert\"},{\"name\":\"Kevin\"},{\"name\":\"Dan\"}]\n[{\"name\":\"dan\"},{\"name\":\"robert\"},{\"name\":\"kevin\"}]\n[{\"name\":\"Robert\"},{\"name\":\"Kevin\"},{\"name\":\"Dan\"}]\n[{\"name\":\"dan\"},{\"name\":\"robert\"},{\"name\":\"kevin\"}]\n[{\"name\":\"dan\"},{\"name\":\"robert\"},{\"name\":\"kevin\"}]\n[{\"name\":\"dan\"},{\"name\":\"robert\"},{\"name\":\"kevin\"}]\n[{\"name\":\"Robert\"},{\"name\":\"Kevin\"},{\"name\":\"Dan\"}]\n[{\"name\":\"Robert\"},{\"name\":\"Kevin\"},{\"name\":\"Dan\"}]\n[{\"name\":\"Robert\"},{\"name\":\"Kevin\"},{\"name\":\"Dan\"}]  The cluster is now looking something like this:  kc get pod  NAME                                READY     STATUS    RESTARTS   AGE\nbattleapp-1.0.17-3230326404-2xvxb   1/1       Running   0          19m\nbattleapp-1.0.18-3418480262-5n1d7   1/1       Running   0          2m\nbattleapp-test-2013584858-kq2bg     1/1       Running   0          4m\njenkins-3074977187-rcg1v            1/1       Running   0          15h\nregistry-95525520-9rdvc             1/1       Running   0          20h",
            "title": "Test the canary release"
        },
        {
            "location": "/10_Canary_release/README/#create-a-readiness-probe",
            "text": "It can happen that the Kubernetes service is routing requests to the new service\neven if this service is not ready yet and we get  404  for a short period. To\nsuppress this behavior we can create a  readiness probe  for our canary deployment:  var dfw = new FileWriter(deploymentFileName);\ndfw.write(\"apiVersion: extensions/v1beta1\\n\");\ndfw.write(\"kind: Deployment\\n\");\ndfw.write(\"metadata:\\n\");\ndfw.write(\"  name: \" + nameWithVersion + \"\\n\");\ndfw.write(\"spec:\\n\");\ndfw.write(\"  replicas: \" + replicas + \"\\n\");\ndfw.write(\"  template:\\n\");\ndfw.write(\"    metadata:\\n\");\ndfw.write(\"      labels:\\n\");\ndfw.write(\"        name: \" + name + \"\\n\");\ndfw.write(\"        version: \" + version + \"\\n\");\ndfw.write(\"    spec:\\n\");\ndfw.write(\"      containers:\\n\");\ndfw.write(\"      - resources:\\n\");\ndfw.write(\"        name: \" + name + \"\\n\");\ndfw.write(\"        image: \" + image + \"\\n\");\ndfw.write(\"        ports:\\n\");\ndfw.write(\"        - name: port\\n\");\ndfw.write(\"          containerPort: \" + port + \"\\n\");\ndfw.write(\"        readinessProbe:\\n\");\ndfw.write(\"          httpGet:\\n\");\ndfw.write(\"            path: \" + relativeUrl + \"\\n\");\ndfw.write(\"            port: \" + port + \"\\n\");\ndfw.write(\"          initialDelaySeconds: \" + initialDelay + \"\\n\");\ndfw.write(\"          timeoutSeconds: \" + readinessProbeTimeout + \"\\n\");\ndfw.write(\"      imagePullSecrets:\\n\");\ndfw.write(\"      - name: \" + registrysecret + \"\\n\");\ndfw.close();  Now there shouldn't be any  404  errors.",
            "title": "Create a readiness probe"
        },
        {
            "location": "/11_Full_production_release/README/",
            "text": "Go full production with the new version\n\n\nAfter the tests on production we're ready to go full production with the new version.\n\n\nCreate JavaScript\n\n\nLike the canary release we start the full production step with JavaScript.\n\n\n#!/usr/bin/jjs -fv\n\nvar version = $ENV.VERSION;\nvar kubectl = $ENV.KUBECTL;\n\nvar name = \"battleapp\";\nvar url = \"http://disruptor.ninja:30080/battleapp/resources/users\";\nvar timeout = 2;\n\nvar deleteDeployment = kubectl + \" delete deployment -l name=\" + name + \",version!=\" + version;\nexecute(deleteDeployment);\n\nvar testUrl = \"curl --write-out %{http_code} --silent --output /dev/null \" + url + \" --max-time \" + timeout;\nexecute(testUrl);\nwhile ($OUT != \"200\") {\n    $EXEC(\"sleep 1\");\n    execute(testUrl);\n}\n\nfunction execute(command) {\n    $EXEC(command);\n    print($OUT);\n    print($ERR);\n}\n\n\n\n\nThat the script can be executed it has to be executable:\n\n\nchmod 750 start.js\n\n\n\n\nAdd the full production release as CI step\n\n\nThis script has to be added to the Jenkins pipeline:\n\n\n  stage \"go full production\"\n  input \"undeploy other versions?\"\n  node {\n    git url: \"https://github.com/robertBrem/BattleApp-Prod\"\n    sh \"./start.js\"\n  }\n\n\n\n\nThen \nBuild Now\n.",
            "title": "README"
        },
        {
            "location": "/11_Full_production_release/README/#go-full-production-with-the-new-version",
            "text": "After the tests on production we're ready to go full production with the new version.",
            "title": "Go full production with the new version"
        },
        {
            "location": "/11_Full_production_release/README/#create-javascript",
            "text": "Like the canary release we start the full production step with JavaScript.  #!/usr/bin/jjs -fv\n\nvar version = $ENV.VERSION;\nvar kubectl = $ENV.KUBECTL;\n\nvar name = \"battleapp\";\nvar url = \"http://disruptor.ninja:30080/battleapp/resources/users\";\nvar timeout = 2;\n\nvar deleteDeployment = kubectl + \" delete deployment -l name=\" + name + \",version!=\" + version;\nexecute(deleteDeployment);\n\nvar testUrl = \"curl --write-out %{http_code} --silent --output /dev/null \" + url + \" --max-time \" + timeout;\nexecute(testUrl);\nwhile ($OUT != \"200\") {\n    $EXEC(\"sleep 1\");\n    execute(testUrl);\n}\n\nfunction execute(command) {\n    $EXEC(command);\n    print($OUT);\n    print($ERR);\n}  That the script can be executed it has to be executable:  chmod 750 start.js",
            "title": "Create JavaScript"
        },
        {
            "location": "/11_Full_production_release/README/#add-the-full-production-release-as-ci-step",
            "text": "This script has to be added to the Jenkins pipeline:    stage \"go full production\"\n  input \"undeploy other versions?\"\n  node {\n    git url: \"https://github.com/robertBrem/BattleApp-Prod\"\n    sh \"./start.js\"\n  }  Then  Build Now .",
            "title": "Add the full production release as CI step"
        },
        {
            "location": "/12_Own_Gogs/README/",
            "text": "Use your own Git repository\n\n\nI prefer complex systems over complicated systems therefore I create a lot of repositories.\nIf you don't want to spam your GitHub account you can easily create an own \n\nGoGs repository\n.\n\n\nCreate folders for the persistence\n\n\nThe GoGs repository has persistent data therefore we've to mount this data somewhere.\nThe easiest way to do that is over a node selector. A more advanced solution would be\nto use GlusterFS, Flocker, NFS or something similar.\n\n\nIf we use node selectors for our persistence then we've to log in to the server\nwe want to persist the GoGs data.\n\n\nssh root@5.189.154.24\n\n\n\n\nOn the server we've to create the folder structure that gets mounted to the host.\n\n\nmkdir -p gogs/data\n\n\n\n\nKubernetes deployment\n\n\nTo tell Kubernetes to schedule the GoGs repository pod on specified node we've to \nlabel the node:\n\n\nkc label nodes vmi71992.contabo.host name=vmi71992\n\n\n\n\nNext we create a \ndeployment.yml\n file \nlike this one\n.\n\n\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: gogs\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: gogs\n    spec:\n      containers:\n      - resources:\n        name: gogs\n        image: gogs/gogs:0.9.97\n        ports:\n        - name: gogs-port\n          containerPort: 3000\n        volumeMounts:\n        - mountPath: /data\n          name: data\n      volumes:\n      - name: data\n        hostPath:\n          path: /root/gogs/data\n      nodeSelector:\n        name: vmi71992\n\n\n\n\nThis file has to be deployed:\n\n\nkc create -f deployment.yml\n\n\n\n\nTo test if the deployment is working you can display all pods:\n\n\nkc get po\n\n\n\n\nNAME                      READY     STATUS    RESTARTS   AGE\nregistry-95525520-9rdvc   1/1       Running   0          1m\n\n\n\n\nKubernetes service\n\n\nTo make the repository visible outside the cluster we have to create a Kubernetes service.\nThe \nservice.yml\n file can be created similar to \nthis file\n.\n\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: gogs\n  labels:\n    name: gogs\nspec:\n  ports:\n  - port: 3001\n    targetPort: 3000\n    nodePort: 30130\n  selector:\n    name: gogs\n  type: NodePort\n\n\n\n\nTo test the repository we can call the following url:\n\n\nhttp://disruptor.ninja:30130\n\n\n\n\nDisable register\n\n\nAfter you have created your own user you better should disable the register\nbutton. Otherwise everybody from the internet can create new users and repositories.\nTo disable registration you have to connect to into your Kubernetes pod.\nTo find the correct pod use this command:\n\n\nkc get po | grep gogs\n\n\n\n\ngogs-2819519451-kmpgj                       1/1       Running   0          1h\n\n\n\n\nNow connect into the container inside this pod:\n\n\nkc exec -it gogs-2819519451-kmpgj bash\n\n\n\n\nAnd open the following file:\n\n\nvi /data/gogs/conf/app.ini\n\n\n\n\nSearch for \nDISABLE_REGISTRATION\n set it to \ntrue\n and add \n\nSHOW_REGISTRATION_BUTTON\n:\n\n\nDISABLE_REGISTRATION   = true\nSHOW_REGISTRATION_BUTTON = false\n\n\n\n\nNow kill the running pod. Kubernetes will reschedule the GoGs and start it with\nthe new settings:\n\n\nkc delete pod gogs-2819519451-kmpgj\n\n\n\n\nAfter the restart there is no more register button on the upper right next to\n\nSign In\n.",
            "title": "README"
        },
        {
            "location": "/12_Own_Gogs/README/#use-your-own-git-repository",
            "text": "I prefer complex systems over complicated systems therefore I create a lot of repositories.\nIf you don't want to spam your GitHub account you can easily create an own  GoGs repository .",
            "title": "Use your own Git repository"
        },
        {
            "location": "/12_Own_Gogs/README/#create-folders-for-the-persistence",
            "text": "The GoGs repository has persistent data therefore we've to mount this data somewhere.\nThe easiest way to do that is over a node selector. A more advanced solution would be\nto use GlusterFS, Flocker, NFS or something similar.  If we use node selectors for our persistence then we've to log in to the server\nwe want to persist the GoGs data.  ssh root@5.189.154.24  On the server we've to create the folder structure that gets mounted to the host.  mkdir -p gogs/data",
            "title": "Create folders for the persistence"
        },
        {
            "location": "/12_Own_Gogs/README/#kubernetes-deployment",
            "text": "To tell Kubernetes to schedule the GoGs repository pod on specified node we've to \nlabel the node:  kc label nodes vmi71992.contabo.host name=vmi71992  Next we create a  deployment.yml  file  like this one .  apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: gogs\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: gogs\n    spec:\n      containers:\n      - resources:\n        name: gogs\n        image: gogs/gogs:0.9.97\n        ports:\n        - name: gogs-port\n          containerPort: 3000\n        volumeMounts:\n        - mountPath: /data\n          name: data\n      volumes:\n      - name: data\n        hostPath:\n          path: /root/gogs/data\n      nodeSelector:\n        name: vmi71992  This file has to be deployed:  kc create -f deployment.yml  To test if the deployment is working you can display all pods:  kc get po  NAME                      READY     STATUS    RESTARTS   AGE\nregistry-95525520-9rdvc   1/1       Running   0          1m",
            "title": "Kubernetes deployment"
        },
        {
            "location": "/12_Own_Gogs/README/#kubernetes-service",
            "text": "To make the repository visible outside the cluster we have to create a Kubernetes service.\nThe  service.yml  file can be created similar to  this file .  apiVersion: v1\nkind: Service\nmetadata:\n  name: gogs\n  labels:\n    name: gogs\nspec:\n  ports:\n  - port: 3001\n    targetPort: 3000\n    nodePort: 30130\n  selector:\n    name: gogs\n  type: NodePort  To test the repository we can call the following url:  http://disruptor.ninja:30130",
            "title": "Kubernetes service"
        },
        {
            "location": "/12_Own_Gogs/README/#disable-register",
            "text": "After you have created your own user you better should disable the register\nbutton. Otherwise everybody from the internet can create new users and repositories.\nTo disable registration you have to connect to into your Kubernetes pod.\nTo find the correct pod use this command:  kc get po | grep gogs  gogs-2819519451-kmpgj                       1/1       Running   0          1h  Now connect into the container inside this pod:  kc exec -it gogs-2819519451-kmpgj bash  And open the following file:  vi /data/gogs/conf/app.ini  Search for  DISABLE_REGISTRATION  set it to  true  and add  SHOW_REGISTRATION_BUTTON :  DISABLE_REGISTRATION   = true\nSHOW_REGISTRATION_BUTTON = false  Now kill the running pod. Kubernetes will reschedule the GoGs and start it with\nthe new settings:  kc delete pod gogs-2819519451-kmpgj  After the restart there is no more register button on the upper right next to Sign In .",
            "title": "Disable register"
        },
        {
            "location": "/13_Monitoring/Dashboard/",
            "text": "Kubernetes dashboard\n\n\nTo add a dashboard to your cluster we simple have to execute this command:\n\n\nkc create -f https://rawgit.com/kubernetes/dashboard/master/src/deploy/kubernetes-dashboard.yaml\n\n\n\n\nTo access the dashboard we've to find out the \nNodePort\n of the service.\n\n\nkc describe --namespace kube-system svc kubernetes-dashboard | grep NodePort:\n\n\n\n\nNodePort:       <unset> 31668/TCP\n\n\n\n\nIn this case that's \n31668\n.\n\nNow we can access the dashboard on:\n\n\nhttp://disruptor.ninja:31668\n\n\n\n\n\n\nDon't expose the service over an \nNodePort\n that's a security risk.\n\n\n\n\nAccess the dashboard without exposing it\n\n\nWe can access the dashboard without exposing it. Therefore we've to delete the existing\nservice.\n\n\nkc delete service --namespace kube-system kubernetes-dashboard\n\n\n\n\nThen we've to create a dashboard service without a \nNodePort\n:\n\n\nkind: Service\napiVersion: v1\nmetadata:\n  labels:\n    app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kube-system\nspec:\n  ports:\n  - port: 80\n    targetPort: 9090\n  selector:\n    app: kubernetes-dashboard\n\n\n\n\nNow we can start this service:\n\n\nkc create -f service.yml\n\n\n\n\nTo access the service we've to proxy the internal cluster traffic to localhost:\n\n\nkc proxy\n\n\n\n\nIn the service we've defined the port \n80\n. Therefore we can access the dashboard on:\n\n\nhttp://localhost:8001/ui",
            "title": "Dashboard"
        },
        {
            "location": "/13_Monitoring/Dashboard/#kubernetes-dashboard",
            "text": "To add a dashboard to your cluster we simple have to execute this command:  kc create -f https://rawgit.com/kubernetes/dashboard/master/src/deploy/kubernetes-dashboard.yaml  To access the dashboard we've to find out the  NodePort  of the service.  kc describe --namespace kube-system svc kubernetes-dashboard | grep NodePort:  NodePort:       <unset> 31668/TCP  In this case that's  31668 . \nNow we can access the dashboard on:  http://disruptor.ninja:31668   Don't expose the service over an  NodePort  that's a security risk.",
            "title": "Kubernetes dashboard"
        },
        {
            "location": "/13_Monitoring/Dashboard/#access-the-dashboard-without-exposing-it",
            "text": "We can access the dashboard without exposing it. Therefore we've to delete the existing\nservice.  kc delete service --namespace kube-system kubernetes-dashboard  Then we've to create a dashboard service without a  NodePort :  kind: Service\napiVersion: v1\nmetadata:\n  labels:\n    app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kube-system\nspec:\n  ports:\n  - port: 80\n    targetPort: 9090\n  selector:\n    app: kubernetes-dashboard  Now we can start this service:  kc create -f service.yml  To access the service we've to proxy the internal cluster traffic to localhost:  kc proxy  In the service we've defined the port  80 . Therefore we can access the dashboard on:  http://localhost:8001/ui",
            "title": "Access the dashboard without exposing it"
        },
        {
            "location": "/13_Monitoring/Prometheus/",
            "text": "Monitoring with Prometheus\n\n\nTo monitor your microservices we use Prometheus.\n\n\nTo start Prometheus is pretty simple:\n\n\nkc create -f https://raw.githubusercontent.com/coreos/blog-examples/master/monitoring-kubernetes-with-prometheus/prometheus.yml\n\n\n\n\nTo see the metrics we have create a service:\n\n\nkind: Service\napiVersion: v1\nmetadata:\n  labels:\n    app: prometheus\n  name: prometheus\nspec:\n  ports:\n  - port: 81\n    targetPort: 9090\n    nodePort: 30190\n  selector:\n    app: prometheus\n  type: NodePort\n\n\n\n\nAnd start it:\n\n\nkc create -f service.yml\n\n\n\n\nNow you can open the UI on:\n\n\nhttp://disruptor.ninja:30190",
            "title": "Prometheus"
        },
        {
            "location": "/13_Monitoring/Prometheus/#monitoring-with-prometheus",
            "text": "To monitor your microservices we use Prometheus.  To start Prometheus is pretty simple:  kc create -f https://raw.githubusercontent.com/coreos/blog-examples/master/monitoring-kubernetes-with-prometheus/prometheus.yml  To see the metrics we have create a service:  kind: Service\napiVersion: v1\nmetadata:\n  labels:\n    app: prometheus\n  name: prometheus\nspec:\n  ports:\n  - port: 81\n    targetPort: 9090\n    nodePort: 30190\n  selector:\n    app: prometheus\n  type: NodePort  And start it:  kc create -f service.yml  Now you can open the UI on:  http://disruptor.ninja:30190",
            "title": "Monitoring with Prometheus"
        },
        {
            "location": "/13_Monitoring/README/",
            "text": "Monitoring\n\n\n\n\nKubernetes dashboard\n\n\nMonitoring with Prometheus\n\n\nWeave Scope",
            "title": "README"
        },
        {
            "location": "/13_Monitoring/README/#monitoring",
            "text": "Kubernetes dashboard  Monitoring with Prometheus  Weave Scope",
            "title": "Monitoring"
        },
        {
            "location": "/13_Monitoring/Weave_scope/",
            "text": "Weave Scope\n\n\nAn other visualisation of the cluster is Weave Scope. To start Weave Scope we simple\nhave to start this script:\n\n\nkc apply -f 'https://cloud.weave.works/launch/k8s/weavescope.yaml'\n\n\n\n\nTo access the UI we have to port forward the service on the localhost:\n\n\nkc port-forward $(kc get pod --selector=weave-scope-component=app -o jsonpath='{.items..metadata.name}') 4040\n\n\n\n\nNow we can access the UI on:\n\n\nhttp://localhost:4040",
            "title": "Weave scope"
        },
        {
            "location": "/13_Monitoring/Weave_scope/#weave-scope",
            "text": "An other visualisation of the cluster is Weave Scope. To start Weave Scope we simple\nhave to start this script:  kc apply -f 'https://cloud.weave.works/launch/k8s/weavescope.yaml'  To access the UI we have to port forward the service on the localhost:  kc port-forward $(kc get pod --selector=weave-scope-component=app -o jsonpath='{.items..metadata.name}') 4040  Now we can access the UI on:  http://localhost:4040",
            "title": "Weave Scope"
        },
        {
            "location": "/14_Documentation_of_rest_service/README/",
            "text": "Documentation of the \njax-rs\n service\n\n\nI choose \nswagger\n to document my REST services. Therefore I've to \nactivate CORS headers.\n\n\nAdd CORS headers\n\n\nTo add CORS header to your REST service is pretty simple, just add the folowing dependency\nthat adds a response filter that intercepts every response and add the CORS headers. It\nis just one class without any dependencies.\n\n\n<dependency>\n    <groupId>com.airhacks</groupId>\n    <artifactId>jaxrs-cors</artifactId>\n    <version>0.0.2</version>\n    <scope>compile</scope>\n</dependency>\n\n\n\n\nCreate \nswagger.json\n\n\nFor the creation of the \nswagger.json\n file I use the flowing Maven plugin.\n\n\n<plugin>\n    <groupId>com.sebastian-daschner</groupId>\n    <artifactId>jaxrs-analyzer-maven-plugin</artifactId>\n    <version>0.12</version>\n    <executions>\n        <execution>\n            <goals>\n                <goal>analyze-jaxrs</goal>\n            </goals>\n            <configuration>\n                <!-- Available backends are plaintext (default), swagger and asciidoc -->\n                <backend>swagger</backend>\n                <!-- Domain of the deployed project, defaults to example.com -->\n                <deployedDomain>disruptor.ninja:30080/battleapp</deployedDomain>\n            </configuration>\n        </execution>\n    </executions>\n</plugin>\n\n\n\n\nVisualize \nswagger.json\n\n\nTo visualize the swagger documentation I'm using the swagger editor that I start locally\nin a Docker container:\n\n\ndocker run -d -p 82:8080 --name swagger-editor swaggerapi/swagger-editor\n\n\n\n\nNow I can access the swagger editor under:\n\n\nhttp://localhost:82\n\n\n\n\nAnd copy the content of the generated \nswagger.json\n into left part of the editor.",
            "title": "README"
        },
        {
            "location": "/14_Documentation_of_rest_service/README/#documentation-of-the-jax-rs-service",
            "text": "I choose  swagger  to document my REST services. Therefore I've to \nactivate CORS headers.",
            "title": "Documentation of the jax-rs service"
        },
        {
            "location": "/14_Documentation_of_rest_service/README/#add-cors-headers",
            "text": "To add CORS header to your REST service is pretty simple, just add the folowing dependency\nthat adds a response filter that intercepts every response and add the CORS headers. It\nis just one class without any dependencies.  <dependency>\n    <groupId>com.airhacks</groupId>\n    <artifactId>jaxrs-cors</artifactId>\n    <version>0.0.2</version>\n    <scope>compile</scope>\n</dependency>",
            "title": "Add CORS headers"
        },
        {
            "location": "/14_Documentation_of_rest_service/README/#create-swaggerjson",
            "text": "For the creation of the  swagger.json  file I use the flowing Maven plugin.  <plugin>\n    <groupId>com.sebastian-daschner</groupId>\n    <artifactId>jaxrs-analyzer-maven-plugin</artifactId>\n    <version>0.12</version>\n    <executions>\n        <execution>\n            <goals>\n                <goal>analyze-jaxrs</goal>\n            </goals>\n            <configuration>\n                <!-- Available backends are plaintext (default), swagger and asciidoc -->\n                <backend>swagger</backend>\n                <!-- Domain of the deployed project, defaults to example.com -->\n                <deployedDomain>disruptor.ninja:30080/battleapp</deployedDomain>\n            </configuration>\n        </execution>\n    </executions>\n</plugin>",
            "title": "Create swagger.json"
        },
        {
            "location": "/14_Documentation_of_rest_service/README/#visualize-swaggerjson",
            "text": "To visualize the swagger documentation I'm using the swagger editor that I start locally\nin a Docker container:  docker run -d -p 82:8080 --name swagger-editor swaggerapi/swagger-editor  Now I can access the swagger editor under:  http://localhost:82  And copy the content of the generated  swagger.json  into left part of the editor.",
            "title": "Visualize swagger.json"
        },
        {
            "location": "/15_Angular2_frontend/First_view/",
            "text": "Creation of the first view\n\n\nWe're going to create an own view that displays the users from the REST service.\n\n\nCreation of the template\n\n\nTherefore we create a new folder \nsrc/app/users\n with the following template\n\nusers.component.html\n:\n\n\n<md-input placeholder=\"Nickname\" (keyup)=\"search($event)\"></md-input>\n\n<md-card *ngFor=\"let user of users\">\n  Name: {{ user.name }}\n</md-card>\n\n\n\n\nWe're going to use \nAngular 2 Material\n. \nTherefore we have to install it.\n\n\nnpm install --save @angular/material\n\n\n\n\nIn the \nsrc/app/app.module.ts\n file we've to include Material:\n\n\n...\nimport {MaterialModule} from \"@angular/material\";\n...\nimports: [ // import Angular's modules\n    BrowserModule,\n    FormsModule,\n    HttpModule,\n    MaterialModule.forRoot(),\n    RouterModule.forRoot(ROUTES, {useHash: true, preloadingStrategy: PreloadAllModules})\n  ],\n...\n\n\n\n\nInstall \nhammerjs\n. \n\n\nnpm install --save hammerjs \n\n\n\n\nIn \nsrc/index.html\n add the following line in the header:\n\n\n<link href=\"https://fonts.googleapis.com/icon?family=Material+Icons\" rel=\"stylesheet\">\n\n\n\n\nCreate an empty \nusers.component.css\n file in the same folder as the \nhtml template.\n\n\nCreation of the service\n\n\nFor the service we need a \nuser.ts\n object in the same folder as the \ntemplate files:\n\n\nexport class User {\n  name: string;\n\n  constructor() {\n  }\n\n}\n\n\n\n\nThe next class is the service for the component:\n\n\nimport {Injectable} from \"@angular/core\";\nimport {RequestOptions, Response, Headers, Http} from \"@angular/http\";\nimport {Observable} from \"rxjs\";\nimport {User} from \"./user\";\n\n@Injectable()\nexport class UserService {\n  private environment: Observable<any>;\n\n  constructor(private http: Http) {\n    this.environment = this.http\n      .get('/environment/environment.json')\n      .map(res => res.json());\n  }\n\n  public getUsersUrl(env: any): string {\n    let baseUsersUrl = '/battleapp/';\n    let api: string = 'resources/';\n    let usersUrl = 'http://' + env.host + ':' + env.port + baseUsersUrl + api + 'users/';\n    return usersUrl;\n  }\n\n  public getAll = (): Observable<User[]> => {\n    return this.environment.flatMap((env: any) => {\n      return this.http\n        .get(this.getUsersUrl(env), new RequestOptions({headers: this.getHeaders()}))\n        .map(res => res.json());\n    });\n  };\n\n  public search = (nickname: string): Observable<User[]> => {\n    return this.environment.flatMap((env: any) => {\n      return this.http\n        .get(this.getUsersUrl(env) + \"?nickname=\" + nickname, new RequestOptions({headers: this.getHeaders()}))\n        .map(res => res.json());\n    });\n  };\n\n  public find = (id: number): Observable<User> => {\n    return this.environment.flatMap((env: any) => {\n      return this.http\n        .get(this.getUsersUrl(env) + id, new RequestOptions({headers: this.getHeaders()}))\n        .map(res => res.json());\n    });\n  };\n\n  public create = (firstName: string, lastName: string): Observable<User> => {\n    return this.environment.flatMap((env: any) => {\n      var toAdd = JSON.stringify({firstName: firstName, lastName: lastName});\n      return this.http\n        .post(this.getUsersUrl(env), toAdd, new RequestOptions({headers: this.getHeaders()}))\n        .map(res => res.json());\n    });\n  };\n\n  public update = (id: number, itemToUpdate: User): Observable<User> => {\n    return this.environment.flatMap((env: any) => {\n      return this.http\n        .put(this.getUsersUrl(env) + id, JSON.stringify(itemToUpdate), new RequestOptions({headers: this.getHeaders()}))\n        .map(res => res.json());\n    });\n  };\n\n  public delete = (id: number): Observable<Response> => {\n    return this.environment.flatMap((env: any) => {\n      return this.http\n        .delete(this.getUsersUrl(env) + id, new RequestOptions({headers: this.getHeaders()}));\n    });\n  };\n\n  private getHeaders() {\n    let headers = new Headers();\n    headers.append('Content-Type', 'application/json');\n    headers.append('Accept', 'application/json');\n    return headers;\n  }\n}\n\n\n\n\nWe're going to read the host and the port of the REST service url from a file\ncalled \nenvironment.json\n. Therefore we're going to create this file\n\nsrc/environment/environment.json\n with the following content:\n\n\n{\n  \"host\": \"localhost\",\n  \"port\": 8080\n}\n\n\n\n\nCreation of the component\n\n\nThe next step is to create the TypeScript component \nusers.component.ts\n in the\nsame folder as the service and the other files:\n\n\nimport {User} from \"./user\";\nimport {UserService} from \"./users.service\";\nimport {Component} from \"@angular/core\";\n\n@Component({\n  selector: 'battleapp-user',\n  templateUrl: './users.component.html',\n  styleUrls: ['./users.component.css'],\n  providers: [UserService],\n})\nexport class UserComponent {\n  private users: User[];\n\n  constructor(private usersService: UserService) {\n  }\n\n  ngOnInit() {\n    this.getUsers();\n  }\n\n  public search(event: any) {\n    let searchTerm: string = event.target.value;\n    this.usersService\n      .search(searchTerm)\n      .subscribe((data: User[]) => {\n          this.users = data;\n        },\n        error => console.log(error)\n      );\n  }\n\n  private getUsers() {\n    this.usersService\n      .getAll()\n      .subscribe((data: User[]) => {\n          this.users = data;\n        },\n        error => console.log(error)\n      );\n  };\n\n}\n\n\n\n\nInclude the component in site\n\n\nIn \nsrc/app/app.component.ts\n we've to include the newly created user page.\nTherefore we refactor the template of the app component in a own template\nfile:\n\n\n@Component({\n  selector: 'app',\n  encapsulation: ViewEncapsulation.None,\n  styleUrls: [\n    './app.component.css'\n  ],\n  templateUrl: './app.component.html'\n})\n\n\n\n\nThis file contains the navigation with our new user page:\n\n\n<md-sidenav-layout>\n\n  <md-sidenav #sidenav mode=\"side\" class=\"app-sidenav\">\n    <nav>\n      <p>\n        <a [routerLink]=\" ['./'] \">\n          Index\n        </a>\n      </p>\n      <p>\n        <a [routerLink]=\" ['./home'] \">\n          Home\n        </a>\n      </p>\n      <p>\n        <a [routerLink]=\" ['./detail'] \">\n          Detail\n        </a>\n      </p>\n      <p>\n        <a [routerLink]=\" ['./about'] \">\n          About\n        </a>\n      </p>\n      <p>\n        <a [routerLink]=\" ['./users'] \">\n          Users\n        </a>\n      </p>\n    </nav>\n  </md-sidenav>\n\n  <md-toolbar color=\"primary\">\n    <button class=\"app-icon-button\" (click)=\"sidenav.toggle()\">\n      <i class=\"material-icons app-toolbar-menu\">menu</i>\n    </button>\n\n    Battle App\n\n  </md-toolbar>\n\n  <div class=\"app-content\">\n    <main>\n      <router-outlet></router-outlet>\n    </main>\n  </div>\n\n</md-sidenav-layout>\n\n<footer>\n  Robert Brem\n</footer>\n\n\n\n\nThe \napp.module.ts\n class gets extended with our \nUserComponent\n:\n\n\n...\n@NgModule({\n  bootstrap: [AppComponent],\n  declarations: [\n    AppComponent,\n    AboutComponent,\n    HomeComponent,\n    UserComponent,\n    NoContentComponent,\n    XLarge\n  ],\n...\n\n\n\n\nLike the \napp.module.ts\n the \napp.routes.ts\n gets extended with our \n\nUserComponent\n:\n\n\nexport const ROUTES: Routes = [\n  {path: '', component: HomeComponent},\n  {path: 'home', component: HomeComponent},\n  {path: 'about', component: AboutComponent},\n  {\n    path: 'detail', loadChildren: () => System.import('./+detail')\n    .then((comp: any) => comp.default),\n  },\n  {path: 'users', component: UserComponent},\n  {path: '**', component: NoContentComponent},\n];",
            "title": "First view"
        },
        {
            "location": "/15_Angular2_frontend/First_view/#creation-of-the-first-view",
            "text": "We're going to create an own view that displays the users from the REST service.",
            "title": "Creation of the first view"
        },
        {
            "location": "/15_Angular2_frontend/First_view/#creation-of-the-template",
            "text": "Therefore we create a new folder  src/app/users  with the following template users.component.html :  <md-input placeholder=\"Nickname\" (keyup)=\"search($event)\"></md-input>\n\n<md-card *ngFor=\"let user of users\">\n  Name: {{ user.name }}\n</md-card>  We're going to use  Angular 2 Material . \nTherefore we have to install it.  npm install --save @angular/material  In the  src/app/app.module.ts  file we've to include Material:  ...\nimport {MaterialModule} from \"@angular/material\";\n...\nimports: [ // import Angular's modules\n    BrowserModule,\n    FormsModule,\n    HttpModule,\n    MaterialModule.forRoot(),\n    RouterModule.forRoot(ROUTES, {useHash: true, preloadingStrategy: PreloadAllModules})\n  ],\n...  Install  hammerjs .   npm install --save hammerjs   In  src/index.html  add the following line in the header:  <link href=\"https://fonts.googleapis.com/icon?family=Material+Icons\" rel=\"stylesheet\">  Create an empty  users.component.css  file in the same folder as the \nhtml template.",
            "title": "Creation of the template"
        },
        {
            "location": "/15_Angular2_frontend/First_view/#creation-of-the-service",
            "text": "For the service we need a  user.ts  object in the same folder as the \ntemplate files:  export class User {\n  name: string;\n\n  constructor() {\n  }\n\n}  The next class is the service for the component:  import {Injectable} from \"@angular/core\";\nimport {RequestOptions, Response, Headers, Http} from \"@angular/http\";\nimport {Observable} from \"rxjs\";\nimport {User} from \"./user\";\n\n@Injectable()\nexport class UserService {\n  private environment: Observable<any>;\n\n  constructor(private http: Http) {\n    this.environment = this.http\n      .get('/environment/environment.json')\n      .map(res => res.json());\n  }\n\n  public getUsersUrl(env: any): string {\n    let baseUsersUrl = '/battleapp/';\n    let api: string = 'resources/';\n    let usersUrl = 'http://' + env.host + ':' + env.port + baseUsersUrl + api + 'users/';\n    return usersUrl;\n  }\n\n  public getAll = (): Observable<User[]> => {\n    return this.environment.flatMap((env: any) => {\n      return this.http\n        .get(this.getUsersUrl(env), new RequestOptions({headers: this.getHeaders()}))\n        .map(res => res.json());\n    });\n  };\n\n  public search = (nickname: string): Observable<User[]> => {\n    return this.environment.flatMap((env: any) => {\n      return this.http\n        .get(this.getUsersUrl(env) + \"?nickname=\" + nickname, new RequestOptions({headers: this.getHeaders()}))\n        .map(res => res.json());\n    });\n  };\n\n  public find = (id: number): Observable<User> => {\n    return this.environment.flatMap((env: any) => {\n      return this.http\n        .get(this.getUsersUrl(env) + id, new RequestOptions({headers: this.getHeaders()}))\n        .map(res => res.json());\n    });\n  };\n\n  public create = (firstName: string, lastName: string): Observable<User> => {\n    return this.environment.flatMap((env: any) => {\n      var toAdd = JSON.stringify({firstName: firstName, lastName: lastName});\n      return this.http\n        .post(this.getUsersUrl(env), toAdd, new RequestOptions({headers: this.getHeaders()}))\n        .map(res => res.json());\n    });\n  };\n\n  public update = (id: number, itemToUpdate: User): Observable<User> => {\n    return this.environment.flatMap((env: any) => {\n      return this.http\n        .put(this.getUsersUrl(env) + id, JSON.stringify(itemToUpdate), new RequestOptions({headers: this.getHeaders()}))\n        .map(res => res.json());\n    });\n  };\n\n  public delete = (id: number): Observable<Response> => {\n    return this.environment.flatMap((env: any) => {\n      return this.http\n        .delete(this.getUsersUrl(env) + id, new RequestOptions({headers: this.getHeaders()}));\n    });\n  };\n\n  private getHeaders() {\n    let headers = new Headers();\n    headers.append('Content-Type', 'application/json');\n    headers.append('Accept', 'application/json');\n    return headers;\n  }\n}  We're going to read the host and the port of the REST service url from a file\ncalled  environment.json . Therefore we're going to create this file src/environment/environment.json  with the following content:  {\n  \"host\": \"localhost\",\n  \"port\": 8080\n}",
            "title": "Creation of the service"
        },
        {
            "location": "/15_Angular2_frontend/First_view/#creation-of-the-component",
            "text": "The next step is to create the TypeScript component  users.component.ts  in the\nsame folder as the service and the other files:  import {User} from \"./user\";\nimport {UserService} from \"./users.service\";\nimport {Component} from \"@angular/core\";\n\n@Component({\n  selector: 'battleapp-user',\n  templateUrl: './users.component.html',\n  styleUrls: ['./users.component.css'],\n  providers: [UserService],\n})\nexport class UserComponent {\n  private users: User[];\n\n  constructor(private usersService: UserService) {\n  }\n\n  ngOnInit() {\n    this.getUsers();\n  }\n\n  public search(event: any) {\n    let searchTerm: string = event.target.value;\n    this.usersService\n      .search(searchTerm)\n      .subscribe((data: User[]) => {\n          this.users = data;\n        },\n        error => console.log(error)\n      );\n  }\n\n  private getUsers() {\n    this.usersService\n      .getAll()\n      .subscribe((data: User[]) => {\n          this.users = data;\n        },\n        error => console.log(error)\n      );\n  };\n\n}",
            "title": "Creation of the component"
        },
        {
            "location": "/15_Angular2_frontend/First_view/#include-the-component-in-site",
            "text": "In  src/app/app.component.ts  we've to include the newly created user page.\nTherefore we refactor the template of the app component in a own template\nfile:  @Component({\n  selector: 'app',\n  encapsulation: ViewEncapsulation.None,\n  styleUrls: [\n    './app.component.css'\n  ],\n  templateUrl: './app.component.html'\n})  This file contains the navigation with our new user page:  <md-sidenav-layout>\n\n  <md-sidenav #sidenav mode=\"side\" class=\"app-sidenav\">\n    <nav>\n      <p>\n        <a [routerLink]=\" ['./'] \">\n          Index\n        </a>\n      </p>\n      <p>\n        <a [routerLink]=\" ['./home'] \">\n          Home\n        </a>\n      </p>\n      <p>\n        <a [routerLink]=\" ['./detail'] \">\n          Detail\n        </a>\n      </p>\n      <p>\n        <a [routerLink]=\" ['./about'] \">\n          About\n        </a>\n      </p>\n      <p>\n        <a [routerLink]=\" ['./users'] \">\n          Users\n        </a>\n      </p>\n    </nav>\n  </md-sidenav>\n\n  <md-toolbar color=\"primary\">\n    <button class=\"app-icon-button\" (click)=\"sidenav.toggle()\">\n      <i class=\"material-icons app-toolbar-menu\">menu</i>\n    </button>\n\n    Battle App\n\n  </md-toolbar>\n\n  <div class=\"app-content\">\n    <main>\n      <router-outlet></router-outlet>\n    </main>\n  </div>\n\n</md-sidenav-layout>\n\n<footer>\n  Robert Brem\n</footer>  The  app.module.ts  class gets extended with our  UserComponent :  ...\n@NgModule({\n  bootstrap: [AppComponent],\n  declarations: [\n    AppComponent,\n    AboutComponent,\n    HomeComponent,\n    UserComponent,\n    NoContentComponent,\n    XLarge\n  ],\n...  Like the  app.module.ts  the  app.routes.ts  gets extended with our  UserComponent :  export const ROUTES: Routes = [\n  {path: '', component: HomeComponent},\n  {path: 'home', component: HomeComponent},\n  {path: 'about', component: AboutComponent},\n  {\n    path: 'detail', loadChildren: () => System.import('./+detail')\n    .then((comp: any) => comp.default),\n  },\n  {path: 'users', component: UserComponent},\n  {path: '**', component: NoContentComponent},\n];",
            "title": "Include the component in site"
        },
        {
            "location": "/15_Angular2_frontend/Initial_setup/",
            "text": "Create an Angular 2 frontend\n\n\nInstall NodeJS and NPM\n\n\nWe're going to use NPM as our package manager. To install NodeJS and NPM execute the\nfollowing command:\n\n\ncurl -sL https://deb.nodesource.com/setup_7.x | sudo -E bash -\nsudo apt-get install -y nodejs\n\n\n\n\nSetup the Angular 2 project\n\n\nWe are using a bootstrap project to get started with Angular 2:\n\n\ngit clone --depth 1 https://github.com/angularclass/angular2-webpack-starter.git\ncd angular2-webpack-starter\nnpm install\nnpm run server:dev:hmr\n\n\n\n\nNow you can open the frontend on this url:\n\n\nhttp://localhost:3000\n\n\n\n\nCreate a Docker image\n\n\nIf there isn't already a \nDockerfile\n in the mail folder, create one with\nthe following settings:\n\n\nFROM nginx:latest\n\nMAINTAINER Robert Brem <brem_robert@hotmail.com>\n\nADD dist/ /usr/share/nginx/html\n\n\n\n\nLike the \njax-rs\n service the Angular2 service needs a \nbuild.js\n script\nto create and push the Docker image in the repository.\n\n\n#!/usr/bin/jjs -fv\n\nvar version = $ENV.VERSION;\nvar username = $ENV.REGISTRY_USERNAME;\nvar password = $ENV.REGISTRY_PASSWORD;\nvar email = $ENV.REGISTRY_EMAIL;\n\nvar registry = \"disruptor.ninja:30500\";\nvar imageName = registry + \"/robertbrem/battleapp-frontend:\" + version;\n\nvar build = \"docker build -t \" + imageName + \" .\";\nexecute(build);\n\nvar dockerLogin = \"docker login --username=\" + username + \" --password=\" + password + \" --email=\" + email + \" \" + registry;\nexecute(dockerLogin);\n\nvar push = \"docker push \" + imageName;\nexecute(push);\n\nfunction execute(command) {\n  $EXEC(command);\n  print($OUT);\n  print($ERR);\n}\n\n\n\n\nCreate the Jenkins pipeline\n\n\nFirst of all we've to install NodeJS and NPM on Jenkins.\n\n\nOn Jenkins go to \nManage Jenkins\n \nManage Plugins\n. Change to the \n\nAvailable\n tab and search for the \nNodeJS Plugin\n and install it.\n\n\nAfter the restart go to \nManage Jenkins\n \nGlobal Tool Configuration\n.\n\nUnder the title \nNodeJS\n we make the following settings:\n\n\n\n\nThis installs NodeJS and NPM and we can use it in our pipeline.\n\n\nThe Angular2 sample project also allows us to statically analyze our code and\ncompares it with the official Angular2 style guide. We can include this\nanalysis in our pipeline with the \nCheckstyle\n plugin. Just search under\n\nAvaialble\n plugins for \nCheckstyle Plug-in\n and install it.\n\n\nwithEnv([   \"VERSION=1.0.${currentBuild.number}\",\n            \"KUBECTL=kubectl\",\n            \"REGISTRY_EMAIL=brem_robert@hotmail.com\"]) {\n\n  stage \"checkout, build, test and publish\"\n  node {\n    git url: \"http://disruptor.ninja:30130/rob/battleapp-frontend\"\n    def npmHome = tool 'NPM'\n    env.PATH = \"${npmHome}/bin:${env.PATH}\"\n    sh \"npm install\"\n    sh \"npm run test\"\n    sh \"npm run lint\"\n    sh \"npm run build:prod\"\n    sh \"./build.js\"\n    step([$class: 'JUnitResultArchiver', testResults: '**TESTS-*.xml'])\n    step([$class: 'hudson.plugins.checkstyle.CheckStylePublisher', pattern: '**REPORTS-*.xml'])\n  }\n\n\n\n\nThat the Karma tests can be executed on the server we've to change the\nKarma settings from using Chrome to using PhantomJS. Therefore we've to change\nthe browser in \nkarma.conf.js\n:\n\n\n...\nbrowsers: [\n  'PhantomJS'\n],\n...\n\n\n\n\nPhantomJS is not per default installed therefore we've to install it:\n\n\nnpm install --save-dev karma-phantomjs-launcher\n\n\n\n\nThat Jenkins understands the test results we've to install the \n\nkarma-junit-reporter\n:\n\n\nnpm install karma-junit-reporter --save-dev\n\n\n\n\nAnd tell Angular2 to create a report. This have to be done in the\n\nkarma.conf.js\n as well:\n\n\n...\nreporters: ['mocha', 'coverage', 'remap-coverage', 'junit'],\n\njunitReporter: {\n  outputDir: '', // results will be saved as $outputDir/$browserName.xml\n  outputFile: undefined, // if included, results will be saved as $outputDir/$browserName/$outputFile\n  suite: '', // suite will become the package name attribute in xml testsuite element\n  useBrowserName: true, // add browser name to report and classes names\n  nameFormatter: undefined, // function (browser, result) to customize the name attribute in xml testcase element\n  classNameFormatter: undefined, // function (browser, result) to customize the classname attribute in xml testcase element\n  properties: {} // key value pair of properties to add to the <properties> section of the report\n},\n...\n\n\n\n\nThat Jenkins understands the static analysis we've to adapt the \nlint\n \nnpm script:\n\n\n\"lint\": \"tslint --format tslint-checkstyle-reporter -o REPORTS-tslint.xml --force \\\"src/**/*.ts\\\" && ./createCheckstyle.sh\",\n\n\n\n\nAnd install the \ntslint-checkstyle-reporter\n:\n\n\nnpm install tslint-checkstyle-reporter --save-dev\n\n\n\n\nAdditionally we've to create a script that adds the xml header and footer for\nthe Checkstyle plugin. This script is created in the root folder with the\nname \ncreateCheckstyle.sh\n:\n\n\n# /bin/bash\n\nsed -i \"1s/^/<?xml version='1.0' encoding='utf-8'?>\\n<checkstyle version='5.7'>\\n/\" REPORTS-tslint.xml\necho \"</checkstyle>\" >> REPORTS-tslint.xml",
            "title": "Initial setup"
        },
        {
            "location": "/15_Angular2_frontend/Initial_setup/#create-an-angular-2-frontend",
            "text": "",
            "title": "Create an Angular 2 frontend"
        },
        {
            "location": "/15_Angular2_frontend/Initial_setup/#install-nodejs-and-npm",
            "text": "We're going to use NPM as our package manager. To install NodeJS and NPM execute the\nfollowing command:  curl -sL https://deb.nodesource.com/setup_7.x | sudo -E bash -\nsudo apt-get install -y nodejs",
            "title": "Install NodeJS and NPM"
        },
        {
            "location": "/15_Angular2_frontend/Initial_setup/#setup-the-angular-2-project",
            "text": "We are using a bootstrap project to get started with Angular 2:  git clone --depth 1 https://github.com/angularclass/angular2-webpack-starter.git\ncd angular2-webpack-starter\nnpm install\nnpm run server:dev:hmr  Now you can open the frontend on this url:  http://localhost:3000",
            "title": "Setup the Angular 2 project"
        },
        {
            "location": "/15_Angular2_frontend/Initial_setup/#create-a-docker-image",
            "text": "If there isn't already a  Dockerfile  in the mail folder, create one with\nthe following settings:  FROM nginx:latest\n\nMAINTAINER Robert Brem <brem_robert@hotmail.com>\n\nADD dist/ /usr/share/nginx/html  Like the  jax-rs  service the Angular2 service needs a  build.js  script\nto create and push the Docker image in the repository.  #!/usr/bin/jjs -fv\n\nvar version = $ENV.VERSION;\nvar username = $ENV.REGISTRY_USERNAME;\nvar password = $ENV.REGISTRY_PASSWORD;\nvar email = $ENV.REGISTRY_EMAIL;\n\nvar registry = \"disruptor.ninja:30500\";\nvar imageName = registry + \"/robertbrem/battleapp-frontend:\" + version;\n\nvar build = \"docker build -t \" + imageName + \" .\";\nexecute(build);\n\nvar dockerLogin = \"docker login --username=\" + username + \" --password=\" + password + \" --email=\" + email + \" \" + registry;\nexecute(dockerLogin);\n\nvar push = \"docker push \" + imageName;\nexecute(push);\n\nfunction execute(command) {\n  $EXEC(command);\n  print($OUT);\n  print($ERR);\n}",
            "title": "Create a Docker image"
        },
        {
            "location": "/15_Angular2_frontend/Initial_setup/#create-the-jenkins-pipeline",
            "text": "First of all we've to install NodeJS and NPM on Jenkins.  On Jenkins go to  Manage Jenkins   Manage Plugins . Change to the  Available  tab and search for the  NodeJS Plugin  and install it.  After the restart go to  Manage Jenkins   Global Tool Configuration . \nUnder the title  NodeJS  we make the following settings:   This installs NodeJS and NPM and we can use it in our pipeline.  The Angular2 sample project also allows us to statically analyze our code and\ncompares it with the official Angular2 style guide. We can include this\nanalysis in our pipeline with the  Checkstyle  plugin. Just search under Avaialble  plugins for  Checkstyle Plug-in  and install it.  withEnv([   \"VERSION=1.0.${currentBuild.number}\",\n            \"KUBECTL=kubectl\",\n            \"REGISTRY_EMAIL=brem_robert@hotmail.com\"]) {\n\n  stage \"checkout, build, test and publish\"\n  node {\n    git url: \"http://disruptor.ninja:30130/rob/battleapp-frontend\"\n    def npmHome = tool 'NPM'\n    env.PATH = \"${npmHome}/bin:${env.PATH}\"\n    sh \"npm install\"\n    sh \"npm run test\"\n    sh \"npm run lint\"\n    sh \"npm run build:prod\"\n    sh \"./build.js\"\n    step([$class: 'JUnitResultArchiver', testResults: '**TESTS-*.xml'])\n    step([$class: 'hudson.plugins.checkstyle.CheckStylePublisher', pattern: '**REPORTS-*.xml'])\n  }  That the Karma tests can be executed on the server we've to change the\nKarma settings from using Chrome to using PhantomJS. Therefore we've to change\nthe browser in  karma.conf.js :  ...\nbrowsers: [\n  'PhantomJS'\n],\n...  PhantomJS is not per default installed therefore we've to install it:  npm install --save-dev karma-phantomjs-launcher  That Jenkins understands the test results we've to install the  karma-junit-reporter :  npm install karma-junit-reporter --save-dev  And tell Angular2 to create a report. This have to be done in the karma.conf.js  as well:  ...\nreporters: ['mocha', 'coverage', 'remap-coverage', 'junit'],\n\njunitReporter: {\n  outputDir: '', // results will be saved as $outputDir/$browserName.xml\n  outputFile: undefined, // if included, results will be saved as $outputDir/$browserName/$outputFile\n  suite: '', // suite will become the package name attribute in xml testsuite element\n  useBrowserName: true, // add browser name to report and classes names\n  nameFormatter: undefined, // function (browser, result) to customize the name attribute in xml testcase element\n  classNameFormatter: undefined, // function (browser, result) to customize the classname attribute in xml testcase element\n  properties: {} // key value pair of properties to add to the <properties> section of the report\n},\n...  That Jenkins understands the static analysis we've to adapt the  lint  \nnpm script:  \"lint\": \"tslint --format tslint-checkstyle-reporter -o REPORTS-tslint.xml --force \\\"src/**/*.ts\\\" && ./createCheckstyle.sh\",  And install the  tslint-checkstyle-reporter :  npm install tslint-checkstyle-reporter --save-dev  Additionally we've to create a script that adds the xml header and footer for\nthe Checkstyle plugin. This script is created in the root folder with the\nname  createCheckstyle.sh :  # /bin/bash\n\nsed -i \"1s/^/<?xml version='1.0' encoding='utf-8'?>\\n<checkstyle version='5.7'>\\n/\" REPORTS-tslint.xml\necho \"</checkstyle>\" >> REPORTS-tslint.xml",
            "title": "Create the Jenkins pipeline"
        },
        {
            "location": "/15_Angular2_frontend/README/",
            "text": "Creation of a Angular2 frontend\n\n\n\n\nInitial setup\n\n\nCreate test and production stage\n\n\nFirst view",
            "title": "README"
        },
        {
            "location": "/15_Angular2_frontend/README/#creation-of-a-angular2-frontend",
            "text": "Initial setup  Create test and production stage  First view",
            "title": "Creation of a Angular2 frontend"
        },
        {
            "location": "/15_Angular2_frontend/Test_and_prod_stage/",
            "text": "Create a test and production stage\n\n\nWe create a test environment similar to the test environment of the REST service.\n\n\n#!/usr/bin/jjs -fv\n\nvar FileWriter = Java.type(\"java.io.FileWriter\");\n\nvar version = $ENV.VERSION;\nvar kubectl = $ENV.KUBECTL;\n\nvar name = \"battleapp-frontend-test\";\nvar baseUrl = \"disruptor.ninja\";\nvar image = baseUrl + \":30500/robertbrem/battleapp-frontend:\" + version;\nvar replicas = 1;\nvar port = 80;\nvar clusterPort = 3001;\nvar nodePort = 31030;\nvar deploymentFileName = \"deployment.yml\";\nvar serviceFileName = \"service.yml\";\nvar registrysecret = \"registrykey\";\nvar url = \"http://\" + baseUrl + \":\" + nodePort;\nvar timeout = 2;\n\nvar deleteDeployment = kubectl + \" delete deployment \" + name;\nexecute(deleteDeployment);\n\nvar dfw = new FileWriter(deploymentFileName);\ndfw.write(\"apiVersion: extensions/v1beta1\\n\");\ndfw.write(\"kind: Deployment\\n\");\ndfw.write(\"metadata:\\n\");\ndfw.write(\"  name: \" + name + \"\\n\");\ndfw.write(\"spec:\\n\");\ndfw.write(\"  replicas: \" + replicas + \"\\n\");\ndfw.write(\"  template:\\n\");\ndfw.write(\"    metadata:\\n\");\ndfw.write(\"      labels:\\n\");\ndfw.write(\"        name: \" + name + \"\\n\");\ndfw.write(\"    spec:\\n\");\ndfw.write(\"      containers:\\n\");\ndfw.write(\"      - resources:\\n\");\ndfw.write(\"        name: \" + name + \"\\n\");\ndfw.write(\"        image: \" + image + \"\\n\");\ndfw.write(\"        ports:\\n\");\ndfw.write(\"        - name: port\\n\");\ndfw.write(\"          containerPort: \" + port + \"\\n\");\ndfw.write(\"        volumeMounts:\\n\");\ndfw.write(\"        - name: environment\\n\");\ndfw.write(\"          mountPath: /usr/share/nginx/html/environment\\n\");\ndfw.write(\"      volumes:\\n\");\ndfw.write(\"      - name: environment\\n\");\ndfw.write(\"        configMap:\\n\");\ndfw.write(\"          name: battleapp-frontend-test\\n\");\ndfw.write(\"          items:\\n\");\ndfw.write(\"          - key: environment.json\\n\");\ndfw.write(\"            path: environment.json\\n\");\ndfw.write(\"      imagePullSecrets:\\n\");\ndfw.write(\"      - name: \" + registrysecret + \"\\n\");\ndfw.close();\n\nvar deploy = kubectl + \" create -f \" + deploymentFileName;\nexecute(deploy);\n\nvar deleteService = kubectl + \" delete service \" + name;\nexecute(deleteService);\n\nvar sfw = new FileWriter(serviceFileName);\nsfw.write(\"apiVersion: v1\\n\");\nsfw.write(\"kind: Service\\n\");\nsfw.write(\"metadata:\\n\");\nsfw.write(\"  name: \" + name + \"\\n\");\nsfw.write(\"  labels:\\n\");\nsfw.write(\"    name: \" + name + \"\\n\");\nsfw.write(\"spec:\\n\");\nsfw.write(\"  ports:\\n\");\nsfw.write(\"  - port: \" + clusterPort + \"\\n\");\nsfw.write(\"    targetPort: \" + port + \"\\n\");\nsfw.write(\"    nodePort: \" + nodePort + \"\\n\");\nsfw.write(\"  selector:\\n\");\nsfw.write(\"    name: \" + name + \"\\n\");\nsfw.write(\"  type: NodePort\\n\");\nsfw.close();\n\nvar deployService = kubectl + \" create -f \" + serviceFileName;\nexecute(deployService);\n\nvar testUrl = \"curl --write-out %{http_code} --silent --output /dev/null \" + url + \" --max-time \" + timeout;\nexecute(testUrl);\nwhile ($OUT != \"200\") {\n    $EXEC(\"sleep 1\");\n    execute(testUrl);\n}\n\nfunction execute(command) {\n    $EXEC(command);\n    print($OUT);\n    print($ERR);\n}\n\n\n\n\nIt is important to make this script file executable:\n\n\nchmod 750 start.js\n\n\n\n\nAnd the corresponding pipeline entry:\n\n\nstage \"start test environment\"\nnode {\n  git url: \"http://disruptor.ninja:30130/rob/battleapp-frontend-starttestenv\"\n  sh \"./start.js\"\n}\n\n\n\n\nAfter the test environment we add a manual pipeline step:\n\n\nstage \"manual testing\"\ninput \"everything ok?\"\n\n\n\n\nThe next step is the canary release:\n\n\n#!/usr/bin/jjs -fv\n\nvar FileWriter = Java.type(\"java.io.FileWriter\");\n\nvar version = $ENV.VERSION;\nvar kubectl = $ENV.KUBECTL;\n\nvar name = \"battleapp-frontend\";\nvar nameWithVersion = name + \"-\" + version;\nvar image = \"disruptor.ninja:30500/robertbrem/\" + name + \":\" + version;\nvar replicas = 1;\nvar port = 80;\nvar clusterPort = 3002;\nvar nodePort = 30030;\nvar deploymentFileName = \"deployment.yml\";\nvar serviceFileName = \"service.yml\";\nvar registrysecret = \"registrykey\";\nvar relativeUrl = \"/\";\nvar url = \"http://disruptor.ninja:\" + nodePort;\nvar timeout = 2;\nvar initialDelay = 15;\nvar readinessProbeTimeout = 10;\n\nvar dfw = new FileWriter(deploymentFileName);\ndfw.write(\"apiVersion: extensions/v1beta1\\n\");\ndfw.write(\"kind: Deployment\\n\");\ndfw.write(\"metadata:\\n\");\ndfw.write(\"  name: \" + nameWithVersion + \"\\n\");\ndfw.write(\"spec:\\n\");\ndfw.write(\"  replicas: \" + replicas + \"\\n\");\ndfw.write(\"  template:\\n\");\ndfw.write(\"    metadata:\\n\");\ndfw.write(\"      labels:\\n\");\ndfw.write(\"        name: \" + name + \"\\n\");\ndfw.write(\"        version: \" + version + \"\\n\");\ndfw.write(\"    spec:\\n\");\ndfw.write(\"      containers:\\n\");\ndfw.write(\"      - resources:\\n\");\ndfw.write(\"        name: \" + name + \"\\n\");\ndfw.write(\"        image: \" + image + \"\\n\");\ndfw.write(\"        ports:\\n\");\ndfw.write(\"        - name: port\\n\");\ndfw.write(\"          containerPort: \" + port + \"\\n\");\ndfw.write(\"        readinessProbe:\\n\");\ndfw.write(\"          httpGet:\\n\");\ndfw.write(\"            path: \" + relativeUrl + \"\\n\");\ndfw.write(\"            port: \" + port + \"\\n\");\ndfw.write(\"          initialDelaySeconds: \" + initialDelay + \"\\n\");\ndfw.write(\"          timeoutSeconds: \" + readinessProbeTimeout + \"\\n\");\ndfw.write(\"        volumeMounts:\\n\");\ndfw.write(\"        - name: environment\\n\");\ndfw.write(\"          mountPath: /usr/share/nginx/html/environment\\n\");\ndfw.write(\"      volumes:\\n\");\ndfw.write(\"      - name: environment\\n\");\ndfw.write(\"        configMap:\\n\");\ndfw.write(\"          name: battleapp-frontend\\n\");\ndfw.write(\"          items:\\n\");\ndfw.write(\"          - key: environment.json\\n\");\ndfw.write(\"            path: environment.json\\n\");\ndfw.write(\"      imagePullSecrets:\\n\");\ndfw.write(\"      - name: \" + registrysecret + \"\\n\");\ndfw.close();\n\nvar deploy = kubectl + \" create -f \" + deploymentFileName;\nexecute(deploy);\n\nvar sfw = new FileWriter(serviceFileName);\nsfw.write(\"apiVersion: v1\\n\");\nsfw.write(\"kind: Service\\n\");\nsfw.write(\"metadata:\\n\");\nsfw.write(\"  name: \" + name + \"\\n\");\nsfw.write(\"  labels:\\n\");\nsfw.write(\"    name: \" + name + \"\\n\");\nsfw.write(\"spec:\\n\");\nsfw.write(\"  ports:\\n\");\nsfw.write(\"  - port: \" + clusterPort + \"\\n\");\nsfw.write(\"    targetPort: \" + port + \"\\n\");\nsfw.write(\"    nodePort: \" + nodePort + \"\\n\");\nsfw.write(\"  selector:\\n\");\nsfw.write(\"    name: \" + name + \"\\n\");\nsfw.write(\"  type: NodePort\\n\");\nsfw.close();\n\nvar deployService = kubectl + \" create -f \" + serviceFileName;\nexecute(deployService);\n\nvar testUrl = \"curl --write-out %{http_code} --silent --output /dev/null \" + url + \" --max-time \" + timeout;\nexecute(testUrl);\nwhile ($OUT != \"200\") {\n    $EXEC(\"sleep 1\");\n    execute(testUrl);\n}\n\nfunction execute(command) {\n    $EXEC(command);\n    print($OUT);\n    print($ERR);\n}\n\n\n\n\nMake the script file executable:\n\n\nchmod 750 start.js\n\n\n\n\nThe corresponding pipeline entry:\n\n\nstage \"start canary\"\ninput \"deploy the canary?\"\nnode {\n  git url: \"http://disruptor.ninja:30130/rob/battleapp-frontend-canary\"\n  sh \"./start.js\"\n}\n\n\n\n\nThe last step is the production step with the following script:\n\n\n#!/usr/bin/jjs -fv\n\nvar version = $ENV.VERSION;\nvar kubectl = $ENV.KUBECTL;\n\nvar name = \"battleapp-frontend\";\nvar url = \"http://disruptor.ninja:30030\";\nvar timeout = 2;\n\nvar deleteDeployment = kubectl + \" delete deployment -l name=\" + name + \",version!=\" + version;\nexecute(deleteDeployment);\n\nvar testUrl = \"curl --write-out %{http_code} --silent --output /dev/null \" + url + \" --max-time \" + timeout;\nexecute(testUrl);\nwhile ($OUT != \"200\") {\n    $EXEC(\"sleep 1\");\n    execute(testUrl);\n}\n\nfunction execute(command) {\n    $EXEC(command);\n    print($OUT);\n    print($ERR);\n}\n\n\n\n\nMake the script file executable:\n\n\nchmod 750 start.js\n\n\n\n\nThe corresponding pipeline entry:\n\n\nstage \"go full production\"\ninput \"undeploy other versions?\"\nnode {\n  git url: \"http://disruptor.ninja:30130/rob/battleapp-frontend-prod\"\n  sh \"./start.js\"\n}\n\n\n\n\nCreation of Kubernetes ConfigMap\n\n\nIn both the test and the production stage we referenced a Kubernetes\nConfigMap that we've to create first. Therefore we have to create a folder\non the local machine with the name \nbattleapp-frontend\n and a file \n\nenvironment.json\n with the following content:\n\n\n{\n  \"host\": \"disruptor.ninja\",\n  \"port\": 30080\n}\n\n\n\n\nWe need also a \nenvironment.json\n file for the test stage. Therefore we \ncreate a folder \nbattleapp-frontend-test\n and a file \nenvironment.json\n\nwith the following content:\n\n\n{\n  \"host\": \"disruptor.ninja\",\n  \"port\": 31080\n}\n\n\n\n\nNow we create the two ConfigMaps:\n\n\nkc create configmap battleapp-frontend-test --from-file=battleapp-frontend-test\nkc create configmap battleapp-frontend --from-file=battleapp-frontend\n\n\n\n\nWe can test display the ConfigMaps with the following command:\n\n\nkc get configmap battleapp-frontend-test -o yaml\n\n\n\n\napiVersion: v1\ndata:\n  environment.json: |\n    {\n      \"host\": \"disruptor.ninja\",\n      \"port\": 31080\n    }\nkind: ConfigMap\nmetadata:\n  creationTimestamp: 2016-12-31T15:54:44Z\n  name: battleapp-frontend-test\n  namespace: default\n  resourceVersion: \"1049486\"\n  selfLink: /api/v1/namespaces/default/configmaps/battleapp-frontend-test\n  uid: 72a5399b-cf71-11e6-a836-0050563cad2a",
            "title": "Test and prod stage"
        },
        {
            "location": "/15_Angular2_frontend/Test_and_prod_stage/#create-a-test-and-production-stage",
            "text": "We create a test environment similar to the test environment of the REST service.  #!/usr/bin/jjs -fv\n\nvar FileWriter = Java.type(\"java.io.FileWriter\");\n\nvar version = $ENV.VERSION;\nvar kubectl = $ENV.KUBECTL;\n\nvar name = \"battleapp-frontend-test\";\nvar baseUrl = \"disruptor.ninja\";\nvar image = baseUrl + \":30500/robertbrem/battleapp-frontend:\" + version;\nvar replicas = 1;\nvar port = 80;\nvar clusterPort = 3001;\nvar nodePort = 31030;\nvar deploymentFileName = \"deployment.yml\";\nvar serviceFileName = \"service.yml\";\nvar registrysecret = \"registrykey\";\nvar url = \"http://\" + baseUrl + \":\" + nodePort;\nvar timeout = 2;\n\nvar deleteDeployment = kubectl + \" delete deployment \" + name;\nexecute(deleteDeployment);\n\nvar dfw = new FileWriter(deploymentFileName);\ndfw.write(\"apiVersion: extensions/v1beta1\\n\");\ndfw.write(\"kind: Deployment\\n\");\ndfw.write(\"metadata:\\n\");\ndfw.write(\"  name: \" + name + \"\\n\");\ndfw.write(\"spec:\\n\");\ndfw.write(\"  replicas: \" + replicas + \"\\n\");\ndfw.write(\"  template:\\n\");\ndfw.write(\"    metadata:\\n\");\ndfw.write(\"      labels:\\n\");\ndfw.write(\"        name: \" + name + \"\\n\");\ndfw.write(\"    spec:\\n\");\ndfw.write(\"      containers:\\n\");\ndfw.write(\"      - resources:\\n\");\ndfw.write(\"        name: \" + name + \"\\n\");\ndfw.write(\"        image: \" + image + \"\\n\");\ndfw.write(\"        ports:\\n\");\ndfw.write(\"        - name: port\\n\");\ndfw.write(\"          containerPort: \" + port + \"\\n\");\ndfw.write(\"        volumeMounts:\\n\");\ndfw.write(\"        - name: environment\\n\");\ndfw.write(\"          mountPath: /usr/share/nginx/html/environment\\n\");\ndfw.write(\"      volumes:\\n\");\ndfw.write(\"      - name: environment\\n\");\ndfw.write(\"        configMap:\\n\");\ndfw.write(\"          name: battleapp-frontend-test\\n\");\ndfw.write(\"          items:\\n\");\ndfw.write(\"          - key: environment.json\\n\");\ndfw.write(\"            path: environment.json\\n\");\ndfw.write(\"      imagePullSecrets:\\n\");\ndfw.write(\"      - name: \" + registrysecret + \"\\n\");\ndfw.close();\n\nvar deploy = kubectl + \" create -f \" + deploymentFileName;\nexecute(deploy);\n\nvar deleteService = kubectl + \" delete service \" + name;\nexecute(deleteService);\n\nvar sfw = new FileWriter(serviceFileName);\nsfw.write(\"apiVersion: v1\\n\");\nsfw.write(\"kind: Service\\n\");\nsfw.write(\"metadata:\\n\");\nsfw.write(\"  name: \" + name + \"\\n\");\nsfw.write(\"  labels:\\n\");\nsfw.write(\"    name: \" + name + \"\\n\");\nsfw.write(\"spec:\\n\");\nsfw.write(\"  ports:\\n\");\nsfw.write(\"  - port: \" + clusterPort + \"\\n\");\nsfw.write(\"    targetPort: \" + port + \"\\n\");\nsfw.write(\"    nodePort: \" + nodePort + \"\\n\");\nsfw.write(\"  selector:\\n\");\nsfw.write(\"    name: \" + name + \"\\n\");\nsfw.write(\"  type: NodePort\\n\");\nsfw.close();\n\nvar deployService = kubectl + \" create -f \" + serviceFileName;\nexecute(deployService);\n\nvar testUrl = \"curl --write-out %{http_code} --silent --output /dev/null \" + url + \" --max-time \" + timeout;\nexecute(testUrl);\nwhile ($OUT != \"200\") {\n    $EXEC(\"sleep 1\");\n    execute(testUrl);\n}\n\nfunction execute(command) {\n    $EXEC(command);\n    print($OUT);\n    print($ERR);\n}  It is important to make this script file executable:  chmod 750 start.js  And the corresponding pipeline entry:  stage \"start test environment\"\nnode {\n  git url: \"http://disruptor.ninja:30130/rob/battleapp-frontend-starttestenv\"\n  sh \"./start.js\"\n}  After the test environment we add a manual pipeline step:  stage \"manual testing\"\ninput \"everything ok?\"  The next step is the canary release:  #!/usr/bin/jjs -fv\n\nvar FileWriter = Java.type(\"java.io.FileWriter\");\n\nvar version = $ENV.VERSION;\nvar kubectl = $ENV.KUBECTL;\n\nvar name = \"battleapp-frontend\";\nvar nameWithVersion = name + \"-\" + version;\nvar image = \"disruptor.ninja:30500/robertbrem/\" + name + \":\" + version;\nvar replicas = 1;\nvar port = 80;\nvar clusterPort = 3002;\nvar nodePort = 30030;\nvar deploymentFileName = \"deployment.yml\";\nvar serviceFileName = \"service.yml\";\nvar registrysecret = \"registrykey\";\nvar relativeUrl = \"/\";\nvar url = \"http://disruptor.ninja:\" + nodePort;\nvar timeout = 2;\nvar initialDelay = 15;\nvar readinessProbeTimeout = 10;\n\nvar dfw = new FileWriter(deploymentFileName);\ndfw.write(\"apiVersion: extensions/v1beta1\\n\");\ndfw.write(\"kind: Deployment\\n\");\ndfw.write(\"metadata:\\n\");\ndfw.write(\"  name: \" + nameWithVersion + \"\\n\");\ndfw.write(\"spec:\\n\");\ndfw.write(\"  replicas: \" + replicas + \"\\n\");\ndfw.write(\"  template:\\n\");\ndfw.write(\"    metadata:\\n\");\ndfw.write(\"      labels:\\n\");\ndfw.write(\"        name: \" + name + \"\\n\");\ndfw.write(\"        version: \" + version + \"\\n\");\ndfw.write(\"    spec:\\n\");\ndfw.write(\"      containers:\\n\");\ndfw.write(\"      - resources:\\n\");\ndfw.write(\"        name: \" + name + \"\\n\");\ndfw.write(\"        image: \" + image + \"\\n\");\ndfw.write(\"        ports:\\n\");\ndfw.write(\"        - name: port\\n\");\ndfw.write(\"          containerPort: \" + port + \"\\n\");\ndfw.write(\"        readinessProbe:\\n\");\ndfw.write(\"          httpGet:\\n\");\ndfw.write(\"            path: \" + relativeUrl + \"\\n\");\ndfw.write(\"            port: \" + port + \"\\n\");\ndfw.write(\"          initialDelaySeconds: \" + initialDelay + \"\\n\");\ndfw.write(\"          timeoutSeconds: \" + readinessProbeTimeout + \"\\n\");\ndfw.write(\"        volumeMounts:\\n\");\ndfw.write(\"        - name: environment\\n\");\ndfw.write(\"          mountPath: /usr/share/nginx/html/environment\\n\");\ndfw.write(\"      volumes:\\n\");\ndfw.write(\"      - name: environment\\n\");\ndfw.write(\"        configMap:\\n\");\ndfw.write(\"          name: battleapp-frontend\\n\");\ndfw.write(\"          items:\\n\");\ndfw.write(\"          - key: environment.json\\n\");\ndfw.write(\"            path: environment.json\\n\");\ndfw.write(\"      imagePullSecrets:\\n\");\ndfw.write(\"      - name: \" + registrysecret + \"\\n\");\ndfw.close();\n\nvar deploy = kubectl + \" create -f \" + deploymentFileName;\nexecute(deploy);\n\nvar sfw = new FileWriter(serviceFileName);\nsfw.write(\"apiVersion: v1\\n\");\nsfw.write(\"kind: Service\\n\");\nsfw.write(\"metadata:\\n\");\nsfw.write(\"  name: \" + name + \"\\n\");\nsfw.write(\"  labels:\\n\");\nsfw.write(\"    name: \" + name + \"\\n\");\nsfw.write(\"spec:\\n\");\nsfw.write(\"  ports:\\n\");\nsfw.write(\"  - port: \" + clusterPort + \"\\n\");\nsfw.write(\"    targetPort: \" + port + \"\\n\");\nsfw.write(\"    nodePort: \" + nodePort + \"\\n\");\nsfw.write(\"  selector:\\n\");\nsfw.write(\"    name: \" + name + \"\\n\");\nsfw.write(\"  type: NodePort\\n\");\nsfw.close();\n\nvar deployService = kubectl + \" create -f \" + serviceFileName;\nexecute(deployService);\n\nvar testUrl = \"curl --write-out %{http_code} --silent --output /dev/null \" + url + \" --max-time \" + timeout;\nexecute(testUrl);\nwhile ($OUT != \"200\") {\n    $EXEC(\"sleep 1\");\n    execute(testUrl);\n}\n\nfunction execute(command) {\n    $EXEC(command);\n    print($OUT);\n    print($ERR);\n}  Make the script file executable:  chmod 750 start.js  The corresponding pipeline entry:  stage \"start canary\"\ninput \"deploy the canary?\"\nnode {\n  git url: \"http://disruptor.ninja:30130/rob/battleapp-frontend-canary\"\n  sh \"./start.js\"\n}  The last step is the production step with the following script:  #!/usr/bin/jjs -fv\n\nvar version = $ENV.VERSION;\nvar kubectl = $ENV.KUBECTL;\n\nvar name = \"battleapp-frontend\";\nvar url = \"http://disruptor.ninja:30030\";\nvar timeout = 2;\n\nvar deleteDeployment = kubectl + \" delete deployment -l name=\" + name + \",version!=\" + version;\nexecute(deleteDeployment);\n\nvar testUrl = \"curl --write-out %{http_code} --silent --output /dev/null \" + url + \" --max-time \" + timeout;\nexecute(testUrl);\nwhile ($OUT != \"200\") {\n    $EXEC(\"sleep 1\");\n    execute(testUrl);\n}\n\nfunction execute(command) {\n    $EXEC(command);\n    print($OUT);\n    print($ERR);\n}  Make the script file executable:  chmod 750 start.js  The corresponding pipeline entry:  stage \"go full production\"\ninput \"undeploy other versions?\"\nnode {\n  git url: \"http://disruptor.ninja:30130/rob/battleapp-frontend-prod\"\n  sh \"./start.js\"\n}",
            "title": "Create a test and production stage"
        },
        {
            "location": "/15_Angular2_frontend/Test_and_prod_stage/#creation-of-kubernetes-configmap",
            "text": "In both the test and the production stage we referenced a Kubernetes\nConfigMap that we've to create first. Therefore we have to create a folder\non the local machine with the name  battleapp-frontend  and a file  environment.json  with the following content:  {\n  \"host\": \"disruptor.ninja\",\n  \"port\": 30080\n}  We need also a  environment.json  file for the test stage. Therefore we \ncreate a folder  battleapp-frontend-test  and a file  environment.json \nwith the following content:  {\n  \"host\": \"disruptor.ninja\",\n  \"port\": 31080\n}  Now we create the two ConfigMaps:  kc create configmap battleapp-frontend-test --from-file=battleapp-frontend-test\nkc create configmap battleapp-frontend --from-file=battleapp-frontend  We can test display the ConfigMaps with the following command:  kc get configmap battleapp-frontend-test -o yaml  apiVersion: v1\ndata:\n  environment.json: |\n    {\n      \"host\": \"disruptor.ninja\",\n      \"port\": 31080\n    }\nkind: ConfigMap\nmetadata:\n  creationTimestamp: 2016-12-31T15:54:44Z\n  name: battleapp-frontend-test\n  namespace: default\n  resourceVersion: \"1049486\"\n  selfLink: /api/v1/namespaces/default/configmaps/battleapp-frontend-test\n  uid: 72a5399b-cf71-11e6-a836-0050563cad2a",
            "title": "Creation of Kubernetes ConfigMap"
        },
        {
            "location": "/16_SSO_with_Keycloak/Initial_setup_of_Keycloak/",
            "text": "Initial setup of Keycloak\n\n\nThat we can use Keyclaok for our \njax-rs\n service and our Angular2 frontend\nwe have to create some roles and a user.\n\n\nStart a local Keycloak server\n\n\nThat we can test our application on the local machine we've to start a \nKeycloak server locally.\n\n\nFor our local Keycloak server we don't need SSL therefore we can use the\nofficially image directly. But first we need to create a local folder\nwhere Keycloak can store its persistent data:\n\n\nmkdir -p ~/Desktop/dockervolumes/keycloakdata\n\n\n\n\nSet the rights of the folder to \n1000:1000\n:\n\n\nchown -R 1000:1000 ~/Desktop/dockervolumes/keycloakdata\n\n\n\n\nAnd now we can start our local Keycloak server.\n\n\ndocker run -d -e KEYCLOAK_USER=admin -e KEYCLOAK_PASSWORD=admin -p 8280:8080 -v ~/Desktop/dockervolumes/keycloakdata/:/opt/jboss/keycloak/standalone/data --name keycloak jboss/keycloak:2.4.0.Final\n\n\n\n\nCreate Keycloak roles and users\n\n\nOpen the Keycloak console on \nhttp://localhost:8280/auth/admin\n.\n\n\n\n\nLogin in with the user \nadmin\n and the password \nadmin\n. We've defined this\npassword on the startup of the Docker container.\n\n\nKeycloak displays the Master realm. That's the realm for Keycloak itself.\nFor our application we need an own realm therefore we've to create one.\nClick on \nMaster\n and a button \nAdd realm\n appears.\n\n\n\n\nWe choose the name \nbattleapp-local\n for our local Keycloak.\n\n\n\n\nWe also have to create two realms on our Keycloak that we've started in\nKubernetes. One for the test stage and one for the production stage.\nI called them \nbattleapp-test\n and \nbattleapp\n.\n\n\n\n\n\n\nClick \nCreate\n.\n\n\nFirst we're going to create two roles \nuser\n and \nadmin\n. Change to the \n\nRoles\n tab and create these two roles.\n\n\n\n\nClick on the button \nAdd Role\n.\n\n\n\n\nClick \nSave\n and do the same for \nadmin\n.\n\n\nWhen we've the roles we can create a user and add these roles to the user.\nChange to the \nUsers\n tab and create a user.\n\n\n\n\nClick on the button \nAdd user\n.\n\n\n\n\nClick \nSave\n.\n\n\nThat the user can login he need a password. Therefore we've to change \nto the \nCredentials\n tab and enter a password.\n\n\n\n\nClick \nReset Password\n -> \nChange Password\n.\n\n\nThe last setting we've to make is to assign the created roles to our user.\nChange to the \nRole Mappings\n tab and assign the \nuser\n and \nadmin\n role\nfrom \nAvailable Roles\n to \nAssigned Roles\n.\n\n\n\n\nAdd the REST service and the frontend\n\n\nKeycloak need to know where our applications are running. We can setup our\ntwo microservices in the \nClient\n tab.\n\n\n\n\nClick on the button \nCreate\n.\n\nThe REST service is the first service we're going to create.\n\n\n\n\nClick \nSave\n.\n\n\nChange the \nAccess Type\n to \nbearer-only\n and click \nSave\n.\n\n\n\n\nThat was all for the REST service now we can create the frontend service.\n\n\n\n\nClick \nSave\n.\n\n\nThe frontend service is of the already chosen \nAccess Type\n \npublic\n.",
            "title": "Initial setup of Keycloak"
        },
        {
            "location": "/16_SSO_with_Keycloak/Initial_setup_of_Keycloak/#initial-setup-of-keycloak",
            "text": "That we can use Keyclaok for our  jax-rs  service and our Angular2 frontend\nwe have to create some roles and a user.",
            "title": "Initial setup of Keycloak"
        },
        {
            "location": "/16_SSO_with_Keycloak/Initial_setup_of_Keycloak/#start-a-local-keycloak-server",
            "text": "That we can test our application on the local machine we've to start a \nKeycloak server locally.  For our local Keycloak server we don't need SSL therefore we can use the\nofficially image directly. But first we need to create a local folder\nwhere Keycloak can store its persistent data:  mkdir -p ~/Desktop/dockervolumes/keycloakdata  Set the rights of the folder to  1000:1000 :  chown -R 1000:1000 ~/Desktop/dockervolumes/keycloakdata  And now we can start our local Keycloak server.  docker run -d -e KEYCLOAK_USER=admin -e KEYCLOAK_PASSWORD=admin -p 8280:8080 -v ~/Desktop/dockervolumes/keycloakdata/:/opt/jboss/keycloak/standalone/data --name keycloak jboss/keycloak:2.4.0.Final",
            "title": "Start a local Keycloak server"
        },
        {
            "location": "/16_SSO_with_Keycloak/Initial_setup_of_Keycloak/#create-keycloak-roles-and-users",
            "text": "Open the Keycloak console on  http://localhost:8280/auth/admin .   Login in with the user  admin  and the password  admin . We've defined this\npassword on the startup of the Docker container.  Keycloak displays the Master realm. That's the realm for Keycloak itself.\nFor our application we need an own realm therefore we've to create one.\nClick on  Master  and a button  Add realm  appears.   We choose the name  battleapp-local  for our local Keycloak.   We also have to create two realms on our Keycloak that we've started in\nKubernetes. One for the test stage and one for the production stage.\nI called them  battleapp-test  and  battleapp .    Click  Create .  First we're going to create two roles  user  and  admin . Change to the  Roles  tab and create these two roles.   Click on the button  Add Role .   Click  Save  and do the same for  admin .  When we've the roles we can create a user and add these roles to the user.\nChange to the  Users  tab and create a user.   Click on the button  Add user .   Click  Save .  That the user can login he need a password. Therefore we've to change \nto the  Credentials  tab and enter a password.   Click  Reset Password  ->  Change Password .  The last setting we've to make is to assign the created roles to our user.\nChange to the  Role Mappings  tab and assign the  user  and  admin  role\nfrom  Available Roles  to  Assigned Roles .",
            "title": "Create Keycloak roles and users"
        },
        {
            "location": "/16_SSO_with_Keycloak/Initial_setup_of_Keycloak/#add-the-rest-service-and-the-frontend",
            "text": "Keycloak need to know where our applications are running. We can setup our\ntwo microservices in the  Client  tab.   Click on the button  Create . \nThe REST service is the first service we're going to create.   Click  Save .  Change the  Access Type  to  bearer-only  and click  Save .   That was all for the REST service now we can create the frontend service.   Click  Save .  The frontend service is of the already chosen  Access Type   public .",
            "title": "Add the REST service and the frontend"
        },
        {
            "location": "/16_SSO_with_Keycloak/README/",
            "text": "SOO with Keycloak\n\n\n\n\nSetup Keycloak\n\n\nInitial setup of Keycloak\n\n\nSecure the REST service\n\n\nSecure the frontend service",
            "title": "README"
        },
        {
            "location": "/16_SSO_with_Keycloak/README/#soo-with-keycloak",
            "text": "Setup Keycloak  Initial setup of Keycloak  Secure the REST service  Secure the frontend service",
            "title": "SOO with Keycloak"
        },
        {
            "location": "/16_SSO_with_Keycloak/Secure_REST_service/",
            "text": "Secure the \njax-rs\n service\n\n\nPatch Wildfly with the Keycloak adapter\n\n\nThe first thing we've to change is the \nDockerfile\n of the REST service.\nWildfly need the Keyclaok adapter that it can use Keycloak. Luckily there's\nalready a Docker image for that \njboss/keycloak-adapter-wildfly\n. Our whole\nDockerimage looks like the flowing:\n\n\nFROM jboss/keycloak-adapter-wildfly:2.4.0.Final\n\nMAINTAINER Robert Brem <brem_robert@hotmail.com>\n\nENV DEPLOYMENT_DIR ${JBOSS_HOME}/standalone/deployments/\n\nADD target/battleapp.war ${DEPLOYMENT_DIR}\n\n\n\n\nThat we can test our service locally as well we've to patch our local Wildfly\nas well. We've to do exactly the same as \n\nthe Docker image\n \ndoes.\n\n\nChange into the local Wildfly directory and execute the following command:\n\n\nKEYCLOAK_VERSION=2.4.0.Final curl -L https://downloads.jboss.org/keycloak/$KEYCLOAK_VERSION/adapters/keycloak-oidc/keycloak-wildfly-adapter-dist-$KEYCLOAK_VERSION.tar.gz | tar zx\n\n\n\n\nThen execute the following command:\n\n\nsed -i -e 's/<extensions>/&\\n        <extension module=\"org.keycloak.keycloak-adapter-subsystem\"\\/>/' standalone/configuration/standalone.xml && \\\nsed -i -e 's/<profile>/&\\n        <subsystem xmlns=\"urn:jboss:domain:keycloak:1.1\"\\/>/' standalone/configuration/standalone.xml && \\\nsed -i -e 's/<security-domains>/&\\n                <security-domain name=\"keycloak\">\\n                    <authentication>\\n                        <login-module code=\"org.keycloak.adapters.jboss.KeycloakLoginModule\" flag=\"required\"\\/>\\n                    <\\/authentication>\\n                <\\/security-domain>/' standalone/configuration/standalone.xml\n\n\n\n\nSetup the project with Keycloak\n\n\nTo secure the REST service we've to create a \nweb.xml\n file like we would do it\nfor normal basic authentication. The flowing \nweb.xml\n is located in the \n\nsrc/main/webapp/WEB-INF\n folder.\n\n\n<web-app xmlns=\"http://java.sun.com/xml/ns/javaee\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd\"\n         version=\"3.0\">\n\n    <security-constraint>\n        <web-resource-collection>\n            <web-resource-name>health</web-resource-name>\n            <url-pattern>/resources/health</url-pattern>\n        </web-resource-collection>\n        <!-- OMIT auth-constraint -->\n    </security-constraint>\n\n    <security-constraint>\n        <web-resource-collection>\n            <web-resource-name>cors</web-resource-name>\n            <url-pattern>/*</url-pattern>\n            <http-method>GET</http-method>\n            <http-method>POST</http-method>\n            <http-method>PUT</http-method>\n            <http-method>DELETE</http-method>\n        </web-resource-collection>\n        <auth-constraint>\n            <role-name>user</role-name>\n        </auth-constraint>\n    </security-constraint>\n\n    <login-config>\n        <auth-method>KEYCLOAK</auth-method>\n        <realm-name>this is ignored currently</realm-name>\n    </login-config>\n\n    <security-role>\n        <role-name>admin</role-name>\n    </security-role>\n    <security-role>\n        <role-name>user</role-name>\n    </security-role>\n</web-app>\n\n\n\n\nHere we can see the roles \nadmin\n and \nuser\n we've previously created in the\nKeycloak console. Additionally there's a \nhealth\n endpoint that's not secured.\nThis is the endpoint on which Kubernetes checks if the application is deployed\nand therefore ready. We're going to create this endpoint later.\n\n\nNow we've to define where our Keycloak server is running and which realm we\nwant to use. This can be done in a \nkeycloak.json\n that's located in the same\nfolder \nsrc/main/webapp/WEB-INF\n.\n\n\n{\n  \"realm\": \"${env.REALM_NAME}\",\n  \"bearer-only\": true,\n  \"auth-server-url\": \"${env.AUTH_SERVER_URL}\",\n  \"ssl-required\": \"none\",\n  \"resource\": \"battleapp\"\n}\n\n\n\n\nThat we can use the same \nwar\n on different stages we have to set the realm\nname and the server url over environment variables. For the local setup we've\nto open the Wildfly configuration:\n\n\n\n\nChange in the \nStartup/Connection\n tab and add the two environment variables.\n\n\n\n\nCreate the health check\n\n\nThat Kubernetes recognized if the application is up and running we've to \ncreate the health check we've already defined in the \nweb.xml\n.\n\n\n@Path(\"health\")\npublic class HealthResource {\n\n    @Dedicated\n    @Inject\n    ExecutorService healthPool;\n\n    @GET\n    public void getHealth(@Suspended AsyncResponse response) {\n        CompletableFuture\n                .supplyAsync(this::getHealthText, healthPool)\n                .thenAccept(response::resume);\n    }\n\n    public String getHealthText() {\n        return \"everything ok!\";\n    }\n}\n\n\n\n\nNow we can start the local Wildfly with the secured application.\n\n\nSecure test environment\n\n\nTo let the application run in our test stage we've to make some adaptions\nto the \nstart.js\n file from the start test environment project.\nFirst of all we've to change the test url from \n\nhttp://disruptor.ninja:31080/battleapp/resources/users\n to\n\nhttp://disruptor.ninja:31080/battleapp/resources/health\n.\n\nThen we've to add the two environment variables for Keycloak:\n\n\n...\nvar realmName = \"battleapp-test\";\nvar authServerUrl = \"https://disruptor.ninja:30182/auth\";\n...\ndfw.write(\"        env:\\n\");\ndfw.write(\"        - name: REALM_NAME\\n\");\ndfw.write(\"          value: \\\"\" + realmName + \"\\\"\\n\");\ndfw.write(\"        - name: AUTH_SERVER_URL\\n\");\ndfw.write(\"          value: \\\"\" + authServerUrl + \"\\\"\\n\");\n...\n\n\n\n\nNow the deployment on the test stage is secured.\n\n\nSecure prod environment\n\n\nTo let the application run in our prod stage we've to make some adaptions\nto the \nstart.js\n file from the canary environment project.\nFirst of all we've to change the test url from \n\nhttp://disruptor.ninja:30080/battleapp/resources/users\n to\n\nhttp://disruptor.ninja:30080/battleapp/resources/health\n.\n\nThen we've to add the two environment variables for Keycloak:\n\n\n...\nvar realmName = \"battleapp\";\nvar authServerUrl = \"https://disruptor.ninja:30182/auth\";\n...\ndfw.write(\"        env:\\n\");\ndfw.write(\"        - name: REALM_NAME\\n\");\ndfw.write(\"          value: \\\"\" + realmName + \"\\\"\\n\");\ndfw.write(\"        - name: AUTH_SERVER_URL\\n\");\ndfw.write(\"          value: \\\"\" + authServerUrl + \"\\\"\\n\");\n...\n\n\n\n\nSystem test of the secured service\n\n\nOur system test tries to test the secured \nusers\n url. Therefore we've to\ntell the test how to access the secured endpoint.\nTo access the service we need to add the \nkeycloak-wildfly-adapter\n:\n\n\n<dependency>\n    <groupId>org.keycloak</groupId>\n    <artifactId>keycloak-wildfly-adapter</artifactId>\n    <version>2.4.0.Final</version>\n    <scope>test</scope>\n</dependency>\n\n\n\n\nNow we can create a class that requests a token form the Keycloak server:\n\n\npublic class KeycloakHeaderCreater {\n\n    public static final String CLIENT_ID = \"battleapp-frontend\";\n    public static final String REALM = System.getenv(\"REALM_NAME\");\n    public static final String KEYCLOAK_URL = System.getenv(\"KEYCLOAK_URL\");\n\n    public static AccessTokenResponse getTokenResponse(String user, String password) throws IOException {\n        HttpClient client = new HttpClientBuilder().disableTrustManager().build();\n        try {\n            HttpPost post = new HttpPost(KeycloakUriBuilder.fromUri(KEYCLOAK_URL)\n                    .path(ServiceUrlConstants.TOKEN_PATH).build(REALM));\n            List<NameValuePair> formparams = new ArrayList<>();\n            formparams.add(new BasicNameValuePair(OAuth2Constants.GRANT_TYPE, \"password\"));\n            formparams.add(new BasicNameValuePair(\"username\", user));\n            formparams.add(new BasicNameValuePair(\"password\", password));\n\n            formparams.add(new BasicNameValuePair(OAuth2Constants.CLIENT_ID, CLIENT_ID));\n\n            UrlEncodedFormEntity form = new UrlEncodedFormEntity(formparams, \"UTF-8\");\n            post.setEntity(form);\n            HttpResponse response = client.execute(post);\n            int status = response.getStatusLine().getStatusCode();\n            HttpEntity entity = response.getEntity();\n            if (status != 200) {\n                throw new IOException(\"Bad status: \" + status);\n            }\n            if (entity == null) {\n                throw new IOException(\"No Entity\");\n            }\n            InputStream is = entity.getContent();\n            try {\n                AccessTokenResponse tokenResponse = JsonSerialization.readValue(is, AccessTokenResponse.class);\n                return tokenResponse;\n            } finally {\n                try {\n                    is.close();\n                } catch (IOException ignored) {\n                }\n            }\n        } finally {\n            client.getConnectionManager().shutdown();\n        }\n    }\n\n}\n\n\n\n\nWe need a token when we request the users from the service:\n\n\n@Test\n    public void shouldReturn200() throws IOException {\n        String token = KeycloakHeaderCreater\n                .getTokenResponse(\n                        System.getenv(\"APPLICATION_USER_NAME\"),\n                        System.getenv(\"APPLICATION_PASSWORD\"))\n                .getToken();\n        Response response = provider\n                .target()\n                .request()\n                .header(\"Authorization\", \"Bearer \" + token)\n                .get();\n        assertThat(response.getStatus(), is(200));\n    }\n\n\n\n\nYou can run the test locally with the following command:\n\n\nHOST=localhost PORT=8080 APPLICATION_USER_NAME=rob APPLICATION_PASSWORD=1234 REALM_NAME=battleapp-local KEYCLOAK_URL=http://localhost:8280/auth mvn clean install failsafe:integration-test failsafe:verify\n\n\n\n\nFinally we've to add the environment variables in the pipeline project:\n\n\nwithEnv([   \"VERSION=1.0.${currentBuild.number}\",\n            \"REGISTRY_EMAIL=brem_robert@hotmail.com\",\n            \"KUBECTL=kubectl\",\n            \"HOST=disruptor.ninja\",\n            \"KEYCLOAK_URL=https://disruptor.ninja:30182/auth\"]) {\n\n  ...\n\n  stage \"system test\"\n  node {\n    git url: \"http://disruptor.ninja:30130/rob/battleapp-st\"\n    def mvnHome = tool 'M3'\n    sh \"PORT=31080 REALM_NAME=battleapp-test ${mvnHome}/bin/mvn clean install failsafe:integration-test failsafe:verify\"\n    step([$class: 'JUnitResultArchiver', testResults: '**/target/failsafe-reports/TEST-*.xml'])\n  }\n\n  ...\n\n\n\n\n\nUI test of the secured service\n\n\nOur ui test tries to test the secured \nusers\n url. Therefore we've to\nchange the url to the \nhealth\n url.\n\n\n@Location(\"http://disruptor.ninja:31080/battleapp/resources/health\")\npublic class BattleAppPage {\n}\n\n\n\n\nAnd the expected text:\n\n\n@RunAsClient\n@RunWith(Arquillian.class)\npublic class BattleAppIT {\n\n    @Drone\n    WebDriver browser;\n\n    @Test\n    public void shouldContainRobert(@InitialPage BattleAppPage page) {\n        String expectedToContain = \"everything ok!\";\n        String content = browser.getPageSource();\n        assertThat(content, containsString(expectedToContain));\n    }\n\n}\n\n\n\n\nThe test can locally be executed with the same run configuration like before.\n\n\nLast test of the secured service\n\n\nOur last test tries to test the secured \nusers\n url. Therefore we've to\nchange the url to the \nhealth\n url inside the Jenkins pipeline:\n\n\n  stage \"last test\"\n  node {\n    git url: \"https://github.com/robertBrem/BattleApp-LT\"\n    def mvnHome = tool 'M3'\n    sh \"${mvnHome}/bin/mvn clean verify -Dperformancetest.webservice.host=disruptor.ninja -Dperformancetest.webservice.port=31080 -Dperformancetest.webservice.threads=5 -Dperformancetest.webservice.iterations=500 -Dperformancetest.webservice.url=/battleapp/resources/health\"\n    archiveArtifacts artifacts: 'target/reports/*.*', fingerprint: true\n  }\n\n\n\n\nThe test can locally be executed with the following command:\n\n\nmvn clean verify -Dperformancetest.webservice.host=localhost -Dperformancetest.webservice.port=8080 -Dperformancetest.webservice.threads=2 -Dperformancetest.webservice.iterations=50 -Dperformancetest.webservice.url=/battleapp/resources/health\n\n\n\n\nConsumer driven contract test of the secured service\n\n\nThe consumer driven contract test has to be adapted exaclty the same way as\nthe system test from before.\n\n\npublic class BattleAppIT {\n\n    @Rule\n    public JAXRSClientProvider provider = buildWithURI(\"http://\" + System.getenv(\"HOST\") + \":\" + System.getenv(\"PORT\") + \"/battleapp/resources/users\");\n\n    @Test\n    public void shouldReturnDan() throws IOException {\n        String expectedToContain = \"Dan\";\n        String token = KeycloakTokenCreator\n                .getTokenResponse(\n                        System.getenv(\"APPLICATION_USER_NAME\"),\n                        System.getenv(\"APPLICATION_PASSWORD\"))\n                .getToken();\n        String response = provider\n                .target()\n                .request()\n                .header(\"Authorization\", \"Bearer \" + token)\n                .get(String.class);\n        assertThat(response, containsString(expectedToContain));\n    }\n\n}\n\n\n\n\nThe test can be locally executed with the following command:\n\n\nHOST=localhost PORT=8080 APPLICATION_USER_NAME=rob APPLICATION_PASSWORD=1234 REALM_NAME=battleapp-local KEYCLOAK_URL=http://localhost:8280/auth mvn clean install failsafe:integration-test failsafe:verify\n\n\n\n\nThe pipeline step has to be extended with the \nREALM_NAME\n as well as the\nsystem test was before.\n\n\nstage \"consumer driven contract test\"\nnode {\n  git url: \"http://disruptor.ninja:30130/rob/battleapp-cdct\"\n  def mvnHome = tool 'M3'\n  sh \"PORT=31080 REALM_NAME=battleapp-test ${mvnHome}/bin/mvn clean install failsafe:integration-test failsafe:verify\"\n  step([$class: 'JUnitResultArchiver', testResults: '**/target/failsafe-reports/TEST-*.xml'])\n}",
            "title": "Secure REST service"
        },
        {
            "location": "/16_SSO_with_Keycloak/Secure_REST_service/#secure-the-jax-rs-service",
            "text": "",
            "title": "Secure the jax-rs service"
        },
        {
            "location": "/16_SSO_with_Keycloak/Secure_REST_service/#patch-wildfly-with-the-keycloak-adapter",
            "text": "The first thing we've to change is the  Dockerfile  of the REST service.\nWildfly need the Keyclaok adapter that it can use Keycloak. Luckily there's\nalready a Docker image for that  jboss/keycloak-adapter-wildfly . Our whole\nDockerimage looks like the flowing:  FROM jboss/keycloak-adapter-wildfly:2.4.0.Final\n\nMAINTAINER Robert Brem <brem_robert@hotmail.com>\n\nENV DEPLOYMENT_DIR ${JBOSS_HOME}/standalone/deployments/\n\nADD target/battleapp.war ${DEPLOYMENT_DIR}  That we can test our service locally as well we've to patch our local Wildfly\nas well. We've to do exactly the same as  the Docker image  \ndoes.  Change into the local Wildfly directory and execute the following command:  KEYCLOAK_VERSION=2.4.0.Final curl -L https://downloads.jboss.org/keycloak/$KEYCLOAK_VERSION/adapters/keycloak-oidc/keycloak-wildfly-adapter-dist-$KEYCLOAK_VERSION.tar.gz | tar zx  Then execute the following command:  sed -i -e 's/<extensions>/&\\n        <extension module=\"org.keycloak.keycloak-adapter-subsystem\"\\/>/' standalone/configuration/standalone.xml && \\\nsed -i -e 's/<profile>/&\\n        <subsystem xmlns=\"urn:jboss:domain:keycloak:1.1\"\\/>/' standalone/configuration/standalone.xml && \\\nsed -i -e 's/<security-domains>/&\\n                <security-domain name=\"keycloak\">\\n                    <authentication>\\n                        <login-module code=\"org.keycloak.adapters.jboss.KeycloakLoginModule\" flag=\"required\"\\/>\\n                    <\\/authentication>\\n                <\\/security-domain>/' standalone/configuration/standalone.xml",
            "title": "Patch Wildfly with the Keycloak adapter"
        },
        {
            "location": "/16_SSO_with_Keycloak/Secure_REST_service/#setup-the-project-with-keycloak",
            "text": "To secure the REST service we've to create a  web.xml  file like we would do it\nfor normal basic authentication. The flowing  web.xml  is located in the  src/main/webapp/WEB-INF  folder.  <web-app xmlns=\"http://java.sun.com/xml/ns/javaee\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd\"\n         version=\"3.0\">\n\n    <security-constraint>\n        <web-resource-collection>\n            <web-resource-name>health</web-resource-name>\n            <url-pattern>/resources/health</url-pattern>\n        </web-resource-collection>\n        <!-- OMIT auth-constraint -->\n    </security-constraint>\n\n    <security-constraint>\n        <web-resource-collection>\n            <web-resource-name>cors</web-resource-name>\n            <url-pattern>/*</url-pattern>\n            <http-method>GET</http-method>\n            <http-method>POST</http-method>\n            <http-method>PUT</http-method>\n            <http-method>DELETE</http-method>\n        </web-resource-collection>\n        <auth-constraint>\n            <role-name>user</role-name>\n        </auth-constraint>\n    </security-constraint>\n\n    <login-config>\n        <auth-method>KEYCLOAK</auth-method>\n        <realm-name>this is ignored currently</realm-name>\n    </login-config>\n\n    <security-role>\n        <role-name>admin</role-name>\n    </security-role>\n    <security-role>\n        <role-name>user</role-name>\n    </security-role>\n</web-app>  Here we can see the roles  admin  and  user  we've previously created in the\nKeycloak console. Additionally there's a  health  endpoint that's not secured.\nThis is the endpoint on which Kubernetes checks if the application is deployed\nand therefore ready. We're going to create this endpoint later.  Now we've to define where our Keycloak server is running and which realm we\nwant to use. This can be done in a  keycloak.json  that's located in the same\nfolder  src/main/webapp/WEB-INF .  {\n  \"realm\": \"${env.REALM_NAME}\",\n  \"bearer-only\": true,\n  \"auth-server-url\": \"${env.AUTH_SERVER_URL}\",\n  \"ssl-required\": \"none\",\n  \"resource\": \"battleapp\"\n}  That we can use the same  war  on different stages we have to set the realm\nname and the server url over environment variables. For the local setup we've\nto open the Wildfly configuration:   Change in the  Startup/Connection  tab and add the two environment variables.",
            "title": "Setup the project with Keycloak"
        },
        {
            "location": "/16_SSO_with_Keycloak/Secure_REST_service/#create-the-health-check",
            "text": "That Kubernetes recognized if the application is up and running we've to \ncreate the health check we've already defined in the  web.xml .  @Path(\"health\")\npublic class HealthResource {\n\n    @Dedicated\n    @Inject\n    ExecutorService healthPool;\n\n    @GET\n    public void getHealth(@Suspended AsyncResponse response) {\n        CompletableFuture\n                .supplyAsync(this::getHealthText, healthPool)\n                .thenAccept(response::resume);\n    }\n\n    public String getHealthText() {\n        return \"everything ok!\";\n    }\n}  Now we can start the local Wildfly with the secured application.",
            "title": "Create the health check"
        },
        {
            "location": "/16_SSO_with_Keycloak/Secure_REST_service/#secure-test-environment",
            "text": "To let the application run in our test stage we've to make some adaptions\nto the  start.js  file from the start test environment project.\nFirst of all we've to change the test url from  http://disruptor.ninja:31080/battleapp/resources/users  to http://disruptor.ninja:31080/battleapp/resources/health . \nThen we've to add the two environment variables for Keycloak:  ...\nvar realmName = \"battleapp-test\";\nvar authServerUrl = \"https://disruptor.ninja:30182/auth\";\n...\ndfw.write(\"        env:\\n\");\ndfw.write(\"        - name: REALM_NAME\\n\");\ndfw.write(\"          value: \\\"\" + realmName + \"\\\"\\n\");\ndfw.write(\"        - name: AUTH_SERVER_URL\\n\");\ndfw.write(\"          value: \\\"\" + authServerUrl + \"\\\"\\n\");\n...  Now the deployment on the test stage is secured.",
            "title": "Secure test environment"
        },
        {
            "location": "/16_SSO_with_Keycloak/Secure_REST_service/#secure-prod-environment",
            "text": "To let the application run in our prod stage we've to make some adaptions\nto the  start.js  file from the canary environment project.\nFirst of all we've to change the test url from  http://disruptor.ninja:30080/battleapp/resources/users  to http://disruptor.ninja:30080/battleapp/resources/health . \nThen we've to add the two environment variables for Keycloak:  ...\nvar realmName = \"battleapp\";\nvar authServerUrl = \"https://disruptor.ninja:30182/auth\";\n...\ndfw.write(\"        env:\\n\");\ndfw.write(\"        - name: REALM_NAME\\n\");\ndfw.write(\"          value: \\\"\" + realmName + \"\\\"\\n\");\ndfw.write(\"        - name: AUTH_SERVER_URL\\n\");\ndfw.write(\"          value: \\\"\" + authServerUrl + \"\\\"\\n\");\n...",
            "title": "Secure prod environment"
        },
        {
            "location": "/16_SSO_with_Keycloak/Secure_REST_service/#system-test-of-the-secured-service",
            "text": "Our system test tries to test the secured  users  url. Therefore we've to\ntell the test how to access the secured endpoint.\nTo access the service we need to add the  keycloak-wildfly-adapter :  <dependency>\n    <groupId>org.keycloak</groupId>\n    <artifactId>keycloak-wildfly-adapter</artifactId>\n    <version>2.4.0.Final</version>\n    <scope>test</scope>\n</dependency>  Now we can create a class that requests a token form the Keycloak server:  public class KeycloakHeaderCreater {\n\n    public static final String CLIENT_ID = \"battleapp-frontend\";\n    public static final String REALM = System.getenv(\"REALM_NAME\");\n    public static final String KEYCLOAK_URL = System.getenv(\"KEYCLOAK_URL\");\n\n    public static AccessTokenResponse getTokenResponse(String user, String password) throws IOException {\n        HttpClient client = new HttpClientBuilder().disableTrustManager().build();\n        try {\n            HttpPost post = new HttpPost(KeycloakUriBuilder.fromUri(KEYCLOAK_URL)\n                    .path(ServiceUrlConstants.TOKEN_PATH).build(REALM));\n            List<NameValuePair> formparams = new ArrayList<>();\n            formparams.add(new BasicNameValuePair(OAuth2Constants.GRANT_TYPE, \"password\"));\n            formparams.add(new BasicNameValuePair(\"username\", user));\n            formparams.add(new BasicNameValuePair(\"password\", password));\n\n            formparams.add(new BasicNameValuePair(OAuth2Constants.CLIENT_ID, CLIENT_ID));\n\n            UrlEncodedFormEntity form = new UrlEncodedFormEntity(formparams, \"UTF-8\");\n            post.setEntity(form);\n            HttpResponse response = client.execute(post);\n            int status = response.getStatusLine().getStatusCode();\n            HttpEntity entity = response.getEntity();\n            if (status != 200) {\n                throw new IOException(\"Bad status: \" + status);\n            }\n            if (entity == null) {\n                throw new IOException(\"No Entity\");\n            }\n            InputStream is = entity.getContent();\n            try {\n                AccessTokenResponse tokenResponse = JsonSerialization.readValue(is, AccessTokenResponse.class);\n                return tokenResponse;\n            } finally {\n                try {\n                    is.close();\n                } catch (IOException ignored) {\n                }\n            }\n        } finally {\n            client.getConnectionManager().shutdown();\n        }\n    }\n\n}  We need a token when we request the users from the service:  @Test\n    public void shouldReturn200() throws IOException {\n        String token = KeycloakHeaderCreater\n                .getTokenResponse(\n                        System.getenv(\"APPLICATION_USER_NAME\"),\n                        System.getenv(\"APPLICATION_PASSWORD\"))\n                .getToken();\n        Response response = provider\n                .target()\n                .request()\n                .header(\"Authorization\", \"Bearer \" + token)\n                .get();\n        assertThat(response.getStatus(), is(200));\n    }  You can run the test locally with the following command:  HOST=localhost PORT=8080 APPLICATION_USER_NAME=rob APPLICATION_PASSWORD=1234 REALM_NAME=battleapp-local KEYCLOAK_URL=http://localhost:8280/auth mvn clean install failsafe:integration-test failsafe:verify  Finally we've to add the environment variables in the pipeline project:  withEnv([   \"VERSION=1.0.${currentBuild.number}\",\n            \"REGISTRY_EMAIL=brem_robert@hotmail.com\",\n            \"KUBECTL=kubectl\",\n            \"HOST=disruptor.ninja\",\n            \"KEYCLOAK_URL=https://disruptor.ninja:30182/auth\"]) {\n\n  ...\n\n  stage \"system test\"\n  node {\n    git url: \"http://disruptor.ninja:30130/rob/battleapp-st\"\n    def mvnHome = tool 'M3'\n    sh \"PORT=31080 REALM_NAME=battleapp-test ${mvnHome}/bin/mvn clean install failsafe:integration-test failsafe:verify\"\n    step([$class: 'JUnitResultArchiver', testResults: '**/target/failsafe-reports/TEST-*.xml'])\n  }\n\n  ...",
            "title": "System test of the secured service"
        },
        {
            "location": "/16_SSO_with_Keycloak/Secure_REST_service/#ui-test-of-the-secured-service",
            "text": "Our ui test tries to test the secured  users  url. Therefore we've to\nchange the url to the  health  url.  @Location(\"http://disruptor.ninja:31080/battleapp/resources/health\")\npublic class BattleAppPage {\n}  And the expected text:  @RunAsClient\n@RunWith(Arquillian.class)\npublic class BattleAppIT {\n\n    @Drone\n    WebDriver browser;\n\n    @Test\n    public void shouldContainRobert(@InitialPage BattleAppPage page) {\n        String expectedToContain = \"everything ok!\";\n        String content = browser.getPageSource();\n        assertThat(content, containsString(expectedToContain));\n    }\n\n}  The test can locally be executed with the same run configuration like before.",
            "title": "UI test of the secured service"
        },
        {
            "location": "/16_SSO_with_Keycloak/Secure_REST_service/#last-test-of-the-secured-service",
            "text": "Our last test tries to test the secured  users  url. Therefore we've to\nchange the url to the  health  url inside the Jenkins pipeline:    stage \"last test\"\n  node {\n    git url: \"https://github.com/robertBrem/BattleApp-LT\"\n    def mvnHome = tool 'M3'\n    sh \"${mvnHome}/bin/mvn clean verify -Dperformancetest.webservice.host=disruptor.ninja -Dperformancetest.webservice.port=31080 -Dperformancetest.webservice.threads=5 -Dperformancetest.webservice.iterations=500 -Dperformancetest.webservice.url=/battleapp/resources/health\"\n    archiveArtifacts artifacts: 'target/reports/*.*', fingerprint: true\n  }  The test can locally be executed with the following command:  mvn clean verify -Dperformancetest.webservice.host=localhost -Dperformancetest.webservice.port=8080 -Dperformancetest.webservice.threads=2 -Dperformancetest.webservice.iterations=50 -Dperformancetest.webservice.url=/battleapp/resources/health",
            "title": "Last test of the secured service"
        },
        {
            "location": "/16_SSO_with_Keycloak/Secure_REST_service/#consumer-driven-contract-test-of-the-secured-service",
            "text": "The consumer driven contract test has to be adapted exaclty the same way as\nthe system test from before.  public class BattleAppIT {\n\n    @Rule\n    public JAXRSClientProvider provider = buildWithURI(\"http://\" + System.getenv(\"HOST\") + \":\" + System.getenv(\"PORT\") + \"/battleapp/resources/users\");\n\n    @Test\n    public void shouldReturnDan() throws IOException {\n        String expectedToContain = \"Dan\";\n        String token = KeycloakTokenCreator\n                .getTokenResponse(\n                        System.getenv(\"APPLICATION_USER_NAME\"),\n                        System.getenv(\"APPLICATION_PASSWORD\"))\n                .getToken();\n        String response = provider\n                .target()\n                .request()\n                .header(\"Authorization\", \"Bearer \" + token)\n                .get(String.class);\n        assertThat(response, containsString(expectedToContain));\n    }\n\n}  The test can be locally executed with the following command:  HOST=localhost PORT=8080 APPLICATION_USER_NAME=rob APPLICATION_PASSWORD=1234 REALM_NAME=battleapp-local KEYCLOAK_URL=http://localhost:8280/auth mvn clean install failsafe:integration-test failsafe:verify  The pipeline step has to be extended with the  REALM_NAME  as well as the\nsystem test was before.  stage \"consumer driven contract test\"\nnode {\n  git url: \"http://disruptor.ninja:30130/rob/battleapp-cdct\"\n  def mvnHome = tool 'M3'\n  sh \"PORT=31080 REALM_NAME=battleapp-test ${mvnHome}/bin/mvn clean install failsafe:integration-test failsafe:verify\"\n  step([$class: 'JUnitResultArchiver', testResults: '**/target/failsafe-reports/TEST-*.xml'])\n}",
            "title": "Consumer driven contract test of the secured service"
        },
        {
            "location": "/16_SSO_with_Keycloak/Secure_frontend_service/",
            "text": "Secure the Angular2 frontend service\n\n\nThis article is based on \n\nthis article\n.\nTo add Keycloak security to an Angular2 application we've to install the\nJavaScript Keycloak adapter.\n\n\nnpm install keycloak-js --save\n\n\n\n\nNow we've to intercept every call to the frontend. We can achieve that in the\n\nmain.browser.ts\n file:\n\n\nimport * as Keycloak from \"keycloak-js\";\n\nlet keycloak = Keycloak('keycloak/keycloak.json');\nwindow['_keycloak'] = keycloak;\n\nwindow['_keycloak'].init(\n  {onLoad: 'login-required'}\n)\n  .success(function (authenticated) {\n\n    if (!authenticated) {\n      window.location.reload();\n    }\n\n    // refresh login\n    setInterval(function () {\n\n      keycloak.updateToken(70).success(function (refreshed) {\n        if (refreshed) {\n          console.log('Token refreshed');\n        } else {\n          console.log('Token not refreshed, valid for '\n            + Math.round(keycloak.tokenParsed.exp + keycloak.timeSkew - new Date().getTime() / 1000) + ' seconds');\n        }\n      }).error(function () {\n        console.error('Failed to refresh token');\n      });\n\n    }, 60000);\n\n    console.log(\"Loading...\");\n\n    platformBrowserDynamic().bootstrapModule(AppModule);\n\n  });\n\n\n\n\nThen we've to create a folder \nsrc/keycloak\n with the file \nkeycloak.json\n and\nthe following content:\n\n\n{\n  \"realm\": \"battleapp-local\",\n  \"auth-server-url\": \"http://localhost:8280/auth\",\n  \"ssl-required\": \"none\",\n  \"resource\": \"battleapp-frontend\",\n  \"public-client\": true\n}\n\n\n\n\nTo include Keycloak in our services we can use the following library:\n\n\nnpm install angular2-jwt --save\n\n\n\n\nThen we can configure the auth provider in \napp.module.ts\n:\n\n\n...\nimport {provideAuth} from \"angular2-jwt\";\n...\nproviders: [ // expose our Services and Providers into Angular's dependency injection\n  ENV_PROVIDERS,\n  APP_PROVIDERS,\n  provideAuth({\n    globalHeaders: [{'Content-Type': 'application/json'}],\n    noJwtError: true,\n    tokenGetter: () => {\n      return window['_keycloak'].token;\n    }\n  })\n]\n...\n\n\n\n\nNow we can use the \nAuthHttp\n in our \nusers.service.ts\n class.\n\n\nimport {Injectable} from \"@angular/core\";\nimport {Response, Http} from \"@angular/http\";\nimport {Observable} from \"rxjs\";\nimport {User} from \"./user\";\nimport {AuthHttp} from \"angular2-jwt\";\n\n@Injectable()\nexport class UserService {\n  private environment: Observable<any>;\n\n  constructor(private authHttp: AuthHttp, private http: Http) {\n    this.environment = this.http\n      .get('/environment/environment.json')\n      .map(res => res.json());\n  }\n\n  public getUsersUrl(env: any): string {\n    let baseUsersUrl = '/battleapp/';\n    let api: string = 'resources/';\n    let usersUrl = 'http://' + env.host + ':' + env.port + baseUsersUrl + api + 'users/';\n    return usersUrl;\n  }\n\n  public getAll = (): Observable<User[]> => {\n    return this.environment.flatMap((env: any) => {\n      return this.authHttp\n        .get(this.getUsersUrl(env))\n        .map(res => res.json());\n    });\n  };\n\n  public search = (nickname: string): Observable<User[]> => {\n    return this.environment.flatMap((env: any) => {\n      return this.authHttp\n        .get(this.getUsersUrl(env) + \"?nickname=\" + nickname)\n        .map(res => res.json());\n    });\n  };\n\n  public find = (id: number): Observable<User> => {\n    return this.environment.flatMap((env: any) => {\n      return this.authHttp\n        .get(this.getUsersUrl(env) + id)\n        .map(res => res.json());\n    });\n  };\n\n  public create = (firstName: string, lastName: string): Observable<User> => {\n    return this.environment.flatMap((env: any) => {\n      var toAdd = JSON.stringify({firstName: firstName, lastName: lastName});\n      return this.authHttp\n        .post(this.getUsersUrl(env), toAdd)\n        .map(res => res.json());\n    });\n  };\n\n  public update = (id: number, itemToUpdate: User): Observable<User> => {\n    return this.environment.flatMap((env: any) => {\n      return this.authHttp\n        .put(this.getUsersUrl(env) + id, JSON.stringify(itemToUpdate))\n        .map(res => res.json());\n    });\n  };\n\n  public delete = (id: number): Observable<Response> => {\n    return this.environment.flatMap((env: any) => {\n      return this.authHttp\n        .delete(this.getUsersUrl(env) + id);\n    });\n  };\n}\n\n\n\n\nCreate test environment with security\n\n\nIn the \nstart.js\n script form the start test environment script we've to\nadd \nkeycloak.json\n with a ConfigMap. Therefore we've to create a new file\n\nkeycloak.json\n in the \nbattleapp-frontend\n and \nbattleapp-frontend-test\n\nfolder with the corresponding content:\n\n\n{\n  \"realm\": \"battleapp\",\n  \"auth-server-url\": \"https://disruptor.ninja:30182/auth\",\n  \"ssl-required\": \"none\",\n  \"resource\": \"battleapp-frontend\",\n  \"public-client\": true\n}\n\n\n\n\n{\n  \"realm\": \"battleapp-test\",\n  \"auth-server-url\": \"https://disruptor.ninja:30182/auth\",\n  \"ssl-required\": \"none\",\n  \"resource\": \"battleapp-frontend\",\n  \"public-client\": true\n}\n\n\n\n\nNow we've to delete the existing ConfigMaps and recreate them:\n\n\nkc delete configmap battleapp-frontend\nkc delete configmap battleapp-frontend-test\nkc create configmap battleapp-frontend-test --from-file=battleapp-frontend-test\nkc create configmap battleapp-frontend --from-file=battleapp-frontend\n\n\n\n\nAnd test it:\n\n\nkc get configmap battleapp-frontend-test -o yaml\n\n\n\n\napiVersion: v1\ndata:\n  environment.json: |\n    {\n      \"host\": \"disruptor.ninja\",\n      \"port\": 31080\n    }\n  keycloak.json: |\n    {\n      \"realm\": \"battleapp-test\",\n      \"auth-server-url\": \"https://disruptor.ninja:30182/auth\",\n      \"ssl-required\": \"none\",\n      \"resource\": \"battleapp-frontend\",\n      \"public-client\": true\n    }\nkind: ConfigMap\nmetadata:\n  creationTimestamp: 2016-12-31T15:54:44Z\n  name: battleapp-frontend-test\n  namespace: default\n  resourceVersion: \"1049486\"\n  selfLink: /api/v1/namespaces/default/configmaps/battleapp-frontend-test\n  uid: 72a5399b-cf71-11e6-a836-0050563cad2a\n\n\n\n\nNow we can add the ConfigMap in the \nstart.js\n script form the start \ntest environment script:\n\n\n...\ndfw.write(\"        - name: keycloak\\n\");\ndfw.write(\"          mountPath: /usr/share/nginx/html/keycloak\\n\");\n...\ndfw.write(\"      - name: keycloak\\n\");\ndfw.write(\"        configMap:\\n\");\ndfw.write(\"          name: battleapp-frontend-test\\n\");\ndfw.write(\"          items:\\n\");\ndfw.write(\"          - key: keycloak.json\\n\");\ndfw.write(\"            path: keycloak.json\\n\");\n...\n\n\n\n\nAnd in the \nstart.js\n script from the canary release:\n\n\n...\ndfw.write(\"        - name: keycloak\\n\");\ndfw.write(\"          mountPath: /usr/share/nginx/html/keycloak\\n\");\n...\ndfw.write(\"      - name: keycloak\\n\");\ndfw.write(\"        configMap:\\n\");\ndfw.write(\"          name: battleapp-frontend\\n\");\ndfw.write(\"          items:\\n\");\ndfw.write(\"          - key: keycloak.json\\n\");\ndfw.write(\"            path: keycloak.json\\n\");\n...",
            "title": "Secure frontend service"
        },
        {
            "location": "/16_SSO_with_Keycloak/Secure_frontend_service/#secure-the-angular2-frontend-service",
            "text": "This article is based on  this article .\nTo add Keycloak security to an Angular2 application we've to install the\nJavaScript Keycloak adapter.  npm install keycloak-js --save  Now we've to intercept every call to the frontend. We can achieve that in the main.browser.ts  file:  import * as Keycloak from \"keycloak-js\";\n\nlet keycloak = Keycloak('keycloak/keycloak.json');\nwindow['_keycloak'] = keycloak;\n\nwindow['_keycloak'].init(\n  {onLoad: 'login-required'}\n)\n  .success(function (authenticated) {\n\n    if (!authenticated) {\n      window.location.reload();\n    }\n\n    // refresh login\n    setInterval(function () {\n\n      keycloak.updateToken(70).success(function (refreshed) {\n        if (refreshed) {\n          console.log('Token refreshed');\n        } else {\n          console.log('Token not refreshed, valid for '\n            + Math.round(keycloak.tokenParsed.exp + keycloak.timeSkew - new Date().getTime() / 1000) + ' seconds');\n        }\n      }).error(function () {\n        console.error('Failed to refresh token');\n      });\n\n    }, 60000);\n\n    console.log(\"Loading...\");\n\n    platformBrowserDynamic().bootstrapModule(AppModule);\n\n  });  Then we've to create a folder  src/keycloak  with the file  keycloak.json  and\nthe following content:  {\n  \"realm\": \"battleapp-local\",\n  \"auth-server-url\": \"http://localhost:8280/auth\",\n  \"ssl-required\": \"none\",\n  \"resource\": \"battleapp-frontend\",\n  \"public-client\": true\n}  To include Keycloak in our services we can use the following library:  npm install angular2-jwt --save  Then we can configure the auth provider in  app.module.ts :  ...\nimport {provideAuth} from \"angular2-jwt\";\n...\nproviders: [ // expose our Services and Providers into Angular's dependency injection\n  ENV_PROVIDERS,\n  APP_PROVIDERS,\n  provideAuth({\n    globalHeaders: [{'Content-Type': 'application/json'}],\n    noJwtError: true,\n    tokenGetter: () => {\n      return window['_keycloak'].token;\n    }\n  })\n]\n...  Now we can use the  AuthHttp  in our  users.service.ts  class.  import {Injectable} from \"@angular/core\";\nimport {Response, Http} from \"@angular/http\";\nimport {Observable} from \"rxjs\";\nimport {User} from \"./user\";\nimport {AuthHttp} from \"angular2-jwt\";\n\n@Injectable()\nexport class UserService {\n  private environment: Observable<any>;\n\n  constructor(private authHttp: AuthHttp, private http: Http) {\n    this.environment = this.http\n      .get('/environment/environment.json')\n      .map(res => res.json());\n  }\n\n  public getUsersUrl(env: any): string {\n    let baseUsersUrl = '/battleapp/';\n    let api: string = 'resources/';\n    let usersUrl = 'http://' + env.host + ':' + env.port + baseUsersUrl + api + 'users/';\n    return usersUrl;\n  }\n\n  public getAll = (): Observable<User[]> => {\n    return this.environment.flatMap((env: any) => {\n      return this.authHttp\n        .get(this.getUsersUrl(env))\n        .map(res => res.json());\n    });\n  };\n\n  public search = (nickname: string): Observable<User[]> => {\n    return this.environment.flatMap((env: any) => {\n      return this.authHttp\n        .get(this.getUsersUrl(env) + \"?nickname=\" + nickname)\n        .map(res => res.json());\n    });\n  };\n\n  public find = (id: number): Observable<User> => {\n    return this.environment.flatMap((env: any) => {\n      return this.authHttp\n        .get(this.getUsersUrl(env) + id)\n        .map(res => res.json());\n    });\n  };\n\n  public create = (firstName: string, lastName: string): Observable<User> => {\n    return this.environment.flatMap((env: any) => {\n      var toAdd = JSON.stringify({firstName: firstName, lastName: lastName});\n      return this.authHttp\n        .post(this.getUsersUrl(env), toAdd)\n        .map(res => res.json());\n    });\n  };\n\n  public update = (id: number, itemToUpdate: User): Observable<User> => {\n    return this.environment.flatMap((env: any) => {\n      return this.authHttp\n        .put(this.getUsersUrl(env) + id, JSON.stringify(itemToUpdate))\n        .map(res => res.json());\n    });\n  };\n\n  public delete = (id: number): Observable<Response> => {\n    return this.environment.flatMap((env: any) => {\n      return this.authHttp\n        .delete(this.getUsersUrl(env) + id);\n    });\n  };\n}",
            "title": "Secure the Angular2 frontend service"
        },
        {
            "location": "/16_SSO_with_Keycloak/Secure_frontend_service/#create-test-environment-with-security",
            "text": "In the  start.js  script form the start test environment script we've to\nadd  keycloak.json  with a ConfigMap. Therefore we've to create a new file keycloak.json  in the  battleapp-frontend  and  battleapp-frontend-test \nfolder with the corresponding content:  {\n  \"realm\": \"battleapp\",\n  \"auth-server-url\": \"https://disruptor.ninja:30182/auth\",\n  \"ssl-required\": \"none\",\n  \"resource\": \"battleapp-frontend\",\n  \"public-client\": true\n}  {\n  \"realm\": \"battleapp-test\",\n  \"auth-server-url\": \"https://disruptor.ninja:30182/auth\",\n  \"ssl-required\": \"none\",\n  \"resource\": \"battleapp-frontend\",\n  \"public-client\": true\n}  Now we've to delete the existing ConfigMaps and recreate them:  kc delete configmap battleapp-frontend\nkc delete configmap battleapp-frontend-test\nkc create configmap battleapp-frontend-test --from-file=battleapp-frontend-test\nkc create configmap battleapp-frontend --from-file=battleapp-frontend  And test it:  kc get configmap battleapp-frontend-test -o yaml  apiVersion: v1\ndata:\n  environment.json: |\n    {\n      \"host\": \"disruptor.ninja\",\n      \"port\": 31080\n    }\n  keycloak.json: |\n    {\n      \"realm\": \"battleapp-test\",\n      \"auth-server-url\": \"https://disruptor.ninja:30182/auth\",\n      \"ssl-required\": \"none\",\n      \"resource\": \"battleapp-frontend\",\n      \"public-client\": true\n    }\nkind: ConfigMap\nmetadata:\n  creationTimestamp: 2016-12-31T15:54:44Z\n  name: battleapp-frontend-test\n  namespace: default\n  resourceVersion: \"1049486\"\n  selfLink: /api/v1/namespaces/default/configmaps/battleapp-frontend-test\n  uid: 72a5399b-cf71-11e6-a836-0050563cad2a  Now we can add the ConfigMap in the  start.js  script form the start \ntest environment script:  ...\ndfw.write(\"        - name: keycloak\\n\");\ndfw.write(\"          mountPath: /usr/share/nginx/html/keycloak\\n\");\n...\ndfw.write(\"      - name: keycloak\\n\");\ndfw.write(\"        configMap:\\n\");\ndfw.write(\"          name: battleapp-frontend-test\\n\");\ndfw.write(\"          items:\\n\");\ndfw.write(\"          - key: keycloak.json\\n\");\ndfw.write(\"            path: keycloak.json\\n\");\n...  And in the  start.js  script from the canary release:  ...\ndfw.write(\"        - name: keycloak\\n\");\ndfw.write(\"          mountPath: /usr/share/nginx/html/keycloak\\n\");\n...\ndfw.write(\"      - name: keycloak\\n\");\ndfw.write(\"        configMap:\\n\");\ndfw.write(\"          name: battleapp-frontend\\n\");\ndfw.write(\"          items:\\n\");\ndfw.write(\"          - key: keycloak.json\\n\");\ndfw.write(\"            path: keycloak.json\\n\");\n...",
            "title": "Create test environment with security"
        },
        {
            "location": "/16_SSO_with_Keycloak/Setup_Keycloak/",
            "text": "Setup Keycloak\n\n\nIn a microservices environment we need to have the possibility for \nSSO\n(Single Sign On)\n. We're \ngoing to use \nKeycloak\n. \n\n\nEnable SSL on Keycloak\n\n\nTo use SSL we have to create a keystore that contains our \n\npreviously created\n\nSSL certificates. Therefore we connect to our master where the certificates are.\n\n\nssh root@5.189.173.45\n\n\n\n\nOn the server change in the directory with the certificates:\n\n\ncd /etc/letsencrypt/live/disruptor.ninja/\n\n\n\n\nNow we create a PKCS12 file based on \n\nthis article\n.\n\n\nopenssl pkcs12 -export -in fullchain.pem -inkey privkey.pem -out pkcs.p12 -name test\n\n\n\n\nEnter Export Password:\n\n\n\n\ntest\n\n\n\n\nVerifying - Enter Export Password:\n\n\n\n\ntest\n\n\n\n\nIn the current folder there is a new file: \npkcs.p12\n.\n\nCopy this file on your local machine:\n\n\nscp root@5.189.173.45:/etc/letsencrypt/live/disruptor.ninja/pkcs.p12 .\n\n\n\n\nNow create a Java keystore based on this PKCS12 file:\n\n\nkeytool -importkeystore -deststorepass secret -destkeypass secret -destkeystore keycloak.jks -srckeystore pkcs.p12 -srcstoretype PKCS12 -srcstorepass test -alias test\n\n\n\n\nKeycloak has persistent data therefore we have to mount this data somewhere.\nThe easiest way to do that is over a node selector. A more advanced solution \nwould be to use GlusterFS, Flocker, NFS or something similar.\n\n\nIf we use node selectors for our persistence then we have to label a node.\nIn this case this is \n5.189.153.209\n.\n\n\nkc label nodes vmi71989.contabo.host name=vmi71989\n\n\n\n\nNow we connect to this server:\n\n\nssh root@5.189.153.209\n\n\n\n\nAnd create an empty folder \nkeycloakdata\n.\n\n\nmkdir keycloakdata\n\n\n\n\nIn this folder we copy our keystore:\n\n\nscp keycloak.jks root@5.189.153.209:/root/keycloakdata\n\n\n\n\nNow we change the rights of the folder and its content:\n\n\nchown -R 1000:1000 keycloakdata/\n\n\n\n\nNow we've to tell Keycloak to use this keystore. Therefore I've created an own\nDocker image:\n\n\nFROM jboss/keycloak:2.4.0.Final\n\nMAINTAINER Robert Brem <brem_robert@hotmail.com>\n\nRUN sed -i 's~<security-realms>~<security-realms><security-realm name=\"UndertowRealm\"><server-identities><ssl><keystore path=\"/opt/jboss/keycloak/standalone/data/keycloak.jks\" keystore-password=\"${env.KEYSTORE_PASSWORD}\" /></ssl></server-identities></security-realm>~g' /opt/jboss/keycloak/standalone/configuration/standalone.xml\nRUN sed -i 's~<server name=\"default-server\">~<server name=\"default-server\"><https-listener name=\"https\" socket-binding=\"https\" security-realm=\"UndertowRealm\"/>~g' /opt/jboss/keycloak/standalone/configuration/standalone.xml\n\nENTRYPOINT [ \"/opt/jboss/docker-entrypoint.sh\" ]\nCMD [\"-b\", \"0.0.0.0\"]\n\n\n\n\n\n\nThis Docker image is also available on Docker Hub \nrobertbrem\\keycloak:1.0.3\n\n\n\n\nIt changes the \nstandalone.xml\n based on \nthis article\n\nand uses an environment variable \nKEYSTORE_PASSWORD\n as keystore password.  \n\n\nCreate a Kubernetes deployment\n\n\nFor our deployment we need a secret with the Keycloak user, the Keycloak\npassword for the user and the password for our keystore:\n\n\nkc create secret generic keycloak --from-literal=keycloak_user=admin --from-literal=keycloak_password=admin --from-literal=keystore_password=secret\n\n\n\n\nOur deployment looks like that:\n\n\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: keycloak\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: keycloak\n    spec:\n      nodeSelector:\n        name: vmi71989\n      containers:\n      - name: keycloak\n        image: robertbrem/keycloak:1.0.3\n        env:\n        - name: KEYCLOAK_USER\n          valueFrom:\n            secretKeyRef:\n              name: keycloak\n              key: keycloak_user\n        - name: KEYCLOAK_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: keycloak\n              key: keycloak_password\n        - name: KEYSTORE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: keycloak\n              key: keystore_password\n        volumeMounts:\n          - mountPath: /opt/jboss/keycloak/standalone/data\n            name: keycloakdata\n        ports:\n          - name: http\n            containerPort: 8080\n          - name: https\n            containerPort: 8443\n      volumes:\n        - name: keycloakdata\n          hostPath:\n            path: /root/keycloakdata\n\n\n\n\nStart the deployment:\n\n\nkc create -f deployment.yml\n\n\n\n\nCreate a Kubernetes service\n\n\nTo access Keycloak from outside the cluster we've to create a service:\n\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: keycloak\n  labels:\n    name: keycloak\nspec:\n  ports:\n  - name: http\n    port: 8383\n    targetPort: 8080\n    nodePort: 30181\n  - name: https\n    port: 8443\n    targetPort: 8443\n    nodePort: 30182\n  selector:\n    name: keycloak\n  type: NodePort\n\n\n\n\nStart the service:\n\n\nkc create -f service.yml\n\n\n\n\nTest if Keycloak is up and running:\n\n\nhttps://disruptor.ninja:30182",
            "title": "Setup Keycloak"
        },
        {
            "location": "/16_SSO_with_Keycloak/Setup_Keycloak/#setup-keycloak",
            "text": "In a microservices environment we need to have the possibility for  SSO\n(Single Sign On) . We're \ngoing to use  Keycloak .",
            "title": "Setup Keycloak"
        },
        {
            "location": "/16_SSO_with_Keycloak/Setup_Keycloak/#enable-ssl-on-keycloak",
            "text": "To use SSL we have to create a keystore that contains our  previously created \nSSL certificates. Therefore we connect to our master where the certificates are.  ssh root@5.189.173.45  On the server change in the directory with the certificates:  cd /etc/letsencrypt/live/disruptor.ninja/  Now we create a PKCS12 file based on  this article .  openssl pkcs12 -export -in fullchain.pem -inkey privkey.pem -out pkcs.p12 -name test  Enter Export Password:  test  Verifying - Enter Export Password:  test  In the current folder there is a new file:  pkcs.p12 . \nCopy this file on your local machine:  scp root@5.189.173.45:/etc/letsencrypt/live/disruptor.ninja/pkcs.p12 .  Now create a Java keystore based on this PKCS12 file:  keytool -importkeystore -deststorepass secret -destkeypass secret -destkeystore keycloak.jks -srckeystore pkcs.p12 -srcstoretype PKCS12 -srcstorepass test -alias test  Keycloak has persistent data therefore we have to mount this data somewhere.\nThe easiest way to do that is over a node selector. A more advanced solution \nwould be to use GlusterFS, Flocker, NFS or something similar.  If we use node selectors for our persistence then we have to label a node.\nIn this case this is  5.189.153.209 .  kc label nodes vmi71989.contabo.host name=vmi71989  Now we connect to this server:  ssh root@5.189.153.209  And create an empty folder  keycloakdata .  mkdir keycloakdata  In this folder we copy our keystore:  scp keycloak.jks root@5.189.153.209:/root/keycloakdata  Now we change the rights of the folder and its content:  chown -R 1000:1000 keycloakdata/  Now we've to tell Keycloak to use this keystore. Therefore I've created an own\nDocker image:  FROM jboss/keycloak:2.4.0.Final\n\nMAINTAINER Robert Brem <brem_robert@hotmail.com>\n\nRUN sed -i 's~<security-realms>~<security-realms><security-realm name=\"UndertowRealm\"><server-identities><ssl><keystore path=\"/opt/jboss/keycloak/standalone/data/keycloak.jks\" keystore-password=\"${env.KEYSTORE_PASSWORD}\" /></ssl></server-identities></security-realm>~g' /opt/jboss/keycloak/standalone/configuration/standalone.xml\nRUN sed -i 's~<server name=\"default-server\">~<server name=\"default-server\"><https-listener name=\"https\" socket-binding=\"https\" security-realm=\"UndertowRealm\"/>~g' /opt/jboss/keycloak/standalone/configuration/standalone.xml\n\nENTRYPOINT [ \"/opt/jboss/docker-entrypoint.sh\" ]\nCMD [\"-b\", \"0.0.0.0\"]   This Docker image is also available on Docker Hub  robertbrem\\keycloak:1.0.3   It changes the  standalone.xml  based on  this article \nand uses an environment variable  KEYSTORE_PASSWORD  as keystore password.",
            "title": "Enable SSL on Keycloak"
        },
        {
            "location": "/16_SSO_with_Keycloak/Setup_Keycloak/#create-a-kubernetes-deployment",
            "text": "For our deployment we need a secret with the Keycloak user, the Keycloak\npassword for the user and the password for our keystore:  kc create secret generic keycloak --from-literal=keycloak_user=admin --from-literal=keycloak_password=admin --from-literal=keystore_password=secret  Our deployment looks like that:  apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: keycloak\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: keycloak\n    spec:\n      nodeSelector:\n        name: vmi71989\n      containers:\n      - name: keycloak\n        image: robertbrem/keycloak:1.0.3\n        env:\n        - name: KEYCLOAK_USER\n          valueFrom:\n            secretKeyRef:\n              name: keycloak\n              key: keycloak_user\n        - name: KEYCLOAK_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: keycloak\n              key: keycloak_password\n        - name: KEYSTORE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: keycloak\n              key: keystore_password\n        volumeMounts:\n          - mountPath: /opt/jboss/keycloak/standalone/data\n            name: keycloakdata\n        ports:\n          - name: http\n            containerPort: 8080\n          - name: https\n            containerPort: 8443\n      volumes:\n        - name: keycloakdata\n          hostPath:\n            path: /root/keycloakdata  Start the deployment:  kc create -f deployment.yml",
            "title": "Create a Kubernetes deployment"
        },
        {
            "location": "/16_SSO_with_Keycloak/Setup_Keycloak/#create-a-kubernetes-service",
            "text": "To access Keycloak from outside the cluster we've to create a service:  apiVersion: v1\nkind: Service\nmetadata:\n  name: keycloak\n  labels:\n    name: keycloak\nspec:\n  ports:\n  - name: http\n    port: 8383\n    targetPort: 8080\n    nodePort: 30181\n  - name: https\n    port: 8443\n    targetPort: 8443\n    nodePort: 30182\n  selector:\n    name: keycloak\n  type: NodePort  Start the service:  kc create -f service.yml  Test if Keycloak is up and running:  https://disruptor.ninja:30182",
            "title": "Create a Kubernetes service"
        },
        {
            "location": "/17_Event_Sourcing_with_Cassandra/Changes_to_the_frontend/",
            "text": "Change to the frontend service\n\n\nUsage of the new REST method\n\n\nWe've created a create method in the REST service now we've to\ncall this service in the frontend. Therefore the following\nfiles have to be adapted:\n\n\nuser.ts\n\n\nexport class User {\n  id: string;\n  nickame: string;\n  firstname: string;\n  lastname: string;\n\n  constructor() {\n  }\n\n}\n\n\n\n\nuser.component.html\n\n\n<form>\n  <md-card>\n    <md-card-title-group>\n      <md-input #id placeholder=\"ID\"></md-input>\n      <md-input #nickname placeholder=\"Nickname\"></md-input>\n      <md-input #firstName placeholder=\"First Name\"></md-input>\n      <md-input #lastName placeholder=\"Last Name\"></md-input>\n    </md-card-title-group>\n  </md-card>\n  <button md-raised-button\n          (click)=\"createUser(id.value, nickname.value, firstName.value, lastName.value)\"\n          class=\"btn btn-primary btn-lg\">\n    create\n  </button>\n</form>\n\n<md-input placeholder=\"Nickname\" (keyup)=\"search($event)\"></md-input>\n\n<md-card *ngFor=\"let user of users\">\n  <md-card-title-group>\n    <img md-card-sm-image src=\"path/to/img.png\">\n    <md-card-title>{{ user.nickname }}</md-card-title>\n    <md-card-subtitle>{{ user.firstName }}</md-card-subtitle>\n    <md-card-subtitle>{{ user.lastName }}</md-card-subtitle>\n  </md-card-title-group>\n</md-card>\n\n\n\n\nuser.component.ts\n\n\nimport {User} from \"./user\";\nimport {UserService} from \"./users.service\";\nimport {Component} from \"@angular/core\";\n\n@Component({\n  selector: 'battleapp-user',\n  templateUrl: './users.component.html',\n  styleUrls: ['./users.component.css'],\n  providers: [UserService],\n})\nexport class UserComponent {\n  private users: User[];\n\n  constructor(private service: UserService) {\n  }\n\n  ngOnInit() {\n    this.getUsers();\n  }\n\n  public createUser(id: string, nickname: string, firstName: string, lastName: string) {\n    return this.service\n      .create(id, nickname, firstName, lastName)\n      .subscribe((data: User) => {\n          let user: User = data;\n          console.log(user);\n          this.users.push(user);\n        },\n        error => console.log(error)\n      );\n  }\n\n  public search(event: any) {\n    let searchTerm: string = event.target.value;\n    this.service\n      .search(searchTerm)\n      .subscribe((data: User[]) => {\n          this.users = data;\n        },\n        error => console.log(error)\n      );\n  }\n\n  private getUsers() {\n    this.service\n      .getAll()\n      .subscribe((data: User[]) => {\n          this.users = data;\n        },\n        error => console.log(error),\n        () => console.log(this.users)\n      );\n  }\n  ;\n\n}\n\n\n\n\nuser.service.ts\n\n\nimport {Injectable} from \"@angular/core\";\nimport {Response, Http} from \"@angular/http\";\nimport {Observable} from \"rxjs\";\nimport {User} from \"./user\";\nimport {AuthHttp} from \"angular2-jwt\";\n\n@Injectable()\nexport class UserService {\n  private environment: Observable<any>;\n\n  constructor(private authHttp: AuthHttp, private http: Http) {\n    this.environment = this.http\n      .get('/environment/environment.json')\n      .map(res => res.json());\n  }\n\n  public getUsersUrl(env: any): string {\n    let usersUrl = 'http://' + env.host + ':' + env.port + '/battleapp/resources/users/';\n    return usersUrl;\n  }\n\n  public getAll = (): Observable<User[]> => {\n    return this.environment.flatMap((env: any) => {\n      return this.authHttp\n        .get(this.getUsersUrl(env))\n        .map(res => res.json());\n    });\n  };\n\n  public search = (nickname: string): Observable<User[]> => {\n    return this.environment.flatMap((env: any) => {\n      return this.authHttp\n        .get(this.getUsersUrl(env) + \"?nickname=\" + nickname)\n        .map(res => res.json());\n    });\n  };\n\n  public find = (id: number): Observable<User> => {\n    return this.environment.flatMap((env: any) => {\n      return this.authHttp\n        .get(this.getUsersUrl(env) + id)\n        .map(res => res.json());\n    });\n  };\n\n  public create = (id: string, nickname: string, firstName: string, lastName: string): Observable<User> => {\n    return this.environment.flatMap((env: any) => {\n      var toAdd = JSON.stringify({id: id, nickname: nickname, firstName: firstName, lastName: lastName});\n      return this.authHttp\n        .post(this.getUsersUrl(env), toAdd)\n        .map(res => res.json());\n    });\n  };\n\n  public update = (id: number, itemToUpdate: User): Observable<User> => {\n    return this.environment.flatMap((env: any) => {\n      return this.authHttp\n        .put(this.getUsersUrl(env) + id, JSON.stringify(itemToUpdate))\n        .map(res => res.json());\n    });\n  };\n\n  public delete = (id: number): Observable<Response> => {\n    return this.environment.flatMap((env: any) => {\n      return this.authHttp\n        .delete(this.getUsersUrl(env) + id);\n    });\n  };\n}\n\n\n\n\nAlias for test environment\n\n\nThat we can execute commands in the test namespace we're going\nto create a new alias:\n\n\nvi ~/.alias\n\n\n\n\nalias kc='kubectl --kubeconfig /home/battleapp/Desktop/admin.conf'\nalias watchkc='watch kubectl --kubeconfig /home/battleapp/Desktop/admin.conf'\nalias mountWin='sudo mount -t vboxsf Microservices_with_Kubernetes /media/windows-share'\nalias startKeycloak='docker stop keycloak && docker rm keycloak && docker run -d -e KEYCLOAK_USER=admin -e KEYCLOAK_PASSWORD=admin -p 8280:8080 -v /home/battleapp/Desktop/dockervolumes/keycloakdata/:/opt/jboss/keycloak/standalone/data --name keycloak jboss/keycloak:2.4.0.Final'\nalias startCass='~/Desktop/startCassandra.sh'\nalias kctest='kubectl --kubeconfig /home/battleapp/Desktop/admin.conf --namespace test'\n\n\n\n\nChanges to the test environment\n\n\nIn the frontend we need additionally to the Kubernetes secret\nfor the registry a Kubernetes configmap:\n\n\nkc delete configmap battleapp-frontend-test\nkctest create configmap battleapp-frontend --from-file battleapp-frontend-test\n\n\n\n\nChanges to the \nstart.js\n script:\n\n\n...\nvar name = \"battleapp-frontend\";\n...\ndfw.write(\"        configMap:\\n\");\ndfw.write(\"          name: battleapp-frontend\\n\");\n...\ndfw.write(\"        configMap:\\n\");\ndfw.write(\"          name: battleapp-frontend\\n\");\n...\nvar deleteDeployment = kubectl + \" --namespace \" + namespace + \" delete deployment \" + name;\n...\ndfw.write(\"kind: Deployment\\n\");\ndfw.write(\"metadata:\\n\");\ndfw.write(\"  name: \" + name + \"\\n\");\ndfw.write(\"  namespace: \" + namespace + \"\\n\");\n...\nvar deleteService = kubectl + \" --namespace \" + namespace + \"delete service \" + name;\n...\nsfw.write(\"kind: Service\\n\");\nsfw.write(\"metadata:\\n\");\nsfw.write(\"  name: \" + name + \"\\n\");\nsfw.write(\"  namespace: \" + namespace + \"\\n\");\n...",
            "title": "Changes to the frontend"
        },
        {
            "location": "/17_Event_Sourcing_with_Cassandra/Changes_to_the_frontend/#change-to-the-frontend-service",
            "text": "",
            "title": "Change to the frontend service"
        },
        {
            "location": "/17_Event_Sourcing_with_Cassandra/Changes_to_the_frontend/#usage-of-the-new-rest-method",
            "text": "We've created a create method in the REST service now we've to\ncall this service in the frontend. Therefore the following\nfiles have to be adapted:  user.ts  export class User {\n  id: string;\n  nickame: string;\n  firstname: string;\n  lastname: string;\n\n  constructor() {\n  }\n\n}  user.component.html  <form>\n  <md-card>\n    <md-card-title-group>\n      <md-input #id placeholder=\"ID\"></md-input>\n      <md-input #nickname placeholder=\"Nickname\"></md-input>\n      <md-input #firstName placeholder=\"First Name\"></md-input>\n      <md-input #lastName placeholder=\"Last Name\"></md-input>\n    </md-card-title-group>\n  </md-card>\n  <button md-raised-button\n          (click)=\"createUser(id.value, nickname.value, firstName.value, lastName.value)\"\n          class=\"btn btn-primary btn-lg\">\n    create\n  </button>\n</form>\n\n<md-input placeholder=\"Nickname\" (keyup)=\"search($event)\"></md-input>\n\n<md-card *ngFor=\"let user of users\">\n  <md-card-title-group>\n    <img md-card-sm-image src=\"path/to/img.png\">\n    <md-card-title>{{ user.nickname }}</md-card-title>\n    <md-card-subtitle>{{ user.firstName }}</md-card-subtitle>\n    <md-card-subtitle>{{ user.lastName }}</md-card-subtitle>\n  </md-card-title-group>\n</md-card>  user.component.ts  import {User} from \"./user\";\nimport {UserService} from \"./users.service\";\nimport {Component} from \"@angular/core\";\n\n@Component({\n  selector: 'battleapp-user',\n  templateUrl: './users.component.html',\n  styleUrls: ['./users.component.css'],\n  providers: [UserService],\n})\nexport class UserComponent {\n  private users: User[];\n\n  constructor(private service: UserService) {\n  }\n\n  ngOnInit() {\n    this.getUsers();\n  }\n\n  public createUser(id: string, nickname: string, firstName: string, lastName: string) {\n    return this.service\n      .create(id, nickname, firstName, lastName)\n      .subscribe((data: User) => {\n          let user: User = data;\n          console.log(user);\n          this.users.push(user);\n        },\n        error => console.log(error)\n      );\n  }\n\n  public search(event: any) {\n    let searchTerm: string = event.target.value;\n    this.service\n      .search(searchTerm)\n      .subscribe((data: User[]) => {\n          this.users = data;\n        },\n        error => console.log(error)\n      );\n  }\n\n  private getUsers() {\n    this.service\n      .getAll()\n      .subscribe((data: User[]) => {\n          this.users = data;\n        },\n        error => console.log(error),\n        () => console.log(this.users)\n      );\n  }\n  ;\n\n}  user.service.ts  import {Injectable} from \"@angular/core\";\nimport {Response, Http} from \"@angular/http\";\nimport {Observable} from \"rxjs\";\nimport {User} from \"./user\";\nimport {AuthHttp} from \"angular2-jwt\";\n\n@Injectable()\nexport class UserService {\n  private environment: Observable<any>;\n\n  constructor(private authHttp: AuthHttp, private http: Http) {\n    this.environment = this.http\n      .get('/environment/environment.json')\n      .map(res => res.json());\n  }\n\n  public getUsersUrl(env: any): string {\n    let usersUrl = 'http://' + env.host + ':' + env.port + '/battleapp/resources/users/';\n    return usersUrl;\n  }\n\n  public getAll = (): Observable<User[]> => {\n    return this.environment.flatMap((env: any) => {\n      return this.authHttp\n        .get(this.getUsersUrl(env))\n        .map(res => res.json());\n    });\n  };\n\n  public search = (nickname: string): Observable<User[]> => {\n    return this.environment.flatMap((env: any) => {\n      return this.authHttp\n        .get(this.getUsersUrl(env) + \"?nickname=\" + nickname)\n        .map(res => res.json());\n    });\n  };\n\n  public find = (id: number): Observable<User> => {\n    return this.environment.flatMap((env: any) => {\n      return this.authHttp\n        .get(this.getUsersUrl(env) + id)\n        .map(res => res.json());\n    });\n  };\n\n  public create = (id: string, nickname: string, firstName: string, lastName: string): Observable<User> => {\n    return this.environment.flatMap((env: any) => {\n      var toAdd = JSON.stringify({id: id, nickname: nickname, firstName: firstName, lastName: lastName});\n      return this.authHttp\n        .post(this.getUsersUrl(env), toAdd)\n        .map(res => res.json());\n    });\n  };\n\n  public update = (id: number, itemToUpdate: User): Observable<User> => {\n    return this.environment.flatMap((env: any) => {\n      return this.authHttp\n        .put(this.getUsersUrl(env) + id, JSON.stringify(itemToUpdate))\n        .map(res => res.json());\n    });\n  };\n\n  public delete = (id: number): Observable<Response> => {\n    return this.environment.flatMap((env: any) => {\n      return this.authHttp\n        .delete(this.getUsersUrl(env) + id);\n    });\n  };\n}",
            "title": "Usage of the new REST method"
        },
        {
            "location": "/17_Event_Sourcing_with_Cassandra/Changes_to_the_frontend/#alias-for-test-environment",
            "text": "That we can execute commands in the test namespace we're going\nto create a new alias:  vi ~/.alias  alias kc='kubectl --kubeconfig /home/battleapp/Desktop/admin.conf'\nalias watchkc='watch kubectl --kubeconfig /home/battleapp/Desktop/admin.conf'\nalias mountWin='sudo mount -t vboxsf Microservices_with_Kubernetes /media/windows-share'\nalias startKeycloak='docker stop keycloak && docker rm keycloak && docker run -d -e KEYCLOAK_USER=admin -e KEYCLOAK_PASSWORD=admin -p 8280:8080 -v /home/battleapp/Desktop/dockervolumes/keycloakdata/:/opt/jboss/keycloak/standalone/data --name keycloak jboss/keycloak:2.4.0.Final'\nalias startCass='~/Desktop/startCassandra.sh'\nalias kctest='kubectl --kubeconfig /home/battleapp/Desktop/admin.conf --namespace test'",
            "title": "Alias for test environment"
        },
        {
            "location": "/17_Event_Sourcing_with_Cassandra/Changes_to_the_frontend/#changes-to-the-test-environment",
            "text": "In the frontend we need additionally to the Kubernetes secret\nfor the registry a Kubernetes configmap:  kc delete configmap battleapp-frontend-test\nkctest create configmap battleapp-frontend --from-file battleapp-frontend-test  Changes to the  start.js  script:  ...\nvar name = \"battleapp-frontend\";\n...\ndfw.write(\"        configMap:\\n\");\ndfw.write(\"          name: battleapp-frontend\\n\");\n...\ndfw.write(\"        configMap:\\n\");\ndfw.write(\"          name: battleapp-frontend\\n\");\n...\nvar deleteDeployment = kubectl + \" --namespace \" + namespace + \" delete deployment \" + name;\n...\ndfw.write(\"kind: Deployment\\n\");\ndfw.write(\"metadata:\\n\");\ndfw.write(\"  name: \" + name + \"\\n\");\ndfw.write(\"  namespace: \" + namespace + \"\\n\");\n...\nvar deleteService = kubectl + \" --namespace \" + namespace + \"delete service \" + name;\n...\nsfw.write(\"kind: Service\\n\");\nsfw.write(\"metadata:\\n\");\nsfw.write(\"  name: \" + name + \"\\n\");\nsfw.write(\"  namespace: \" + namespace + \"\\n\");\n...",
            "title": "Changes to the test environment"
        },
        {
            "location": "/17_Event_Sourcing_with_Cassandra/README/",
            "text": "Use Cassandra for Event Sourcing\n\n\n\n\nSetup Cassandra\n\n\nREST service with Event Sourcing\n\n\nUse namespaces in the frontend",
            "title": "README"
        },
        {
            "location": "/17_Event_Sourcing_with_Cassandra/README/#use-cassandra-for-event-sourcing",
            "text": "Setup Cassandra  REST service with Event Sourcing  Use namespaces in the frontend",
            "title": "Use Cassandra for Event Sourcing"
        },
        {
            "location": "/17_Event_Sourcing_with_Cassandra/REST_service_with_event_sourcing/",
            "text": "Change the REST service to use event sourcing and Cassandra\n\n\nEvent Sourcing in the REST service\n\n\nIn the book \n\nImplementing Domain Driven Design\n\nthere's a chapter with a C# implementation of Event Sourcing. I've implemented\nmy version of the Event Sourcing based on this example from the book.\nThe implementation is under the following package \n\nninja.disruptor.battleapp.eventstore\n in \n\nthis repository\n.\n\n\nUnder \nninja.disruptor.battleapp.user.entity.event\n we've to create the needed events for the \nUser\n.\nOur user has the following properties:\n\n\nprivate String id;\nprivate String nickname;\nprivate String firstName;\nprivate String lastName;\n\n\n\n\nTherefore we need these event classes:\n\n\n@AllArgsConstructor\n@Getter\npublic class UserEvent implements CoreEvent {\n    private final String id;\n}\n\n\n\n\npublic class UserCreated extends UserEvent {\n    public UserCreated(String id) {\n        super(id);\n    }\n}\n\n\n\n\npublic class UserDeleted extends UserEvent {\n    public UserDeleted(String id) {\n        super(id);\n    }\n}\n\n\n\n\n@Getter\npublic class UserFirstNameChanged extends UserEvent {\n    private final String firstName;\n\n    public UserFirstNameChanged(String id, String firstName) {\n        super(id);\n        this.firstName = firstName;\n    }\n}\n\n\n\n\n@Getter\npublic class UserLastNameChanged extends UserEvent {\n    private final String lastName;\n\n    public UserLastNameChanged(String id, String lastName) {\n        super(id);\n        this.lastName = lastName;\n    }\n\n}\n\n\n\n\n@Getter\npublic class UserNicknameChanged extends UserEvent {\n    private final String nickname;\n\n    public UserNicknameChanged(String id, String nickname) {\n        super(id);\n        this.nickname = nickname;\n    }\n\n}\n\n\n\n\nAt next we've to adapt our \nUser\n entity itself:\n\n\n@NoArgsConstructor\n@ToString\n@XmlAccessorType(XmlAccessType.FIELD)\n@Data\npublic class User {\n    private String id;\n    private String nickname;\n    private String firstName;\n    private String lastName;\n\n    @XmlTransient\n    private final List<CoreEvent> changes = new ArrayList<>();\n\n    public User(User copy) {\n        this.id = copy.getId();\n        this.nickname = copy.getNickname();\n        this.firstName = copy.getFirstName();\n        this.lastName = copy.getLastName();\n    }\n\n    public User(List<CoreEvent> events) {\n        for (CoreEvent event : events) {\n            mutate(event);\n        }\n    }\n\n    public void changeFirstName(String firstName) {\n        apply(new UserFirstNameChanged(id, firstName));\n    }\n\n    public void changeLastName(String lastName) {\n        apply(new UserLastNameChanged(id, lastName));\n    }\n\n    public void changeNickname(String nickname) {\n        apply(new UserNicknameChanged(id, nickname));\n    }\n\n    public void create(String id) {\n        apply(new UserCreated(id));\n    }\n\n    public void delete() {\n        apply(new UserDeleted(id));\n    }\n\n    public void mutate(CoreEvent event) {\n        when(event);\n    }\n\n    public void apply(CoreEvent event) {\n        changes.add(event);\n        mutate(event);\n    }\n\n    public void when(CoreEvent event) {\n        if (event instanceof UserCreated) {\n            this.id = event.getId();\n        } else if (event instanceof UserFirstNameChanged) {\n            this.firstName = ((UserFirstNameChanged) event).getFirstName();\n        } else if (event instanceof UserLastNameChanged) {\n            this.lastName = ((UserLastNameChanged) event).getLastName();\n        } else if (event instanceof UserNicknameChanged) {\n            this.nickname = ((UserNicknameChanged) event).getNickname();\n        }\n    }\n\n}\n\n\n\n\nImplement a \ncreateUser\n method in our \nUserService\n EJB:\n\n\n...\n\n@Inject\nEventStore store;\n\npublic Supplier<Response> save(User user, UriInfo info) {\n    User saved = create(user.getId());\n    if (user.getFirstName() != null) {\n        saved = changeFirstName(saved.getId(), user.getFirstName());\n    }\n    if (user.getLastName() != null) {\n        saved = changeLastName(saved.getId(), user.getLastName());\n    }\n    if (user.getNickname() != null) {\n        saved = changeNickname(saved.getId(), user.getNickname());\n    }\n    String id = saved.getId();\n    URI uri = info\n            .getAbsolutePathBuilder()\n            .path(\"/\" + id)\n            .build();\n    final User postSaveUser = new User(saved);\n    return () -> Response\n            .created(uri)\n            .entity(new User(postSaveUser))\n            .build();\n}\n\npublic User create(String id) {\n    User player = new User(new ArrayList<>());\n    player.create(id);\n    store.appendToStream(new EventIdentity(User.class, id), 0L, player.getChanges());\n    return player;\n}\n\npublic User changeFirstName(String id, String firstName) {\n    EventStream stream = store.loadEventStream(new EventIdentity(User.class, id));\n    User user = new User(stream.getEvents());\n    user.changeFirstName(firstName);\n    store.appendToStream(new EventIdentity(User.class, id), stream.getVersion(), user.getChanges());\n    return user;\n}\n\npublic User changeLastName(String id, String lastName) {\n    EventStream stream = store.loadEventStream(new EventIdentity(User.class, id));\n    User user = new User(stream.getEvents());\n    user.changeLastName(lastName);\n    store.appendToStream(new EventIdentity(User.class, id), stream.getVersion(), user.getChanges());\n    return user;\n}\n\npublic User changeNickname(String id, String nickname) {\n    EventStream stream = store.loadEventStream(new EventIdentity(User.class, id));\n    User user = new User(stream.getEvents());\n    user.changeNickname(nickname);\n    store.appendToStream(new EventIdentity(User.class, id), stream.getVersion(), user.getChanges());\n    return user;\n}\n\n...\n\n\n\n\nTo expose the \ncreate\n method we've to create a REST service method in the \nUserResource\n as well.\n\n\n@POST\npublic void save(@Suspended AsyncResponse response, @Context UriInfo info, User user) {\n    CompletableFuture\n            .supplyAsync(service.save(user, info), usersPool)\n            .thenAccept(response::resume);\n}\n\n\n\n\nOur event sourcing implementation uses Cassandre therefore we've to add the following dependencies:\n\n\n<dependency>\n    <groupId>com.datastax.cassandra</groupId>\n    <artifactId>cassandra-driver-core</artifactId>\n    <version>3.1.2</version>\n</dependency>\n<dependency>\n    <groupId>com.datastax.cassandra</groupId>\n    <artifactId>cassandra-driver-mapping</artifactId>\n    <version>3.1.2</version>\n</dependency>\n\n\n\n\nTo configure Cassandra also have to create a \nCassandraProvider\n:\n\n\n@Singleton\npublic class CassandraProvider {\n    public static final String CASSANDRA_ADDRESS = \"CASSANDRA_ADDRESS\";\n    public static final String KEYSPACE = \"battleapp\";\n\n    private Session session;\n\n    @Produces\n    public Session getSession() {\n        if (session == null) {\n            String address = \"localhost\";\n            String cassandraEnv = System.getenv(CASSANDRA_ADDRESS);\n            if (cassandraEnv != null && !cassandraEnv.isEmpty()) {\n                address = cassandraEnv;\n            }\n            Cluster cluster = Cluster.builder()\n                    .addContactPoints(address)\n                    .build();\n            session = cluster.connect(KEYSPACE);\n        }\n        return session;\n    }\n\n}\n\n\n\n\nTo display the created events we need a database or in our case just a simple \nMap\n to store the\nusers.\n\n\n@Startup\n@Singleton\n@ConcurrencyManagement(ConcurrencyManagementType.BEAN)\npublic class InMemoryCache {\n\n    @Getter\n    private Map<String, User> users = new HashMap<>();\n\n    @Inject\n    JsonConverter converter;\n\n    @Inject\n    EventRepository repository;\n\n    @PostConstruct\n    public void init() {\n        repository\n                .findAllUsers()\n                .parallelStream()\n                .forEach(u -> users.put(u.getId(), u));\n    }\n\n    public void onEvent(@Observes String jsonEventString) {\n        List<CoreEvent> events = converter.convertToEvents(jsonEventString);\n        for (CoreEvent event : events) {\n            handle(event);\n        }\n    }\n\n    public void handle(CoreEvent event) {\n        if (event instanceof UserCreated) {\n            List<CoreEvent> events = new ArrayList<>();\n            events.add(event);\n            User user = new User(events);\n            users.put(event.getId(), user);\n        } else if (event instanceof UserDeleted) {\n            User user = users.get(event.getId());\n            if (user == null) {\n                System.out.println(\"rejected!\");\n                return;\n            }\n            users.remove(user.getId());\n        } else if (event instanceof UserEvent) {\n            User user = users.get(event.getId());\n            if (user == null) {\n                System.out.println(\"rejected!\");\n                return;\n            }\n            user.mutate(event);\n        } else {\n            System.out.println(\"Event not found: \" + event.toString());\n            throw new NotImplementedException();\n        }\n    }\n\n}\n\n\n\n\nNow we can change our \nusers\n REST service to use the users from the db instead the hardcoded\ntest users. In the \nUserService\n we've to include the following parts:\n\n\n...\n@Inject\nInMemoryCache cache;\n\npublic Supplier<GenericEntity<Set<User>>> getUsersFilteredByNickname(String nickname) {\n    if (nickname == null || nickname.isEmpty()) {\n        return () -> new GenericEntity<Set<User>>(getUsers()) {\n        };\n    } else {\n        return () -> new GenericEntity<Set<User>>(getUsers()\n                .parallelStream()\n                .filter(u -> u.getNickname().toLowerCase().contains(nickname.toLowerCase()))\n                .collect(Collectors.toSet())) {\n        };\n    }\n}\n\npublic Set<User> getUsers() {\n    return new HashSet<>(cache.getUsers().values());\n}\n...\n\n\n\n\nAnd in our \nUserResource\n:\n\n\n@GET\npublic void getUsers(@Suspended AsyncResponse response, @QueryParam(\"nickname\") String nickname) {\n    CompletableFuture\n            .supplyAsync(service.getUsersFilteredByNickname(nickname), usersPool)\n            .thenAccept(response::resume);\n}\n\n\n\n\nChanges to the test environment\n\n\nThat we can use the Docker repository we've to create the same \n\ndocker-registry\n \nsecret\n from the production environment for the \ntest environment too.\n\n\nkc --namespace test create secret docker-registry registrykey --docker-username=rob --docker-password=1234 --docker-email=brem_robert@hotmail.com --docker-server=disruptor.ninja:30500\n\n\n\n\nThe following changes have to be made to the \nstart.js\n:\n\n\n...\nvar name = \"battleapp\";\nvar cassandraHost = \"cassandra\";\nvar namespace = \"test\";\n...\nvar deleteDeployment = kubectl + \" --namespace \" + namespace + \" delete deployment \" + name;\n...\ndfw.write(\"metadata:\\n\");\ndfw.write(\"  namespace: \" + namespace + \"\\n\");\n...\ndfw.write(\"        - name: CASSANDRA_ADDRESS\\n\");\ndfw.write(\"          value: \\\"\" + cassandraHost + \"\\\"\\n\");\n...\nvar deleteService = kubectl + \" --namespace \" + namespace + \" delete service \" + name;\n...\nsfw.write(\"metadata:\\n\");\nsfw.write(\"  name: \" + name + \"\\n\");\nsfw.write(\"  namespace: \" + namespace + \"\\n\");\n...\n\n\n\n\nChanges to the canary release\n\n\nThe following changes have to be made to the \nstart.js\n:\n\n\n...\nvar cassandraHost = \"cassandra\";\n...\ndfw.write(\"        - name: CASSANDRA_ADDRESS\\n\");\ndfw.write(\"          value: \\\"\" + cassandraHost + \"\\\"\\n\");\n...\n\n\n\n\nChanges to the consumer driven contract test\n\n\nWe need the following two dependencies that we can call the create method of the REST service:\n\n\n<dependency>\n    <groupId>org.glassfish</groupId>\n    <artifactId>javax.json</artifactId>\n    <version>1.0.4</version>\n    <scope>test</scope>\n</dependency>\n<dependency>\n    <groupId>org.glassfish.jersey.media</groupId>\n    <artifactId>jersey-media-json-processing</artifactId>\n    <version>2.12</version>\n    <scope>test</scope>\n</dependency>\n\n\n\n\nThe test itself has to be replaced with the following code:\n\n\n@FixMethodOrder(MethodSorters.NAME_ASCENDING)\npublic class BattleAppIT {\n\n    public static final String ID = \"id\";\n    public static final String NICKNAME = \"nickname\";\n    public static final String FIRST_NAME = \"firstName\";\n    public static final String LAST_NAME = \"lastName\";\n\n    public static final String LOCATION = \"Location\";\n\n    @Rule\n    public JAXRSClientProvider provider = buildWithURI(\"http://\" + System.getenv(\"HOST\") + \":\" + System.getenv(\"PORT\") + \"/battleapp/resources/users\");\n\n    private String nickname = \"rob\";\n    private String firstName = \"Robert\";\n    private String lastName = \"Brem\";\n\n\n    @Test\n    public void a01_shouldCreateRob() throws IOException {\n        JsonObjectBuilder userBuilder = Json.createObjectBuilder();\n        JsonObject playerToCreate = userBuilder\n                .add(ID, UUID.randomUUID().toString())\n                .add(NICKNAME, nickname)\n                .add(FIRST_NAME, firstName)\n                .add(LAST_NAME, lastName)\n                .build();\n\n        String token = KeycloakTokenCreator\n                .getTokenResponse(\n                        System.getenv(\"APPLICATION_USER_NAME\"),\n                        System.getenv(\"APPLICATION_PASSWORD\"))\n                .getToken();\n\n        Response postResponse = provider\n                .target()\n                .request()\n                .header(\"Authorization\", \"Bearer \" + token)\n                .post(Entity.json(playerToCreate));\n        System.out.println(\"postResponse = \" + postResponse);\n        assertThat(postResponse.getStatus(), is(201));\n        String location = postResponse.getHeaderString(LOCATION);\n    }\n\n    @Test\n    public void a02_shouldReturnRob() throws IOException {\n        String token = KeycloakTokenCreator\n                .getTokenResponse(\n                        System.getenv(\"APPLICATION_USER_NAME\"),\n                        System.getenv(\"APPLICATION_PASSWORD\"))\n                .getToken();\n        String response = provider\n                .target()\n                .request()\n                .header(\"Authorization\", \"Bearer \" + token)\n                .get(String.class);\n        assertThat(response, containsString(nickname));\n    }\n\n}",
            "title": "REST service with event sourcing"
        },
        {
            "location": "/17_Event_Sourcing_with_Cassandra/REST_service_with_event_sourcing/#change-the-rest-service-to-use-event-sourcing-and-cassandra",
            "text": "",
            "title": "Change the REST service to use event sourcing and Cassandra"
        },
        {
            "location": "/17_Event_Sourcing_with_Cassandra/REST_service_with_event_sourcing/#event-sourcing-in-the-rest-service",
            "text": "In the book  Implementing Domain Driven Design \nthere's a chapter with a C# implementation of Event Sourcing. I've implemented\nmy version of the Event Sourcing based on this example from the book.\nThe implementation is under the following package  ninja.disruptor.battleapp.eventstore  in  this repository .  Under  ninja.disruptor.battleapp.user.entity.event  we've to create the needed events for the  User .\nOur user has the following properties:  private String id;\nprivate String nickname;\nprivate String firstName;\nprivate String lastName;  Therefore we need these event classes:  @AllArgsConstructor\n@Getter\npublic class UserEvent implements CoreEvent {\n    private final String id;\n}  public class UserCreated extends UserEvent {\n    public UserCreated(String id) {\n        super(id);\n    }\n}  public class UserDeleted extends UserEvent {\n    public UserDeleted(String id) {\n        super(id);\n    }\n}  @Getter\npublic class UserFirstNameChanged extends UserEvent {\n    private final String firstName;\n\n    public UserFirstNameChanged(String id, String firstName) {\n        super(id);\n        this.firstName = firstName;\n    }\n}  @Getter\npublic class UserLastNameChanged extends UserEvent {\n    private final String lastName;\n\n    public UserLastNameChanged(String id, String lastName) {\n        super(id);\n        this.lastName = lastName;\n    }\n\n}  @Getter\npublic class UserNicknameChanged extends UserEvent {\n    private final String nickname;\n\n    public UserNicknameChanged(String id, String nickname) {\n        super(id);\n        this.nickname = nickname;\n    }\n\n}  At next we've to adapt our  User  entity itself:  @NoArgsConstructor\n@ToString\n@XmlAccessorType(XmlAccessType.FIELD)\n@Data\npublic class User {\n    private String id;\n    private String nickname;\n    private String firstName;\n    private String lastName;\n\n    @XmlTransient\n    private final List<CoreEvent> changes = new ArrayList<>();\n\n    public User(User copy) {\n        this.id = copy.getId();\n        this.nickname = copy.getNickname();\n        this.firstName = copy.getFirstName();\n        this.lastName = copy.getLastName();\n    }\n\n    public User(List<CoreEvent> events) {\n        for (CoreEvent event : events) {\n            mutate(event);\n        }\n    }\n\n    public void changeFirstName(String firstName) {\n        apply(new UserFirstNameChanged(id, firstName));\n    }\n\n    public void changeLastName(String lastName) {\n        apply(new UserLastNameChanged(id, lastName));\n    }\n\n    public void changeNickname(String nickname) {\n        apply(new UserNicknameChanged(id, nickname));\n    }\n\n    public void create(String id) {\n        apply(new UserCreated(id));\n    }\n\n    public void delete() {\n        apply(new UserDeleted(id));\n    }\n\n    public void mutate(CoreEvent event) {\n        when(event);\n    }\n\n    public void apply(CoreEvent event) {\n        changes.add(event);\n        mutate(event);\n    }\n\n    public void when(CoreEvent event) {\n        if (event instanceof UserCreated) {\n            this.id = event.getId();\n        } else if (event instanceof UserFirstNameChanged) {\n            this.firstName = ((UserFirstNameChanged) event).getFirstName();\n        } else if (event instanceof UserLastNameChanged) {\n            this.lastName = ((UserLastNameChanged) event).getLastName();\n        } else if (event instanceof UserNicknameChanged) {\n            this.nickname = ((UserNicknameChanged) event).getNickname();\n        }\n    }\n\n}  Implement a  createUser  method in our  UserService  EJB:  ...\n\n@Inject\nEventStore store;\n\npublic Supplier<Response> save(User user, UriInfo info) {\n    User saved = create(user.getId());\n    if (user.getFirstName() != null) {\n        saved = changeFirstName(saved.getId(), user.getFirstName());\n    }\n    if (user.getLastName() != null) {\n        saved = changeLastName(saved.getId(), user.getLastName());\n    }\n    if (user.getNickname() != null) {\n        saved = changeNickname(saved.getId(), user.getNickname());\n    }\n    String id = saved.getId();\n    URI uri = info\n            .getAbsolutePathBuilder()\n            .path(\"/\" + id)\n            .build();\n    final User postSaveUser = new User(saved);\n    return () -> Response\n            .created(uri)\n            .entity(new User(postSaveUser))\n            .build();\n}\n\npublic User create(String id) {\n    User player = new User(new ArrayList<>());\n    player.create(id);\n    store.appendToStream(new EventIdentity(User.class, id), 0L, player.getChanges());\n    return player;\n}\n\npublic User changeFirstName(String id, String firstName) {\n    EventStream stream = store.loadEventStream(new EventIdentity(User.class, id));\n    User user = new User(stream.getEvents());\n    user.changeFirstName(firstName);\n    store.appendToStream(new EventIdentity(User.class, id), stream.getVersion(), user.getChanges());\n    return user;\n}\n\npublic User changeLastName(String id, String lastName) {\n    EventStream stream = store.loadEventStream(new EventIdentity(User.class, id));\n    User user = new User(stream.getEvents());\n    user.changeLastName(lastName);\n    store.appendToStream(new EventIdentity(User.class, id), stream.getVersion(), user.getChanges());\n    return user;\n}\n\npublic User changeNickname(String id, String nickname) {\n    EventStream stream = store.loadEventStream(new EventIdentity(User.class, id));\n    User user = new User(stream.getEvents());\n    user.changeNickname(nickname);\n    store.appendToStream(new EventIdentity(User.class, id), stream.getVersion(), user.getChanges());\n    return user;\n}\n\n...  To expose the  create  method we've to create a REST service method in the  UserResource  as well.  @POST\npublic void save(@Suspended AsyncResponse response, @Context UriInfo info, User user) {\n    CompletableFuture\n            .supplyAsync(service.save(user, info), usersPool)\n            .thenAccept(response::resume);\n}  Our event sourcing implementation uses Cassandre therefore we've to add the following dependencies:  <dependency>\n    <groupId>com.datastax.cassandra</groupId>\n    <artifactId>cassandra-driver-core</artifactId>\n    <version>3.1.2</version>\n</dependency>\n<dependency>\n    <groupId>com.datastax.cassandra</groupId>\n    <artifactId>cassandra-driver-mapping</artifactId>\n    <version>3.1.2</version>\n</dependency>  To configure Cassandra also have to create a  CassandraProvider :  @Singleton\npublic class CassandraProvider {\n    public static final String CASSANDRA_ADDRESS = \"CASSANDRA_ADDRESS\";\n    public static final String KEYSPACE = \"battleapp\";\n\n    private Session session;\n\n    @Produces\n    public Session getSession() {\n        if (session == null) {\n            String address = \"localhost\";\n            String cassandraEnv = System.getenv(CASSANDRA_ADDRESS);\n            if (cassandraEnv != null && !cassandraEnv.isEmpty()) {\n                address = cassandraEnv;\n            }\n            Cluster cluster = Cluster.builder()\n                    .addContactPoints(address)\n                    .build();\n            session = cluster.connect(KEYSPACE);\n        }\n        return session;\n    }\n\n}  To display the created events we need a database or in our case just a simple  Map  to store the\nusers.  @Startup\n@Singleton\n@ConcurrencyManagement(ConcurrencyManagementType.BEAN)\npublic class InMemoryCache {\n\n    @Getter\n    private Map<String, User> users = new HashMap<>();\n\n    @Inject\n    JsonConverter converter;\n\n    @Inject\n    EventRepository repository;\n\n    @PostConstruct\n    public void init() {\n        repository\n                .findAllUsers()\n                .parallelStream()\n                .forEach(u -> users.put(u.getId(), u));\n    }\n\n    public void onEvent(@Observes String jsonEventString) {\n        List<CoreEvent> events = converter.convertToEvents(jsonEventString);\n        for (CoreEvent event : events) {\n            handle(event);\n        }\n    }\n\n    public void handle(CoreEvent event) {\n        if (event instanceof UserCreated) {\n            List<CoreEvent> events = new ArrayList<>();\n            events.add(event);\n            User user = new User(events);\n            users.put(event.getId(), user);\n        } else if (event instanceof UserDeleted) {\n            User user = users.get(event.getId());\n            if (user == null) {\n                System.out.println(\"rejected!\");\n                return;\n            }\n            users.remove(user.getId());\n        } else if (event instanceof UserEvent) {\n            User user = users.get(event.getId());\n            if (user == null) {\n                System.out.println(\"rejected!\");\n                return;\n            }\n            user.mutate(event);\n        } else {\n            System.out.println(\"Event not found: \" + event.toString());\n            throw new NotImplementedException();\n        }\n    }\n\n}  Now we can change our  users  REST service to use the users from the db instead the hardcoded\ntest users. In the  UserService  we've to include the following parts:  ...\n@Inject\nInMemoryCache cache;\n\npublic Supplier<GenericEntity<Set<User>>> getUsersFilteredByNickname(String nickname) {\n    if (nickname == null || nickname.isEmpty()) {\n        return () -> new GenericEntity<Set<User>>(getUsers()) {\n        };\n    } else {\n        return () -> new GenericEntity<Set<User>>(getUsers()\n                .parallelStream()\n                .filter(u -> u.getNickname().toLowerCase().contains(nickname.toLowerCase()))\n                .collect(Collectors.toSet())) {\n        };\n    }\n}\n\npublic Set<User> getUsers() {\n    return new HashSet<>(cache.getUsers().values());\n}\n...  And in our  UserResource :  @GET\npublic void getUsers(@Suspended AsyncResponse response, @QueryParam(\"nickname\") String nickname) {\n    CompletableFuture\n            .supplyAsync(service.getUsersFilteredByNickname(nickname), usersPool)\n            .thenAccept(response::resume);\n}",
            "title": "Event Sourcing in the REST service"
        },
        {
            "location": "/17_Event_Sourcing_with_Cassandra/REST_service_with_event_sourcing/#changes-to-the-test-environment",
            "text": "That we can use the Docker repository we've to create the same  docker-registry   secret  from the production environment for the \ntest environment too.  kc --namespace test create secret docker-registry registrykey --docker-username=rob --docker-password=1234 --docker-email=brem_robert@hotmail.com --docker-server=disruptor.ninja:30500  The following changes have to be made to the  start.js :  ...\nvar name = \"battleapp\";\nvar cassandraHost = \"cassandra\";\nvar namespace = \"test\";\n...\nvar deleteDeployment = kubectl + \" --namespace \" + namespace + \" delete deployment \" + name;\n...\ndfw.write(\"metadata:\\n\");\ndfw.write(\"  namespace: \" + namespace + \"\\n\");\n...\ndfw.write(\"        - name: CASSANDRA_ADDRESS\\n\");\ndfw.write(\"          value: \\\"\" + cassandraHost + \"\\\"\\n\");\n...\nvar deleteService = kubectl + \" --namespace \" + namespace + \" delete service \" + name;\n...\nsfw.write(\"metadata:\\n\");\nsfw.write(\"  name: \" + name + \"\\n\");\nsfw.write(\"  namespace: \" + namespace + \"\\n\");\n...",
            "title": "Changes to the test environment"
        },
        {
            "location": "/17_Event_Sourcing_with_Cassandra/REST_service_with_event_sourcing/#changes-to-the-canary-release",
            "text": "The following changes have to be made to the  start.js :  ...\nvar cassandraHost = \"cassandra\";\n...\ndfw.write(\"        - name: CASSANDRA_ADDRESS\\n\");\ndfw.write(\"          value: \\\"\" + cassandraHost + \"\\\"\\n\");\n...",
            "title": "Changes to the canary release"
        },
        {
            "location": "/17_Event_Sourcing_with_Cassandra/REST_service_with_event_sourcing/#changes-to-the-consumer-driven-contract-test",
            "text": "We need the following two dependencies that we can call the create method of the REST service:  <dependency>\n    <groupId>org.glassfish</groupId>\n    <artifactId>javax.json</artifactId>\n    <version>1.0.4</version>\n    <scope>test</scope>\n</dependency>\n<dependency>\n    <groupId>org.glassfish.jersey.media</groupId>\n    <artifactId>jersey-media-json-processing</artifactId>\n    <version>2.12</version>\n    <scope>test</scope>\n</dependency>  The test itself has to be replaced with the following code:  @FixMethodOrder(MethodSorters.NAME_ASCENDING)\npublic class BattleAppIT {\n\n    public static final String ID = \"id\";\n    public static final String NICKNAME = \"nickname\";\n    public static final String FIRST_NAME = \"firstName\";\n    public static final String LAST_NAME = \"lastName\";\n\n    public static final String LOCATION = \"Location\";\n\n    @Rule\n    public JAXRSClientProvider provider = buildWithURI(\"http://\" + System.getenv(\"HOST\") + \":\" + System.getenv(\"PORT\") + \"/battleapp/resources/users\");\n\n    private String nickname = \"rob\";\n    private String firstName = \"Robert\";\n    private String lastName = \"Brem\";\n\n\n    @Test\n    public void a01_shouldCreateRob() throws IOException {\n        JsonObjectBuilder userBuilder = Json.createObjectBuilder();\n        JsonObject playerToCreate = userBuilder\n                .add(ID, UUID.randomUUID().toString())\n                .add(NICKNAME, nickname)\n                .add(FIRST_NAME, firstName)\n                .add(LAST_NAME, lastName)\n                .build();\n\n        String token = KeycloakTokenCreator\n                .getTokenResponse(\n                        System.getenv(\"APPLICATION_USER_NAME\"),\n                        System.getenv(\"APPLICATION_PASSWORD\"))\n                .getToken();\n\n        Response postResponse = provider\n                .target()\n                .request()\n                .header(\"Authorization\", \"Bearer \" + token)\n                .post(Entity.json(playerToCreate));\n        System.out.println(\"postResponse = \" + postResponse);\n        assertThat(postResponse.getStatus(), is(201));\n        String location = postResponse.getHeaderString(LOCATION);\n    }\n\n    @Test\n    public void a02_shouldReturnRob() throws IOException {\n        String token = KeycloakTokenCreator\n                .getTokenResponse(\n                        System.getenv(\"APPLICATION_USER_NAME\"),\n                        System.getenv(\"APPLICATION_PASSWORD\"))\n                .getToken();\n        String response = provider\n                .target()\n                .request()\n                .header(\"Authorization\", \"Bearer \" + token)\n                .get(String.class);\n        assertThat(response, containsString(nickname));\n    }\n\n}",
            "title": "Changes to the consumer driven contract test"
        },
        {
            "location": "/17_Event_Sourcing_with_Cassandra/Setup_Cassandra/",
            "text": "Setup Cassandra\n\n\nSetup Cassandra on the local machine\n\n\nTo start Cassandra on our local machine we've to execute the following\nscript:\n\n\n#!/usr/bin/env bash\n\ndocker stop cassandra\ndocker rm cassandra\ndocker run --name cassandra -d -e CASSANDRA_START_RPC=true -p 9160:9160 -p 9042:9042 -p 7199:7199 -p 7001:7001 -p 7000:7000 cassandra\necho \"wait for cassandra to start\"\nwhile ! docker logs cassandra | grep \"Listening for thrift clients...\"\ndo\n echo \"$(date) - still trying\"\n sleep 1\ndone\necho \"$(date) - connected successfully\"\n\necho \"copy init script in container\"\ndocker cp initial_db.sql cassandra:/\n\necho \"create database\"\ndocker exec -d cassandra cqlsh localhost -f /initial_db.sql\n\n\n\n\ninitial_db.sql\n contains the creation of the table:\n\n\nCREATE KEYSPACE battleapp WITH REPLICATION = { 'class' : 'SimpleStrategy','replication_factor' : 3 };\n\nUSE battleapp;\n\nCREATE TABLE EVENTS (\n ID text,\n NAME text,\n VERSION bigint,\n DATE timestamp,\n DATA text,\n PRIMARY KEY(ID, NAME, VERSION)\n);\n\n\n\n\nSetup Cassandra in the cluster\n\n\nTo have two separate Cassandra cluster; one for the test environment and one\nfor the production environment we've to separate the test environment from \nthe production environment. That can be achieved with Kubernetes namespaces.\nWe let our production environment run on the default namespace and the\ntest environment in a new namespace called \ntest\n. Therefore we've to create\nthis new namespace in a file:\n\n\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: test\n\n\n\n\nNow we've to tell Kubernetes to create this namespace:\n\n\nkc create -f namespace.yml\n\n\n\n\nWe can test if the namespace was created with the following command:\n\n\nkc get namespace | grep test\n\n\n\n\ntest          Active        6h\n\n\n\n\nFor Cassandra we're going to use Kubernetes deamonsets. A deamonset\nstarts on each node on the cluster a pod that's defined in the\ndeamonset. We don't want to start Cassandra on every node therefore \nwe create more node labels. In this case we set the label \ngroup=cassandra\n\non three nodes:\n\n\nkc label nodes vmi71989.contabo.host group=cassandra\nkc label nodes vmi71992.contabo.host group=cassandra\nkc label nodes vmi71992.contabo.host group=cassandra\n\n\n\n\nWe can test this setting with the following command:\n\n\nkc get no -l group=cassandra\n\n\n\n\nNAME                    STATUS    AGE\nvmi71989.contabo.host   Ready     6d\nvmi71992.contabo.host   Ready     10d\nvmi74389.contabo.host   Ready     10d\n\n\n\n\nThis is are going to be the nodes for our production Cassandra cluster.\nFor our test environment we specify just one node with the label\n\ngroup=cassandra-test\n.\n\n\nkc label nodes vmi74388.contabo.host group=cassandra\n\n\n\n\nkc get no -l group=cassandra-test\n\n\n\n\nNAME                    STATUS    AGE\nvmi74388.contabo.host   Ready     10d\n\n\n\n\nNow we've to create a service for each environment:\n\n\napiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    name: cassandra\n  name: cassandra\nspec:\n  clusterIP: None\n  ports:\n    - port: 9042\n  selector:\n    name: cassandra\n\n\n\n\nAnd here the service for the test environment:\n\n\napiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    name: cassandra\n  name: cassandra\n  namespace: test\nspec:\n  clusterIP: None\n  ports:\n    - port: 9042\n  selector:\n    name: cassandra\n\n\n\n\nThen we've to start the services:\n\n\nkc create -f cassandra.yml\nkc create -f cassandra-test.yml\n\n\n\n\nNow we can create the daemonset for each environment:\n\n\napiVersion: extensions/v1beta1\nkind: DaemonSet\nmetadata:\n  labels:\n    name: cassandra\n  name: cassandra\nspec:\n  template:\n    metadata:\n      labels:\n        name: cassandra\n    spec:\n      # Filter to specific nodes:\n      nodeSelector:\n        group: cassandra\n      containers:\n        - command:\n            - /run.sh\n          env:\n            - name: MAX_HEAP_SIZE\n              value: 512M\n            - name: HEAP_NEWSIZE\n              value: 100M\n            - name: CASSANDRA_SEED_PROVIDER\n              value: \"io.k8s.cassandra.KubernetesSeedProvider\"\n            - name: POD_NAMESPACE\n              valueFrom:\n                fieldRef:\n                  fieldPath: metadata.namespace\n            - name: POD_IP\n              valueFrom:\n                fieldRef:\n                  fieldPath: status.podIP\n          image: gcr.io/google-samples/cassandra:v11\n          name: cassandra\n          ports:\n            - containerPort: 7000\n              name: intra-node\n            - containerPort: 7001\n              name: tls-intra-node\n            - containerPort: 7199\n              name: jmx\n            - containerPort: 9042\n              name: cql\n          volumeMounts:\n            - mountPath: /cassandra_data\n              name: data\n      volumes:\n        - name: data\n          emptyDir: {}\n\n\n\n\nAnd the daemonset for the test environment:\n\n\napiVersion: extensions/v1beta1\nkind: DaemonSet\nmetadata:\n  labels:\n    name: cassandra\n  name: cassandra\n  namespace: test\nspec:\n  template:\n    metadata:\n      labels:\n        name: cassandra\n    spec:\n      # Filter to specific nodes:\n      nodeSelector:\n        group: cassandra-test\n      containers:\n        - command:\n            - /run.sh\n          env:\n            - name: MAX_HEAP_SIZE\n              value: 512M\n            - name: HEAP_NEWSIZE\n              value: 100M\n            - name: CASSANDRA_SEED_PROVIDER\n              value: \"io.k8s.cassandra.KubernetesSeedProvider\"\n            - name: POD_NAMESPACE\n              valueFrom:\n                fieldRef:\n                  fieldPath: metadata.namespace\n            - name: POD_IP\n              valueFrom:\n                fieldRef:\n                  fieldPath: status.podIP\n          image: gcr.io/google-samples/cassandra:v11\n          name: cassandra\n          ports:\n            - containerPort: 7000\n              name: intra-node\n            - containerPort: 7001\n              name: tls-intra-node\n            - containerPort: 7199\n              name: jmx\n            - containerPort: 9042\n              name: cql\n          volumeMounts:\n            - mountPath: /cassandra_data\n              name: data\n      volumes:\n        - name: data\n          emptyDir: {}\n\n\n\n\nThen we've to start the daemonsets:\n\n\nkc create -f cassandra.yml\nkc create -f cassandra-test.yml\n\n\n\n\nWe can test the setup with the following commands:\n\n\nkc get po -l name=cassandra\n\n\n\n\nNAME              READY     STATUS    RESTARTS   AGE\ncassandra-19qlh   1/1       Running   0          20h\ncassandra-rtgqx   1/1       Running   0          20h\ncassandra-tbhz1   1/1       Running   0          20h\n\n\n\n\nkc exec -it cassandra-19qlh -- nodetool status\n\n\n\n\nDatacenter: datacenter1\n=======================\nStatus=Up/Down\n|/ State=Normal/Leaving/Joining/Moving\n--  Address    Load       Tokens       Owns (effective)  Host ID                               Rack\nUN  10.36.0.3  132.31 KiB  32           71.4%             c6e9ae7e-3806-4e7b-9d7e-f1846e71f33f  rack1\nUN  10.42.0.3  132.33 KiB  32           76.2%             3026572a-f232-43fb-a63c-a32b5efb4b32  rack1\nUN  10.40.0.5  148.29 KiB  32           67.9%             7f7b469e-8a6b-401d-92de-6a5b363d92e9  rack1\n\n\n\n\nThe same for the test environment:\n\n\nkc --namespace test get po -l name=cassandra\n\n\n\n\nNAME              READY     STATUS    RESTARTS   AGE\ncassandra-cgj4q   1/1       Running   0          6h\n\n\n\n\nkc --namespace test exec -it cassandra-cgj4q -- nodetool status\n\n\n\n\nDatacenter: datacenter1\n=======================\nStatus=Up/Down\n|/ State=Normal/Leaving/Joining/Moving\n--  Address    Load       Tokens       Owns (effective)  Host ID                               Rack\nUN  10.44.0.3  124.75 KiB  32           100.0%            5939fe71-23dd-49f5-ae87-4ce174656fb9  rack1\n\n\n\n\nFinally we've to create the Cassandra namespace and table in both environments\nsimilar to the local setting:\n\n\nkc exec -it cassandra-19qlh cqlsh cassandra\n\n\n\n\nConnected to Test Cluster at cassandra:9042.\n[cqlsh 5.0.1 | Cassandra 3.9 | CQL spec 3.4.2 | Native protocol v4]\nUse HELP for help.\ncqlsh>\n\n\n\n\nAnd copy and past the content of the \ninitial_db.sql\n:\n\n\nCREATE KEYSPACE battleapp WITH REPLICATION = { 'class' : 'SimpleStrategy','replication_factor' : 3 };\n\nUSE battleapp;\n\nCREATE TABLE EVENTS (\n ID text,\n NAME text,\n VERSION bigint,\n DATE timestamp,\n DATA text,\n PRIMARY KEY(ID, NAME, VERSION)\n);\n\n\n\n\nThe same for the test environment:\n\n\nkc --namespace test exec -it cassandra-cgj4q cqlsh cassandra",
            "title": "Setup Cassandra"
        },
        {
            "location": "/17_Event_Sourcing_with_Cassandra/Setup_Cassandra/#setup-cassandra",
            "text": "",
            "title": "Setup Cassandra"
        },
        {
            "location": "/17_Event_Sourcing_with_Cassandra/Setup_Cassandra/#setup-cassandra-on-the-local-machine",
            "text": "To start Cassandra on our local machine we've to execute the following\nscript:  #!/usr/bin/env bash\n\ndocker stop cassandra\ndocker rm cassandra\ndocker run --name cassandra -d -e CASSANDRA_START_RPC=true -p 9160:9160 -p 9042:9042 -p 7199:7199 -p 7001:7001 -p 7000:7000 cassandra\necho \"wait for cassandra to start\"\nwhile ! docker logs cassandra | grep \"Listening for thrift clients...\"\ndo\n echo \"$(date) - still trying\"\n sleep 1\ndone\necho \"$(date) - connected successfully\"\n\necho \"copy init script in container\"\ndocker cp initial_db.sql cassandra:/\n\necho \"create database\"\ndocker exec -d cassandra cqlsh localhost -f /initial_db.sql  initial_db.sql  contains the creation of the table:  CREATE KEYSPACE battleapp WITH REPLICATION = { 'class' : 'SimpleStrategy','replication_factor' : 3 };\n\nUSE battleapp;\n\nCREATE TABLE EVENTS (\n ID text,\n NAME text,\n VERSION bigint,\n DATE timestamp,\n DATA text,\n PRIMARY KEY(ID, NAME, VERSION)\n);",
            "title": "Setup Cassandra on the local machine"
        },
        {
            "location": "/17_Event_Sourcing_with_Cassandra/Setup_Cassandra/#setup-cassandra-in-the-cluster",
            "text": "To have two separate Cassandra cluster; one for the test environment and one\nfor the production environment we've to separate the test environment from \nthe production environment. That can be achieved with Kubernetes namespaces.\nWe let our production environment run on the default namespace and the\ntest environment in a new namespace called  test . Therefore we've to create\nthis new namespace in a file:  apiVersion: v1\nkind: Namespace\nmetadata:\n  name: test  Now we've to tell Kubernetes to create this namespace:  kc create -f namespace.yml  We can test if the namespace was created with the following command:  kc get namespace | grep test  test          Active        6h  For Cassandra we're going to use Kubernetes deamonsets. A deamonset\nstarts on each node on the cluster a pod that's defined in the\ndeamonset. We don't want to start Cassandra on every node therefore \nwe create more node labels. In this case we set the label  group=cassandra \non three nodes:  kc label nodes vmi71989.contabo.host group=cassandra\nkc label nodes vmi71992.contabo.host group=cassandra\nkc label nodes vmi71992.contabo.host group=cassandra  We can test this setting with the following command:  kc get no -l group=cassandra  NAME                    STATUS    AGE\nvmi71989.contabo.host   Ready     6d\nvmi71992.contabo.host   Ready     10d\nvmi74389.contabo.host   Ready     10d  This is are going to be the nodes for our production Cassandra cluster.\nFor our test environment we specify just one node with the label group=cassandra-test .  kc label nodes vmi74388.contabo.host group=cassandra  kc get no -l group=cassandra-test  NAME                    STATUS    AGE\nvmi74388.contabo.host   Ready     10d  Now we've to create a service for each environment:  apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    name: cassandra\n  name: cassandra\nspec:\n  clusterIP: None\n  ports:\n    - port: 9042\n  selector:\n    name: cassandra  And here the service for the test environment:  apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    name: cassandra\n  name: cassandra\n  namespace: test\nspec:\n  clusterIP: None\n  ports:\n    - port: 9042\n  selector:\n    name: cassandra  Then we've to start the services:  kc create -f cassandra.yml\nkc create -f cassandra-test.yml  Now we can create the daemonset for each environment:  apiVersion: extensions/v1beta1\nkind: DaemonSet\nmetadata:\n  labels:\n    name: cassandra\n  name: cassandra\nspec:\n  template:\n    metadata:\n      labels:\n        name: cassandra\n    spec:\n      # Filter to specific nodes:\n      nodeSelector:\n        group: cassandra\n      containers:\n        - command:\n            - /run.sh\n          env:\n            - name: MAX_HEAP_SIZE\n              value: 512M\n            - name: HEAP_NEWSIZE\n              value: 100M\n            - name: CASSANDRA_SEED_PROVIDER\n              value: \"io.k8s.cassandra.KubernetesSeedProvider\"\n            - name: POD_NAMESPACE\n              valueFrom:\n                fieldRef:\n                  fieldPath: metadata.namespace\n            - name: POD_IP\n              valueFrom:\n                fieldRef:\n                  fieldPath: status.podIP\n          image: gcr.io/google-samples/cassandra:v11\n          name: cassandra\n          ports:\n            - containerPort: 7000\n              name: intra-node\n            - containerPort: 7001\n              name: tls-intra-node\n            - containerPort: 7199\n              name: jmx\n            - containerPort: 9042\n              name: cql\n          volumeMounts:\n            - mountPath: /cassandra_data\n              name: data\n      volumes:\n        - name: data\n          emptyDir: {}  And the daemonset for the test environment:  apiVersion: extensions/v1beta1\nkind: DaemonSet\nmetadata:\n  labels:\n    name: cassandra\n  name: cassandra\n  namespace: test\nspec:\n  template:\n    metadata:\n      labels:\n        name: cassandra\n    spec:\n      # Filter to specific nodes:\n      nodeSelector:\n        group: cassandra-test\n      containers:\n        - command:\n            - /run.sh\n          env:\n            - name: MAX_HEAP_SIZE\n              value: 512M\n            - name: HEAP_NEWSIZE\n              value: 100M\n            - name: CASSANDRA_SEED_PROVIDER\n              value: \"io.k8s.cassandra.KubernetesSeedProvider\"\n            - name: POD_NAMESPACE\n              valueFrom:\n                fieldRef:\n                  fieldPath: metadata.namespace\n            - name: POD_IP\n              valueFrom:\n                fieldRef:\n                  fieldPath: status.podIP\n          image: gcr.io/google-samples/cassandra:v11\n          name: cassandra\n          ports:\n            - containerPort: 7000\n              name: intra-node\n            - containerPort: 7001\n              name: tls-intra-node\n            - containerPort: 7199\n              name: jmx\n            - containerPort: 9042\n              name: cql\n          volumeMounts:\n            - mountPath: /cassandra_data\n              name: data\n      volumes:\n        - name: data\n          emptyDir: {}  Then we've to start the daemonsets:  kc create -f cassandra.yml\nkc create -f cassandra-test.yml  We can test the setup with the following commands:  kc get po -l name=cassandra  NAME              READY     STATUS    RESTARTS   AGE\ncassandra-19qlh   1/1       Running   0          20h\ncassandra-rtgqx   1/1       Running   0          20h\ncassandra-tbhz1   1/1       Running   0          20h  kc exec -it cassandra-19qlh -- nodetool status  Datacenter: datacenter1\n=======================\nStatus=Up/Down\n|/ State=Normal/Leaving/Joining/Moving\n--  Address    Load       Tokens       Owns (effective)  Host ID                               Rack\nUN  10.36.0.3  132.31 KiB  32           71.4%             c6e9ae7e-3806-4e7b-9d7e-f1846e71f33f  rack1\nUN  10.42.0.3  132.33 KiB  32           76.2%             3026572a-f232-43fb-a63c-a32b5efb4b32  rack1\nUN  10.40.0.5  148.29 KiB  32           67.9%             7f7b469e-8a6b-401d-92de-6a5b363d92e9  rack1  The same for the test environment:  kc --namespace test get po -l name=cassandra  NAME              READY     STATUS    RESTARTS   AGE\ncassandra-cgj4q   1/1       Running   0          6h  kc --namespace test exec -it cassandra-cgj4q -- nodetool status  Datacenter: datacenter1\n=======================\nStatus=Up/Down\n|/ State=Normal/Leaving/Joining/Moving\n--  Address    Load       Tokens       Owns (effective)  Host ID                               Rack\nUN  10.44.0.3  124.75 KiB  32           100.0%            5939fe71-23dd-49f5-ae87-4ce174656fb9  rack1  Finally we've to create the Cassandra namespace and table in both environments\nsimilar to the local setting:  kc exec -it cassandra-19qlh cqlsh cassandra  Connected to Test Cluster at cassandra:9042.\n[cqlsh 5.0.1 | Cassandra 3.9 | CQL spec 3.4.2 | Native protocol v4]\nUse HELP for help.\ncqlsh>  And copy and past the content of the  initial_db.sql :  CREATE KEYSPACE battleapp WITH REPLICATION = { 'class' : 'SimpleStrategy','replication_factor' : 3 };\n\nUSE battleapp;\n\nCREATE TABLE EVENTS (\n ID text,\n NAME text,\n VERSION bigint,\n DATE timestamp,\n DATA text,\n PRIMARY KEY(ID, NAME, VERSION)\n);  The same for the test environment:  kc --namespace test exec -it cassandra-cgj4q cqlsh cassandra",
            "title": "Setup Cassandra in the cluster"
        },
        {
            "location": "/mkdocs/README/",
            "text": "mkdocs\n\n\nvirtualenv and installation\n\n\nvirtualenv .venv\n.venv/bin/activate\npip install mkdocs\n\n\n\n\nServe Documentation\n\n\nmkdocs serve",
            "title": "README"
        },
        {
            "location": "/mkdocs/README/#mkdocs",
            "text": "",
            "title": "mkdocs"
        },
        {
            "location": "/mkdocs/README/#virtualenv-and-installation",
            "text": "virtualenv .venv\n.venv/bin/activate\npip install mkdocs",
            "title": "virtualenv and installation"
        },
        {
            "location": "/mkdocs/README/#serve-documentation",
            "text": "mkdocs serve",
            "title": "Serve Documentation"
        }
    ]
}